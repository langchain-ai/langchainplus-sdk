{"id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","name":"RetrievalGraph","start_time":"2024-12-04T19:59:29.374537","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:29.374537+00:00"},{"name":"end","time":"2024-12-04T20:00:16.559179+00:00"}],"inputs":{"messages":[{"role":"user","content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ "}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":[],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d"}
{"id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","name":"RetrievalGraph","end_time":"2024-12-04T20:00:16.559179","error":null,"outputs":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false},{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-7d69b282-55a6-4665-8dd8-50146bca4a14","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-83dcd4ef-2ca1-41f8-9e85-847e0f6bed23","example":false,"tool_calls":[],"invalid_tool_calls":[]}],"steps":[],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}],"answer":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":2}}
{"id":"28330be6-2293-4f57-b869-094f825fd3ad","name":"__start__","start_time":"2024-12-04T19:59:29.566096","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:29.566096+00:00"},{"name":"end","time":"2024-12-04T19:59:29.572128+00:00"}],"inputs":{"messages":[{"role":"user","content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ "}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":14,"langgraph_node":"__start__","langgraph_triggers":["__start__"],"langgraph_path":["__pregel_pull","__start__"],"langgraph_checkpoint_ns":"__start__:887d4e59-c3c0-0a6d-3222-fb4fa60bf075","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","graph:step:14"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195929566096Z28330be6-2293-4f57-b869-094f825fd3ad"}
{"id":"28330be6-2293-4f57-b869-094f825fd3ad","name":"__start__","end_time":"2024-12-04T19:59:29.572128","error":null,"outputs":{"messages":[{"role":"user","content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ "}]}}
{"id":"3a323f66-f558-4195-8318-256c2cabb3ca","name":"create_research_plan","start_time":"2024-12-04T19:59:29.581985","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:29.581985+00:00"},{"name":"end","time":"2024-12-04T19:59:31.162025+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false}],"router":{"type":"general","logic":""},"steps":[],"documents":[{"metadata":{"language":"en","description":"In this guide we'll go over the basic ways of constructing a knowledge graph based on unstructured text. The constructured graph can then be used as knowledge base in a RAG application.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_constructing/","title":"How to construct knowledge graphs | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_constructing/","uuid":"2270528e-3cdd-5cff-ae69-78fbf258df3e"},"page_content":"```python\nfrom langchain_core.documents import Document\n\ntext = \"\"\"\nMarie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\nShe was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\nHer husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\nShe was, in 1906, the first woman to become a professor at the University of Paris.\n\"\"\"\ndocuments = [Document(page_content=text)]\ngraph_documents = llm_transformer.convert_to_graph_documents(documents)\nprint(f\"Nodes:{graph_documents[0].nodes}\")\nprint(f\"Relationships:{graph_documents[0].relationships}\")\n```\n\n**API Reference:**[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html)\n```output\nNodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Organization', properties={})]\nRelationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='MARRIED', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Organization', properties={}), type='PROFESSOR', properties={})]\n```\n\nExamine the following image to better grasp the structure of the generated knowledge graph.\n\n![graph_construction1.png](/assets/images/graph_construction1-2b4d31978d58696d5a6a52ad92ae088f.png)\n\nNote that the graph construction process is non-deterministic since we are using LLM. Therefore, you might get slightly different results on each execution.\n\nAdditionally, you have the flexibility to define specific types of nodes and relationships for extraction according to your requirements.\n\n```python\nllm_transformer_filtered = LLMGraphTransformer(\n    llm=llm,\n    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n)\ngraph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(\n    documents\n)\nprint(f\"Nodes:{graph_documents_filtered[0].nodes}\")\nprint(f\"Relationships:{graph_documents_filtered[0].relationships}\")\n```\n\n```output\nNodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Organization', properties={})]\nRelationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Organization', properties={}), type='WORKED_AT', properties={})]\n```\n\nTo define the graph schema more precisely, consider using a three-tuple approach for relationships. In this approach, each tuple consists of three elements: the source node, the relationship type, and the target node.\n\n```python\nallowed_relationships = [\n    (\"Person\", \"SPOUSE\", \"Person\"),\n    (\"Person\", \"NATIONALITY\", \"Country\"),\n    (\"Person\", \"WORKED_AT\", \"Organization\"),\n]\n\nllm_transformer_tuple = LLMGraphTransformer(\n    llm=llm,\n    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n    allowed_relationships=allowed_relationships,\n)\ngraph_documents_filtered = llm_transformer_tuple.convert_to_graph_documents(documents)\nprint(f\"Nodes:{graph_documents_filtered[0].nodes}\")\nprint(f\"Relationships:{graph_documents_filtered[0].relationships}\")\n```","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over the basic ways of constructing a knowledge graph based on unstructured text. The constructured graph can then be used as knowledge base in a RAG application.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_constructing/","title":"How to construct knowledge graphs | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_constructing/","uuid":"62d2375d-0e7b-5618-aec1-5fba71f7158d"},"page_content":"```output\nNodes:[Node(id='Marie Curie', type='Person', properties={}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Organization', properties={})]\nRelationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Organization', properties={}), type='WORKED_AT', properties={})]\n```\n\nFor a better understanding of the generated graph, we can again visualize it.\n\n![graph_construction2.png](/assets/images/graph_construction2-8b43506ae0fb3a006eaa4ba83fea8af5.png)\n\nThe `node_properties` parameter enables the extraction of node properties, allowing the creation of a more detailed graph.\nWhen set to `True`, LLM autonomously identifies and extracts relevant node properties.\nConversely, if `node_properties` is defined as a list of strings, the LLM selectively retrieves only the specified properties from the text.\n\n```python\nllm_transformer_props = LLMGraphTransformer(\n    llm=llm,\n    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n    node_properties=[\"born_year\"],\n)\ngraph_documents_props = llm_transformer_props.convert_to_graph_documents(documents)\nprint(f\"Nodes:{graph_documents_props[0].nodes}\")\nprint(f\"Relationships:{graph_documents_props[0].relationships}\")\n```\n\n```output\nNodes:[Node(id='Marie Curie', type='Person', properties={'born_year': '1867'}), Node(id='Pierre Curie', type='Person', properties={}), Node(id='University Of Paris', type='Organization', properties={}), Node(id='Poland', type='Country', properties={}), Node(id='France', type='Country', properties={})]\nRelationships:[Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Poland', type='Country', properties={}), type='NATIONALITY', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='France', type='Country', properties={}), type='NATIONALITY', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='Pierre Curie', type='Person', properties={}), type='SPOUSE', properties={}), Relationship(source=Node(id='Marie Curie', type='Person', properties={}), target=Node(id='University Of Paris', type='Organization', properties={}), type='WORKED_AT', properties={})]\n```\n\n## Storing to graph database​\n\nThe generated graph documents can be stored to a graph database using the `add_graph_documents` method.\n\n```python\ngraph.add_graph_documents(graph_documents_props)\n```\n\nMost graph databases support indexes to optimize data import and retrieval. Since we might not know all the node labels in advance, we can handle this by adding a secondary base label to each node using the `baseEntityLabel` parameter.\n\n```python\ngraph.add_graph_documents(graph_documents, baseEntityLabel=True)\n```\n\nResults will look like:\n\n![graph_construction3.png](/assets/images/graph_construction3-86cbbef451d33d8b6fa50c2d79af6103.png)\n\nThe final option is to also import the source documents for the extracted nodes and relationships. This approach lets us track which documents each entity appeared in.\n\n```python\ngraph.add_graph_documents(graph_documents, include_source=True)\n```\n\nGraph will have the following structure:\n\n![graph_construction4.png](/assets/images/graph_construction4-e41087302ef4c331c2c95b57467f4c62.png)\n\nIn this visualization, the source document is highlighted in blue, with all entities extracted from it connected by `MENTIONS` relationships.\n\n#### Was this page helpful?\n\n- [⚠️ Security note ⚠️](#️-security-note-️)\n\n- [Architecture](#architecture)\n\n- [Setup](#setup)\n\n- [LLM Graph Transformer](#llm-graph-transformer)\n\n- [Storing to graph database](#storing-to-graph-database)","type":"Document"},{"metadata":{"description":"RDFLib is a pure Python package for working with RDF. RDFLib contains most things you need to work with RDF, including:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/graphs/rdflib_sparql/","title":"RDFLib | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/graphs/rdflib_sparql/","uuid":"461a6c3c-0897-5ea1-a939-1564c33064cb"},"page_content":"```output\nIn the following, each IRI is followed by the local name and optionally its description in parentheses. \nThe RDF graph supports the following node types:\n<http://xmlns.com/foaf/0.1/PersonalProfileDocument> (PersonalProfileDocument, None), <http://www.w3.org/ns/auth/cert#RSAPublicKey> (RSAPublicKey, None), <http://www.w3.org/2000/10/swap/pim/contact#Male> (Male, None), <http://xmlns.com/foaf/0.1/Person> (Person, None), <http://www.w3.org/2006/vcard/ns#Work> (Work, None)\nThe RDF graph supports the following relationships:","type":"Document"},{"metadata":{"description":"Neo4j is a graph database management system developed by Neo4j, Inc.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/graphs/neo4j_cypher/","title":"Neo4j | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/graphs/neo4j_cypher/","uuid":"5eb12c5d-6706-58e5-8e62-9c3549e6e7bd"},"page_content":"- [Ignore specified node and relationship types](#ignore-specified-node-and-relationship-types)\n\n- [Validate generated Cypher statements](#validate-generated-cypher-statements)\n\n- [Provide context from database results as tool/function output](#provide-context-from-database-results-as-toolfunction-output)","type":"Document"},{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"a82d8b04-c2ff-5551-8ec0-19ac3780eef6"},"page_content":"The example below shows how we can modify the `source` to only contain information of the file source relative to the `langchain` directory.\n\n```python\n# Define the metadata extraction function.\ndef metadata_func(record: dict, metadata: dict) -> dict:\n\n    metadata[\"sender_name\"] = record.get(\"sender_name\")\n    metadata[\"timestamp_ms\"] = record.get(\"timestamp_ms\")\n\n    if \"source\" in metadata:\n        source = metadata[\"source\"].split(\"/\")\n        source = source[source.index(\"langchain\"):]\n        metadata[\"source\"] = \"/\".join(source)\n\n    return metadata\n\nloader = JSONLoader(\n    file_path='./example_data/facebook_chat.json',\n    jq_schema='.messages[]',\n    content_key=\"content\",\n    metadata_func=metadata_func\n)\n\ndata = loader.load()\n```\n\n```python\npprint(data)\n```\n\n```output\n    [Document(page_content='Bye!', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 1, 'sender_name': 'User 2', 'timestamp_ms': 1675597571851}),\n     Document(page_content='Oh no worries! Bye', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 2, 'sender_name': 'User 1', 'timestamp_ms': 1675597435669}),\n     Document(page_content='No Im sorry it was my mistake, the blue one is not for sale', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 3, 'sender_name': 'User 2', 'timestamp_ms': 1675596277579}),\n     Document(page_content='I thought you were selling the blue one!', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 4, 'sender_name': 'User 1', 'timestamp_ms': 1675595140251}),\n     Document(page_content='Im not interested in this bag. Im interested in the blue one!', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 5, 'sender_name': 'User 1', 'timestamp_ms': 1675595109305}),\n     Document(page_content='Here is $129', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 6, 'sender_name': 'User 2', 'timestamp_ms': 1675595068468}),\n     Document(page_content='', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 7, 'sender_name': 'User 2', 'timestamp_ms': 1675595060730}),\n     Document(page_content='Online is at least $100', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 8, 'sender_name': 'User 2', 'timestamp_ms': 1675595045152}),\n     Document(page_content='How much do you want?', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 9, 'sender_name': 'User 1', 'timestamp_ms': 1675594799696}),\n     Document(page_content='Goodmorning! $50 is too low.', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 10, 'sender_name': 'User 2', 'timestamp_ms': 1675577876645}),\n     Document(page_content='Hi! Im interested in your bag. Im offering $50. Let me know if you are interested. Thanks!', metadata={'source': 'langchain/docs/modules/indexes/document_loaders/examples/example_data/facebook_chat.json', 'seq_num': 11, 'sender_name': 'User 1', 'timestamp_ms': 1675549022673})]\n```\n\n## Common JSON structures with jq schema​\n\nThe list below provides a reference to the possible `jq_schema` the user can use to extract content from the JSON data depending on the structure.\n\n```text\nJSON        -> [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]\njq_schema   -> \".[].text\"\n\nJSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"Amazon Neptune is a high-performance graph analytics and serverless database for superior scalability and availability.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/graphs/amazon_neptune_sparql/","title":"Amazon Neptune with SPARQL | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/graphs/amazon_neptune_sparql/","uuid":"1cc16785-1b39-57fe-a3cf-6198b85ffcf4"},"page_content":"Amazon Neptune with SPARQL | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Amazon Neptune with SPARQL\n\n[Amazon Neptune](https://aws.amazon.com/neptune/) is a high-performance graph analytics and serverless database for superior scalability and availability.\n\nThis example shows the QA chain that queries [Resource Description Framework (RDF)](https://en.wikipedia.org/wiki/Resource_Description_Framework) data\nin an `Amazon Neptune` graph database using the `SPARQL` query language and returns a human-readable response.\n\n[SPARQL](https://en.wikipedia.org/wiki/SPARQL) is a standard query language for `RDF` graphs.\n\nThis example uses a `NeptuneRdfGraph` class that connects with the Neptune database and loads its schema.\nThe `NeptuneSparqlQAChain` is used to connect the graph and LLM to ask natural language questions.\n\nThis notebook demonstrates an example using organizational data.\n\nRequirements for running this notebook:\n\n- Neptune 1.2.x cluster accessible from this notebook\n\n- Kernel with Python 3.9 or higher\n\n- For Bedrock access, ensure IAM role has this policy\n\n```json\n{\n        \"Action\": [\n            \"bedrock:ListFoundationModels\",\n            \"bedrock:InvokeModel\"\n        ],\n        \"Resource\": \"*\",\n        \"Effect\": \"Allow\"\n}\n```\n\n- S3 bucket for staging sample data. The bucket should be in the same account/region as Neptune.\n\n## Setting up​\n\n### Seed the W3C organizational data​\n\nSeed the W3C organizational data, W3C org ontology plus some instances.\n\nYou will need an S3 bucket in the same region and account. Set `STAGE_BUCKET`as the name of that bucket.\n\n```python\nSTAGE_BUCKET = \"<bucket-name>\"\n```\n\n```bash\n%%bash  -s \"$STAGE_BUCKET\"\n\nrm -rf data\nmkdir -p data\ncd data\necho getting org ontology and sample org instances\nwget http://www.w3.org/ns/org.ttl \nwget https://raw.githubusercontent.com/aws-samples/amazon-neptune-ontology-example-blog/main/data/example_org.ttl \n\necho Copying org ttl to S3\naws s3 cp org.ttl s3://$1/org.ttl\naws s3 cp example_org.ttl s3://$1/example_org.ttl\n\n```\n\nBulk-load the org ttl - both ontology and instances\n\n```python\n%load -s s3://{STAGE_BUCKET} -f turtle --store-to loadres --run\n```\n\n```python\n%load_status {loadres['payload']['loadId']} --errors --details\n```\n\n### Setup Chain​\n\n```python\n!pip install --upgrade --quiet langchain langchain-community langchain-aws\n```\n\n** Restart kernel **\n\n### Prepare an example​\n\n```python\nEXAMPLES = \"\"\"\n\n<question>\nFind organizations.\n</question>\n\n<sparql>\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \nPREFIX org: <http://www.w3.org/ns/org#> \n\nselect ?org ?orgName where {{\n    ?org rdfs:label ?orgName .\n}} \n</sparql>\n\n<question>\nFind sites of an organization\n</question>\n\n<sparql>\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \nPREFIX org: <http://www.w3.org/ns/org#> \n\nselect ?org ?orgName ?siteName where {{\n    ?org rdfs:label ?orgName .\n    ?org org:hasSite/rdfs:label ?siteName . \n}} \n</sparql>\n\n<question>\nFind suborganizations of an organization\n</question>\n\n<sparql>\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \nPREFIX org: <http://www.w3.org/ns/org#> \n\nselect ?org ?orgName ?subName where {{\n    ?org rdfs:label ?orgName .\n    ?org org:hasSubOrganization/rdfs:label ?subName  .\n}} \n</sparql>\n\n<question>\nFind organizational units of an organization\n</question>\n\n<sparql>\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> \nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#> \nPREFIX org: <http://www.w3.org/ns/org#> \n\nselect ?org ?orgName ?unitName where {{\n    ?org rdfs:label ?orgName .\n    ?org org:hasUnit/rdfs:label ?unitName . \n}} \n</sparql>\n\n<question>\nFind members of an organization. Also find their manager, or the member they report to.\n</question>","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"Exa is a search engine fully designed for use by LLMs. Search for documents on the internet using natural language queries, then retrieve cleaned HTML content from desired documents.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/exa_search/","title":"Exa Search | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/exa_search/","uuid":"4997eea3-74a6-5adb-ae92-6c424b87b63e"},"page_content":"managing ever increasing piles of computer instructions and punchcards became overwhelming for humans. In the 1950s, functions were introduced by FORTRAN and became wildly popular as the de facto way to organize instructions almost regardless of programming language.  The Functional Programming (FP) community has elevated the venerable “function” to almost religious status - but that just might be the final blowoff top, much like the fate of OO before it. I’m not going to waste too much time on FP terminology since the hardcore FP zealots will just strawman all day instead of directly answering the tough questions. Most developers don’t care about FP anyway. Cats just view functions as glorified instruction containers. Yes, functions can still play an important role but not quite as central as you think. Thanks to automation, we can now consider alternate ways to manage piles of instructions without always having to resort to functions.  Functions have obviously served the computing industry well for 70 years, so clearly they work in most situations. However, they are starting to show their age. To glue two functions together, you generally need to rely on a third “wrapper” function that shuffles output from one function to the other. This approach is generally put under the heading of lambda calculus and famously credited for allowing programmers to reuse mountains of code. However, it still has a number of drawbacks that become apparent over time:   Functions do not scale across hardware or programming languages because they are hard-wired - and so you eventually end up with the notorious “monolith” until you break things up into services. But now your programmers are having to deal with things you normally pay an operating system to handle   Functions place the burden on the caller to manage the parameters needed to call the function. So while you achieve better code reuse, the benefit is largely offset by having to explicitly manage all the parameters   between   functions. This wiring tends to be pretty dumb too - you can’t even query it like an RDBMS - so you have to treat it much like a 1960s era network database with glorified pointers everywhere. Imagine a rat’s nest of cables. Great if you are a C programmer but not so much fun for everyone else since you’ve moved a lot of problems outside the function where it’s harder to diagnose   Functions have a structural reuse limitation: a single entry/exit - you either take all of the instructions or nothing, there is no middle ground. In many situations that’s fine but what if it’s a big function and you just need a few lines … not the entire thing … ? You must manually break up the function via “refactoring”   To its credit, FP tries to avoid the use of explicit wrappers by letting you chain instructions directly (almost like mini-scripts) but since these chains are also hardwired, it’s hard to see much advantage. Monoliths are infamous for being mysterious black boxes because functions by themselves give almost no visibility into what’s going on unless you break things up or write print statements to a log. Because functions have math-y roots from FORTRAN, it is tempting to treat code almost like math proofs e.g. prove that code is doing what you think it is doing. In practice, this has mixed success. Certainly compilers, type checkers and program verification tools do this sort of stuff anyway but the average developer does not have a math degree and risks not getting the math right. So in many cases, introducing math either increases overall complexity or just moves the problem. Debugging strange errors in your type system can be really difficult. Here’s the issue: the math folks have been warning programmers for years that computer functions are not really the same as math functions. Yeah they look the same but trying to overly conflate the two eventually leads to trouble. It might be more intellectually honest if we at least called them ‘procedures’ instead. Sure,","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/how-tos/return-when-recursion-limit-hits/","title":"How to return state before hitting recursion limit | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/how-tos/return-when-recursion-limit-hits/","uuid":"2af0cccf-6cf4-58d3-96f9-6a1421f293c6"},"page_content":"def router(state: State):\n    # Force the agent to end\n    if state[\"remaining_steps\"] <= 2:\n        return END\n    if state[\"value\"] == \"end\":\n        return END\n    else:\n        return \"action\"\n\ndef decision_node(state):\n    return {\"value\": \"keep going!\"}\n\ndef action_node(state: State):\n    # Do your action here ...\n    return {\"action_result\": \"what a great result!\"}\n\nworkflow = StateGraph(State)\nworkflow.add_node(\"decision\", decision_node)\nworkflow.add_node(\"action\", action_node)\nworkflow.add_edge(START, \"decision\")\nworkflow.add_conditional_edges(\"decision\", router, [\"action\", END])\nworkflow.add_edge(\"action\", \"decision\")\napp = workflow.compile()\n\nAPI Reference:\nStateGraph\n\napp.invoke({\"value\": \"hi!\"})\n\n{'value': 'keep going!', 'action_result': 'what a great result!'}\n\nPerfect! Our code ran with no error, just as we expected!\nComments","type":"Document"},{"metadata":{"language":"en","description":"In some cases you will want to access the current run (span) within a traced function. This can be useful for extracting UUIDs, tags, or other information from the current run.","changefreq":null,"source":"https://docs.smith.langchain.com/observability/how_to_guides/tracing/access_current_span","title":"Access the current run (span) within a traced function | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"d30cc0f1-5cbd-56e0-ba30-567ecefe5685"},"page_content":"Access the current run (span) within a traced function | 🦜️🛠️ LangSmith","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/reference/prebuilt/","title":"Prebuilt Components | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/reference/prebuilt/","uuid":"a3bc76c1-7efb-5aa4-9988-99416a322ff1"},"page_content":"if should_return_direct:\n        workflow.add_conditional_edges(\"tools\", route_tool_responses)\n    else:\n        workflow.add_edge(\"tools\", \"agent\")\n\n    # Finally, we compile it!\n    # This compiles it into a LangChain Runnable,\n    # meaning you can use it as you would any other runnable\n    return workflow.compile(\n        checkpointer=checkpointer,\n        store=store,\n        interrupt_before=interrupt_before,\n        interrupt_after=interrupt_after,\n        debug=debug,\n    )\n\n ToolNode\n¶\n\n              Bases: RunnableCallable\nA node that runs the tools called in the last AIMessage.\nIt can be used either in StateGraph with a \"messages\" state key (or a custom key passed via ToolNode's 'messages_key').\nIf multiple tool calls are requested, they will be run in parallel. The output will be\na list of ToolMessages, one for each tool call.\nParameters:\n\ntools\n              (Sequence[Union[BaseTool, Callable]])\n          –\n          \nA sequence of tools that can be invoked by the ToolNode.\n\nname\n              (str, default:\n                  'tools'\n)\n          –\n          \nThe name of the ToolNode in the graph. Defaults to \"tools\".\n\ntags\n              (Optional[list[str]], default:\n                  None\n)\n          –\n          \nOptional tags to associate with the node. Defaults to None.\n\nhandle_tool_errors\n              (Union[bool, str, Callable[..., str], tuple[type[Exception], ...]], default:\n                  True\n)\n          –\n          \nHow to handle tool errors raised by tools inside the node. Defaults to True.\nMust be one of the following:\n\nTrue: all errors will be caught and\n    a ToolMessage with a default error message (TOOL_CALL_ERROR_TEMPLATE) will be returned.\nstr: all errors will be caught and\n    a ToolMessage with the string value of 'handle_tool_errors' will be returned.\ntuple[type[Exception], ...]: exceptions in the tuple will be caught and\n    a ToolMessage with a default error message (TOOL_CALL_ERROR_TEMPLATE) will be returned.\nCallable[..., str]: exceptions from the signature of the callable will be caught and\n    a ToolMessage with the string value of the result of the 'handle_tool_errors' callable will be returned.\nFalse: none of the errors raised by the tools will be caught\n\nmessages_key\n              (str, default:\n                  'messages'\n)\n          –\n          \nThe state key in the input that contains the list of messages.\nThe same key will be used for the output from the ToolNode.\nDefaults to \"messages\".\n\nThe ToolNode is roughly analogous to:\ntools_by_name = {tool.name: tool for tool in tools}\ndef tool_node(state: dict):\n    result = []\n    for tool_call in state[\"messages\"][-1].tool_calls:\n        tool = tools_by_name[tool_call[\"name\"]]\n        observation = tool.invoke(tool_call[\"args\"])\n        result.append(ToolMessage(content=observation, tool_call_id=tool_call[\"id\"]))\n    return {\"messages\": result}\n\nImportant\n\nThe state MUST contain a list of messages.\nThe last message MUST be an AIMessage.\nThe AIMessage MUST have tool_calls populated.","type":"Document"},{"metadata":{"description":"* Tools","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/concepts/tool_calling/","title":"Tool calling | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/concepts/tool_calling/","uuid":"6c6880a9-a40e-5c8d-96e3-a893d5445f16"},"page_content":"llm_with_tools = tool_calling_model.bind_tools([multiply])\n```\n\n## Tool calling​\n\n![Diagram of a tool call by a model](/assets/images/tool_call_example-2348b869f9a5d0d2a45dfbe614c177a4.png)\n\nA key principle of tool calling is that the model decides when to use a tool based on the input's relevance. The model doesn't always need to call a tool.\nFor example, given an unrelated input, the model would not call the tool:\n\n```python\nresult = llm_with_tools.invoke(\"Hello world!\")\n```\n\nThe result would be an `AIMessage` containing the model's response in natural language (e.g., \"Hello!\").\nHowever, if we pass an input _relevant to the tool_, the model should choose to call it:\n\n```python\nresult = llm_with_tools.invoke(\"What is 2 multiplied by 3?\")\n```\n\nAs before, the output `result` will be an `AIMessage`.\nBut, if the tool was called, `result` will have a `tool_calls` attribute.\nThis attribute includes everything needed to execute the tool, including the tool name and input arguments:\n\n```text\nresult.tool_calls\n{'name': 'multiply', 'args': {'a': 2, 'b': 3}, 'id': 'xxx', 'type': 'tool_call'}\n```\n\nFor more details on usage, see our [how-to guides](/docs/how_to/#tools)!\n\n## Tool execution​\n\n[Tools](/docs/concepts/tools/) implement the [Runnable](/docs/concepts/runnables/) interface, which means that they can be invoked (e.g., `tool.invoke(args)`) directly.\n\n[LangGraph](https://langchain-ai.github.io/langgraph/) offers pre-built components (e.g., [ToolNode](https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.tool_node.ToolNode)) that will often invoke the tool in behalf of the user.\n\nFurther reading- See our [how-to guide](/docs/how_to/tool_calling/) on tool calling.\n\n- See the [LangGraph documentation on using ToolNode](https://langchain-ai.github.io/langgraph/how-tos/tool-calling/).\n\n## Best practices​\n\nWhen designing [tools](/docs/concepts/tools/) to be used by a model, it is important to keep in mind that:\n\n- Models that have explicit [tool-calling APIs](/docs/concepts/tool_calling/) will be better at tool calling than non-fine-tuned models.\n\n- Models will perform better if the tools have well-chosen names and descriptions.\n\n- Simple, narrowly scoped tools are easier for models to use than complex tools.\n\n- Asking the model to select from a large list of tools poses challenges for the model.\n\n#### Was this page helpful?\n\n- [Overview](#overview)\n\n- [Key concepts](#key-concepts)\n\n- [Recommended usage](#recommended-usage)\n\n- [Tool creation](#tool-creation)\n\n- [Tool binding](#tool-binding)\n\n- [Tool calling](#tool-calling-1)\n\n- [Tool execution](#tool-execution)\n\n- [Best practices](#best-practices)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/rewoo/rewoo/","title":"Reasoning without Observation | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/rewoo/rewoo/","uuid":"0e85bb0c-bedc-5c1e-be9b-7f9dff00bedc"},"page_content":"Tools can be one of the following:\n(1) Google[input]: Worker that searches results from Google. Useful when you need to find short\nand succinct answers about a specific topic. The input should be a search query.\n(2) LLM[input]: A pretrained LLM like yourself. Useful when you need to act with general\nworld knowledge and common sense. Prioritize it when you are confident in solving the problem\nyourself. Input can be any instruction.\n\nFor example,\nTask: Thomas, Toby, and Rebecca worked a total of 157 hours in one week. Thomas worked x\nhours. Toby worked 10 hours less than twice what Thomas worked, and Rebecca worked 8 hours\nless than Toby. How many hours did Rebecca work?\nPlan: Given Thomas worked x hours, translate the problem into algebraic expressions and solve\nwith Wolfram Alpha. #E1 = WolframAlpha[Solve x + (2x − 10) + ((2x − 10) − 8) = 157]\nPlan: Find out the number of hours Thomas worked. #E2 = LLM[What is x, given #E1]\nPlan: Calculate the number of hours Rebecca worked. #E3 = Calculator[(2 ∗ #E2 − 10) − 8]\n\nBegin! \nDescribe your plans with rich details. Each Plan should be followed by only one #E.\n\nTask: {task}\"\"\"\n\ntask = \"what is the exact hometown of the 2024 mens australian open winner\"\n\nresult = model.invoke(prompt.format(task=task))\n\nprint(result.content)\n\nPlan: Use Google to search for the 2024 Australian Open winner.\n#E1 = Google[2024 Australian Open winner]\n\nPlan: Retrieve the name of the 2024 Australian Open winner from the search results.\n#E2 = LLM[What is the name of the 2024 Australian Open winner, given #E1]\n\nPlan: Use Google to search for the hometown of the 2024 Australian Open winner.\n#E3 = Google[hometown of 2024 Australian Open winner, given #E2]\n\nPlan: Retrieve the hometown of the 2024 Australian Open winner from the search results.\n#E4 = LLM[What is the hometown of the 2024 Australian Open winner, given #E3]\n\nPlanner Node¶\nTo connect the planner to our graph, we will create a get_plan node that accepts the ReWOO state and returns with a state update for the\nsteps and plan_string fields.\nimport re\n\nfrom langchain_core.prompts import ChatPromptTemplate\n\n# Regex to match expressions of the form E#... = ...[...]\nregex_pattern = r\"Plan:\\s*(.+)\\s*(#E\\d+)\\s*=\\s*(\\w+)\\s*\\[([^\\]]+)\\]\"\nprompt_template = ChatPromptTemplate.from_messages([(\"user\", prompt)])\nplanner = prompt_template | model\n\ndef get_plan(state: ReWOO):\n    task = state[\"task\"]\n    result = planner.invoke({\"task\": task})\n    # Find all matches in the sample text\n    matches = re.findall(regex_pattern, result.content)\n    return {\"steps\": matches, \"plan_string\": result.content}\n\nAPI Reference:\nChatPromptTemplate\n\nExecutor¶\nThe executor receives the plan and executes the tools in sequence.\nBelow, instantiate the search engine and define the tool execution node.\nfrom langchain_community.tools.tavily_search import TavilySearchResults\n\nsearch = TavilySearchResults()\n\nAPI Reference:\nTavilySearchResults\n\ndef _get_current_task(state: ReWOO):\n    if \"results\" not in state or state[\"results\"] is None:\n        return 1\n    if len(state[\"results\"]) == len(state[\"steps\"]):\n        return None\n    else:\n        return len(state[\"results\"]) + 1\n\ndef tool_execution(state: ReWOO):\n    \"\"\"Worker node that executes the tools of a given plan.\"\"\"\n    _step = _get_current_task(state)\n    _, step_name, tool, tool_input = state[\"steps\"][_step - 1]\n    _results = (state[\"results\"] or {}) if \"results\" in state else {}\n    for k, v in _results.items():\n        tool_input = tool_input.replace(k, v)\n    if tool == \"Google\":\n        result = search.invoke(tool_input)\n    elif tool == \"LLM\":\n        result = model.invoke(tool_input)\n    else:\n        raise ValueError\n    _results[step_name] = str(result)\n    return {\"results\": _results}","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/how-tos/tool-calling/","title":"How to call tools using ToolNode | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/how-tos/tool-calling/","uuid":"fd74f5e9-40df-5158-a63a-6fea595b821f"},"page_content":"How to call tools using ToolNode\n\nHow to call tools using ToolNode¶\nThis guide covers how to use LangGraph's prebuilt ToolNode for tool calling.\nToolNode is a LangChain Runnable that takes graph state (with a list of messages) as input and outputs state update with the result of tool calls. It is designed to work well out-of-box with LangGraph's prebuilt ReAct agent, but can also work with any StateGraph as long as its state has a messages key with an appropriate reducer (see MessagesState).\nSetup¶\nFirst, let's install the required packages and set our API keys\n%%capture --no-stderr\n%pip install --quiet -U langgraph langchain_anthropic\n\nimport getpass\nimport os\n\ndef _set_env(var: str):\n    if not os.environ.get(var):\n        os.environ[var] = getpass.getpass(f\"{var}: \")\n\n_set_env(\"ANTHROPIC_API_KEY\")\n\nSet up LangSmith for LangGraph development\n\n        Sign up for LangSmith to quickly spot issues and improve the performance of your LangGraph projects. LangSmith lets you use trace data to debug, test, and monitor your LLM apps built with LangGraph — read more about how to get started here. \n    \n\nDefine tools¶\nfrom langchain_core.messages import AIMessage\nfrom langchain_core.tools import tool\n\nfrom langgraph.prebuilt import ToolNode\n\nAPI Reference:\nAIMessage | tool | ToolNode\n\n@tool\ndef get_weather(location: str):\n    \"\"\"Call to get the current weather.\"\"\"\n    if location.lower() in [\"sf\", \"san francisco\"]:\n        return \"It's 60 degrees and foggy.\"\n    else:\n        return \"It's 90 degrees and sunny.\"\n\n@tool\ndef get_coolest_cities():\n    \"\"\"Get a list of coolest cities\"\"\"\n    return \"nyc, sf\"\n\ntools = [get_weather, get_coolest_cities]\ntool_node = ToolNode(tools)\n\nManually call ToolNode¶\nToolNode operates on graph state with a list of messages. It expects the last message in the list to be an AIMessage with tool_calls parameter. \nLet's first see how to invoke the tool node manually:\nmessage_with_single_tool_call = AIMessage(\n    content=\"\",\n    tool_calls=[\n        {\n            \"name\": \"get_weather\",\n            \"args\": {\"location\": \"sf\"},\n            \"id\": \"tool_call_id\",\n            \"type\": \"tool_call\",\n        }\n    ],\n)\n\ntool_node.invoke({\"messages\": [message_with_single_tool_call]})\n\n{'messages': [ToolMessage(content=\"It's 60 degrees and foggy.\", name='get_weather', tool_call_id='tool_call_id')]}\n\nNote that typically you don't need to create AIMessage manually, and it will be automatically generated by any LangChain chat model that supports tool calling.\nYou can also do parallel tool calling using ToolNode if you pass multiple tool calls to AIMessage's tool_calls parameter:\nmessage_with_multiple_tool_calls = AIMessage(\n    content=\"\",\n    tool_calls=[\n        {\n            \"name\": \"get_coolest_cities\",\n            \"args\": {},\n            \"id\": \"tool_call_id_1\",\n            \"type\": \"tool_call\",\n        },\n        {\n            \"name\": \"get_weather\",\n            \"args\": {\"location\": \"sf\"},\n            \"id\": \"tool_call_id_2\",\n            \"type\": \"tool_call\",\n        },\n    ],\n)\n\ntool_node.invoke({\"messages\": [message_with_multiple_tool_calls]})\n\n{'messages': [ToolMessage(content='nyc, sf', name='get_coolest_cities', tool_call_id='tool_call_id_1'),\n  ToolMessage(content=\"It's 60 degrees and foggy.\", name='get_weather', tool_call_id='tool_call_id_2')]}\n\nUsing with chat models¶\nWe'll be using a small chat model from Anthropic in our example. To use chat models with tool calling, we need to first ensure that the model is aware of the available tools. We do this by calling .bind_tools method on ChatAnthropic moodel\nfrom typing import Literal\n\nfrom langchain_anthropic import ChatAnthropic\nfrom langgraph.graph import StateGraph, MessagesState\nfrom langgraph.prebuilt import ToolNode\n\nmodel_with_tools = ChatAnthropic(\n    model=\"claude-3-haiku-20240307\", temperature=0\n).bind_tools(tools)\n\nAPI Reference:\nChatAnthropic | StateGraph | ToolNode\n\nmodel_with_tools.invoke(\"what's the weather in sf?\").tool_calls","type":"Document"},{"metadata":{"language":"en","description":"This guide assumes familiarity with the following concepts:","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"description":"Nuclia automatically indexes your unstructured data from any internal and external source, providing optimized search results and generative answers. It can handle video and audio transcription, image content extraction, and document parsing.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/nuclia/","title":"Nuclia Understanding | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/nuclia/","uuid":"0b22f469-33c4-5bab-909f-44f40db838a3"},"page_content":"## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Retrieved information](#retrieved-information)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"85d6acfe-2490-551f-8352-88c3298ed5b6"},"page_content":"curl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'\n\nOutput:\n{\n    \"assistant_id\": \"62e209ca-9154-432a-b9e9-2d75c7a9219b\",\n    \"graph_id\": \"agent\",\n    \"created_at\": \"2024-08-31T03:09:10.230718+00:00\",\n    \"updated_at\": \"2024-08-31T03:09:10.230718+00:00\",\n    \"config\": {\n        \"configurable\": {\n            \"model_name\": \"open_ai\"\n        }\n    },\n    \"metadata\": {}\n}\n\nWe can verify the config is indeed taking effect:\nPythonJavascriptCURL\n\nthread = await client.threads.create()\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"who made you?\"}]}\nasync for event in client.runs.stream(\n    thread[\"thread_id\"],\n    openai_assistant[\"assistant_id\"],\n    input=input,\n    stream_mode=\"updates\",\n):\n    print(f\"Receiving event of type: {event.event}\")\n    print(event.data)\n    print(\"\\n\\n\")\n\nconst thread = await client.threads.create();\nlet input = { \"messages\": [{ \"role\": \"user\", \"content\": \"who made you?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  openAIAssistant[\"assistant_id\"],\n  {\n    input,\n    streamMode: \"updates\"\n  }\n);\n\nfor await (const event of streamResponse) {\n  console.log(`Receiving event of type: ${event.event}`);\n  console.log(event.data);\n  console.log(\"\\n\\n\");\n}\n\nthread_id=$(curl --request POST \\\n    --url <DEPLOYMENT_URL>/threads \\\n    --header 'Content-Type: application/json' \\\n    --data '{}' | jq -r '.thread_id') && \\\ncurl --request POST \\\n    --url \"<DEPLOYMENT_URL>/threads/${thread_id}/runs/stream\" \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"assistant_id\": <OPENAI_ASSISTANT_ID>,\n        \"input\": {\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": \"who made you?\"\n                }\n            ]\n        },\n        \"stream_mode\": [\n            \"updates\"\n        ]\n    }' | \\\n    sed 's/\\r$//' | \\\n    awk '\n    /^event:/ {\n        if (data_content != \"\") {\n            print data_content \"\\n\"\n        }\n        sub(/^event: /, \"Receiving event of type: \", $0)\n        printf \"%s...\\n\", $0\n        data_content = \"\"\n    }\n    /^data:/ {\n        sub(/^data: /, \"\", $0)\n        data_content = $0\n    }\n    END {\n        if (data_content != \"\") {\n            print data_content \"\\n\\n\"\n        }\n    }\n'\n\nOutput:\nReceiving event of type: metadata\n{'run_id': '1ef6746e-5893-67b1-978a-0f1cd4060e16'}\n\nReceiving event of type: updates\n{'agent': {'messages': [{'content': 'I was created by OpenAI, a research organization focused on developing and advancing artificial intelligence technology.', 'additional_kwargs': {}, 'response_metadata': {'finish_reason': 'stop', 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_157b3831f5'}, 'type': 'ai', 'name': None, 'id': 'run-e1a6b25c-8416-41f2-9981-f9cfe043f414', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': None}]}}\n\nComments","type":"Document"},{"metadata":{"language":"en","description":"When you add a webhook URL on an automation action, we will make a POST request to your webhook endpoint any time the rules you defined match any new runs.","changefreq":null,"source":"https://docs.smith.langchain.com/observability/how_to_guides/monitoring/webhooks","title":"Set up webhook notifications for rules | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"2c2e0edb-a49a-5bd7-bbfa-d298a6931dd0"},"page_content":"\"feedback_stats\": {    \"about_langchain\": {        \"n\": 1,        \"avg\": 0.0,        \"show_feedback_arrow\": true,        \"values\": {}    },    \"category\": {        \"n\": 0,        \"avg\": null,        \"show_feedback_arrow\": true,        \"values\": {            \"CONCEPTUAL\": 1        }    },    \"user_score\": {        \"n\": 2,        \"avg\": 0.0,        \"show_feedback_arrow\": false,        \"values\": {}    },    \"vagueness\": {        \"n\": 1,        \"avg\": 0.0,        \"show_feedback_arrow\": true,        \"values\": {}    }},\nfetching from S3 URLsDepending on how recent your runs are, the inputs_s3_urls and outputs_s3_urls fields may contain S3 URLs to the actual data instead of the data itself.The inputs and outputs can be fetched by the ROOT.presigned_url provided in inputs_s3_urls and outputs_s3_urls respectively.\nThis is an example of the entire payload we send to your webhook endpoint:\n{  \"rule_id\": \"d75d7417-0c57-4655-88fe-1db3cda3a47a\",  \"start_time\": \"2024-04-05T01:28:54.734491+00:00\",  \"end_time\": \"2024-04-05T01:28:56.492563+00:00\",  \"runs\": [    {      \"status\": \"success\",      \"is_root\": true,      \"trace_id\": \"6ab80f10-d79c-4fa2-b441-922ed6feb630\",      \"dotted_order\": \"20230505T051324571809Z6ab80f10-d79c-4fa2-b441-922ed6feb630\",      \"run_type\": \"tool\",      \"modified_at\": \"2024-04-05T01:28:54.145062\",      \"tenant_id\": \"2ebda79f-2946-4491-a9ad-d642f49e0815\",      \"end_time\": \"2024-04-05T01:28:54.085649\",      \"name\": \"Search\",      \"start_time\": \"2024-04-05T01:28:54.085646\",      \"id\": \"6ab80f10-d79c-4fa2-b441-922ed6feb630\",      \"session_id\": \"6a3be6a2-9a8c-4fc8-b4c6-a8983b286cc5\",      \"parent_run_ids\": [],      \"child_run_ids\": null,      \"direct_child_run_ids\": null,      \"total_tokens\": 0,      \"completion_tokens\": 0,      \"prompt_tokens\": 0,      \"total_cost\": null,      \"completion_cost\": null,      \"prompt_cost\": null,      \"first_token_time\": null,      \"app_path\": \"/o/2ebda79f-2946-4491-a9ad-d642f49e0815/projects/p/6a3be6a2-9a8c-4fc8-b4c6-a8983b286cc5/r/6ab80f10-d79c-4fa2-b441-922ed6feb630?trace_id=6ab80f10-d79c-4fa2-b441-922ed6feb630&start_time=2023-05-05T05:13:24.571809\",      \"in_dataset\": false,      \"last_queued_at\": null,      \"inputs\": null,      \"inputs_s3_urls\": null,      \"outputs\": null,      \"outputs_s3_urls\": null,      \"extra\": null,      \"events\": null,      \"feedback_stats\": null,      \"serialized\": null,      \"share_token\": null    }  ]}\nWebhook Security​\nWe strongly recommend you add a secret query string parameter to the webhook URL, and verify it on any incoming request. This ensures that if someone discovers your webhook URL you can distinguish those calls from authentic webhook notifications.\nAn example would be\nhttps://api.example.com/langsmith_webhook?secret=38ee77617c3a489ab6e871fbeb2ec87d\nWebhook custom HTTP headers​\nIf you'd like to send any specific headers with your webhook, this can be configured per URL. To set this up, click on the Headers option next to the URL field and add your headers.\nnoteHeaders are stored in encrypted format.\n\nWebhook Delivery​\nWhen delivering events to your webhook endpoint we follow these guidelines\n\nIf we fail to connect to your endpoint, we retry the transport connection up to 2 times, before declaring the delivery failed.\nIf your endpoint takes longer than 5 seconds to reply we declare the delivery failed and do not .\nIf your endpoint returns a 5xx status code in less than 5 seconds we retry up to 2 times with exponential backoff.\nIf your endpoint returns a 4xx status code, we declare the delivery failed and do not retry.\nAnything your endpoint returns in the body will be ignored","type":"Document"},{"metadata":{"language":"en","description":"This notebook showcases an agent interacting with large JSON/dict objects.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"LangSmith smoothly integrates with LangGraph (Python and JS)","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/observability/how_to_guides/tracing/trace_with_langgraph","title":"Trace with LangGraph (Python and JS/TS) | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"bc1c8080-6af0-578c-903d-d10f4c816306"},"page_content":"2. Log a trace​\nOnce you've set up your environment, wrap or decorate the custom functions/SDKs you want to trace.\nLangSmith will then infer the proper tracing config:\nPythonTypeScriptimport jsonimport openaiimport operatorfrom langsmith import traceablefrom langsmith.wrappers import wrap_openaifrom typing import Annotated, Literal, TypedDictfrom langgraph.graph import StateGraphclass State(TypedDict):    messages: Annotated[list, operator.add]tool_schema = {    \"type\": \"function\",    \"function\": {        \"name\": \"search\",        \"description\": \"Call to surf the web.\",        \"parameters\": {            \"type\": \"object\",            \"properties\": {\"query\": {\"type\": \"string\"}},            \"required\": [\"query\"],        },    },}# Decorating the tool function will automatically trace it with the correct context@traceable(run_type=\"tool\", name=\"Search Tool\")def search(query: str):    \"\"\"Call to surf the web.\"\"\"    if \"sf\" in query.lower() or \"san francisco\" in query.lower():        return \"It's 60 degrees and foggy.\"    return \"It's 90 degrees and sunny.\"tools = [search]def call_tools(state):    function_name_to_function = {\"search\": search}    messages = state[\"messages\"]    tool_call = messages[-1][\"tool_calls\"][0]    function_name = tool_call[\"function\"][\"name\"]    function_arguments = tool_call[\"function\"][\"arguments\"]    arguments = json.loads(function_arguments)    function_response = function_name_to_function[function_name](**arguments)    tool_message = {        \"tool_call_id\": tool_call[\"id\"],        \"role\": \"tool\",        \"name\": function_name,        \"content\": function_response,    }    return {\"messages\": [tool_message]}wrapped_client = wrap_openai(openai.Client())def should_continue(state: State) -> Literal[\"tools\", \"__end__\"]:    messages = state[\"messages\"]    last_message = messages[-1]    if last_message[\"tool_calls\"]:        return \"tools\"    return \"__end__\"def call_model(state: State):    messages = state[\"messages\"]    # Calling the wrapped client will automatically infer the correct tracing context    response = wrapped_client.chat.completions.create(        messages=messages, model=\"gpt-4o-mini\", tools=[tool_schema]    )    raw_tool_calls = response.choices[0].message.tool_calls    tool_calls = [tool_call.to_dict() for tool_call in raw_tool_calls] if raw_tool_calls else []    response_message = {        \"role\": \"assistant\",        \"content\": response.choices[0].message.content,        \"tool_calls\": tool_calls,    }    return {\"messages\": [response_message]}workflow = StateGraph(State)workflow.add_node(\"agent\", call_model)workflow.add_node(\"tools\", call_tools)workflow.add_edge(\"__start__\", \"agent\")workflow.add_conditional_edges(    \"agent\",    should_continue,)workflow.add_edge(\"tools\", 'agent')app = workflow.compile()final_state = app.invoke(    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]})final_state[\"messages\"][-1][\"content\"]Note: The below example requires langsmith>=0.1.39 and @langchain/langgraph>=0.0.31","type":"Document"},{"metadata":{"description":"In this tutorial, we will walk through 3 evaluation strategies LLM agents, building on the conceptual points shared in our evaluation guide.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/evaluation/tutorials/agents","title":"Evaluate an agent | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"949ed011-cc09-5d12-b76c-77d27a9f28a2"},"page_content":"Here, we just invoke the assistant, assistant_runnable, with a prompt and check if the resulting tool call is as expected.\nHere, we are using a specialized agent where the tools are hard-coded (rather than passed with the dataset input).\nWe specify the reference tool call for the step that we are evaluating, expected_tool_call.\n\nfrom langsmith.schemas import Example, Rundef predict_assistant(example: dict):    \"\"\"Invoke assistant for single tool call evaluation\"\"\"    msg = [ (\"user\", example[\"input\"]) ]    result = assistant_runnable.invoke({\"messages\":msg})    return {\"response\": result}def check_specific_tool_call(root_run: Run, example: Example) -> dict:    \"\"\"    Check if the first tool call in the response matches the expected tool call.    \"\"\"    # Expected tool call    expected_tool_call = 'sql_db_list_tables'    # Run    response = root_run.outputs[\"response\"]    # Get tool call    try:        tool_call = getattr(response, 'tool_calls', [])[0]['name']    except (IndexError, KeyError):        tool_call = None    score = 1 if tool_call == expected_tool_call else 0    return {\"score\": score, \"key\": \"single_tool_call\"}experiment_results = evaluate(    predict_assistant,    data=dataset_name,    evaluators=[check_specific_tool_call],    experiment_prefix=experiment_prefix + \"-single-tool\",    num_repetitions=3,    metadata={\"version\": metadata},)\nTrajectory​\nWe can check a trajectory of tool calls using custom evaluators:\n\nHere, we just invoke the agent, graph.invoke, with a prompt.\nHere, we are using a specialized agent where the tools are hard-coded (rather than passed with the dataset input).\nWe extract the list of tools called, using find_tool_calls.\nCustom functions can process these tool calls in various user-defined ways.\nWe can check if all expected tools are called in any order: contains_all_tool_calls_any_order\nWe can check if all expected tools are called in order, allowing for insertion of tool calls: contains_all_tool_calls_in_order\nWe can check if all expected tools are called in the exact order: contains_all_tool_calls_in_order_exact_match","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/how-tos/tool-calling-errors/","title":"How to handle tool calling errors | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/how-tos/tool-calling-errors/","uuid":"bf10eea6-a503-5365-89bd-b56388392380"},"page_content":"def call_model(state: MessagesState):\n    messages = state[\"messages\"]\n    response = model_with_tools.invoke(messages)\n    return {\"messages\": [response]}\n\ndef remove_failed_tool_call_attempt(state: MessagesState):\n    messages = state[\"messages\"]\n    # Remove all messages from the most recent\n    # instance of AIMessage onwards.\n    last_ai_message_index = next(\n        i\n        for i, msg in reversed(list(enumerate(messages)))\n        if isinstance(msg, AIMessage)\n    )\n    messages_to_remove = messages[last_ai_message_index:]\n    return {\"messages\": [RemoveMessage(id=m.id) for m in messages_to_remove]}\n\n# Fallback to a better model if a tool call fails\ndef call_fallback_model(state: MessagesState):\n    messages = state[\"messages\"]\n    response = better_model_with_tools.invoke(messages)\n    return {\"messages\": [response]}\n\nworkflow = StateGraph(MessagesState)\n\nworkflow.add_node(\"agent\", call_model)\nworkflow.add_node(\"tools\", call_tool)\nworkflow.add_node(\"remove_failed_tool_call_attempt\", remove_failed_tool_call_attempt)\nworkflow.add_node(\"fallback_agent\", call_fallback_model)\n\nworkflow.add_edge(START, \"agent\")\nworkflow.add_conditional_edges(\"agent\", should_continue, [\"tools\", END])\nworkflow.add_conditional_edges(\"tools\", should_fallback)\nworkflow.add_edge(\"remove_failed_tool_call_attempt\", \"fallback_agent\")\nworkflow.add_edge(\"fallback_agent\", \"tools\")\n\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ToolMessage | RemoveMessage\n\nThe tools node will now return ToolMessages with an error field in additional_kwargs if a tool call fails. If that happens, it will go to another node that removes the failed tool messages, and has a better model retry the tool call generation.\nThe diagram below shows this visually:\ntry:\n    display(Image(app.get_graph().draw_mermaid_png()))\nexcept Exception:\n    # This requires some extra dependencies and is optional\n    pass\n\nLet's try it out. To emphasize the removal steps, let's stream the responses from the model so that we can see each executed node:\nstream = app.stream(\n    {\"messages\": [(\"human\", \"Write me an incredible haiku about water.\")]},\n    {\"recursion_limit\": 10},\n)\n\nfor chunk in stream:\n    print(chunk)","type":"Document"},{"metadata":{"description":"Open In Colab","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/graphs/arangodb/","title":"ArangoDB | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/graphs/arangodb/","uuid":"705dd156-07bd-5eeb-839d-de58c178e7ad"},"page_content":"```output\n{'error': False,\n 'created': 4,\n 'errors': 0,\n 'empty': 0,\n 'updated': 0,\n 'ignored': 0,\n 'details': []}\n```\n\n## Getting and setting the ArangoDB schema​\n\nAn initial `ArangoDB Schema` is generated upon instantiating the `ArangoDBGraph` object. Below are the schema's getter & setter methods should you be interested in viewing or modifying the schema:\n\n```python\n# The schema should be empty here,\n# since `graph` was initialized prior to ArangoDB Data ingestion (see above).\n\nimport json\n\nprint(json.dumps(graph.schema, indent=4))\n```\n\n```output\n{\n    \"Graph Schema\": [],\n    \"Collection Schema\": []\n}\n```\n\n```python\ngraph.set_schema()\n```\n\n```python\n# We can now view the generated schema\n\nimport json\n\nprint(json.dumps(graph.schema, indent=4))\n```\n\n```output\n{\n    \"Graph Schema\": [\n        {\n            \"graph_name\": \"GameOfThrones\",\n            \"edge_definitions\": [\n                {\n                    \"edge_collection\": \"ChildOf\",\n                    \"from_vertex_collections\": [\n                        \"Characters\"\n                    ],\n                    \"to_vertex_collections\": [\n                        \"Characters\"\n                    ]\n                }\n            ]\n        }\n    ],\n    \"Collection Schema\": [\n        {\n            \"collection_name\": \"ChildOf\",\n            \"collection_type\": \"edge\",\n            \"edge_properties\": [\n                {\n                    \"name\": \"_key\",\n                    \"type\": \"str\"\n                },\n                {\n                    \"name\": \"_id\",\n                    \"type\": \"str\"\n                },\n                {\n                    \"name\": \"_from\",\n                    \"type\": \"str\"\n                },\n                {\n                    \"name\": \"_to\",\n                    \"type\": \"str\"\n                },\n                {\n                    \"name\": \"_rev\",\n                    \"type\": \"str\"\n                }\n            ],\n            \"example_edge\": {\n                \"_key\": \"266218884025\",\n                \"_id\": \"ChildOf/266218884025\",\n                \"_from\": \"Characters/AryaStark\",\n                \"_to\": \"Characters/NedStark\",\n                \"_rev\": \"_gVPKGSq---\"\n            }\n        },\n        {\n            \"collection_name\": \"Characters\",\n            \"collection_type\": \"document\",\n            \"document_properties\": [\n                {\n                    \"name\": \"_key\",\n                    \"type\": \"str\"\n                },\n                {\n                    \"name\": \"_id\",\n                    \"type\": \"str\"\n                },\n                {\n                    \"name\": \"_rev\",\n                    \"type\": \"str\"\n                },\n                {\n                    \"name\": \"name\",\n                    \"type\": \"str\"\n                },\n                {\n                    \"name\": \"surname\",\n                    \"type\": \"str\"\n                },\n                {\n                    \"name\": \"alive\",\n                    \"type\": \"bool\"\n                },\n                {\n                    \"name\": \"age\",\n                    \"type\": \"int\"\n                },\n                {\n                    \"name\": \"gender\",\n                    \"type\": \"str\"\n                }\n            ],\n            \"example_document\": {\n                \"_key\": \"NedStark\",\n                \"_id\": \"Characters/NedStark\",\n                \"_rev\": \"_gVPKGPi---\",\n                \"name\": \"Ned\",\n                \"surname\": \"Stark\",\n                \"alive\": true,\n                \"age\": 41,\n                \"gender\": \"male\"\n            }\n        }\n    ]\n}\n```\n\n## Querying the ArangoDB database​\n\nWe can now use the `ArangoDB Graph` QA Chain to inquire about our data\n\n```python\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"your-key-here\"\n```\n\n```python\nfrom langchain.chains import ArangoGraphQAChain\nfrom langchain_openai import ChatOpenAI\n\nchain = ArangoGraphQAChain.from_llm(\n    ChatOpenAI(temperature=0), graph=graph, verbose=True\n)\n```","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"fa656b44-33da-5c5c-93cb-163bf4a580c6"},"page_content":"----------------------------------------------------------------------------------------------------------------------------\n\n{\n    'graph_id': 'agent',\n    'state_schema':\n        {\n            'title': 'LangGraphInput',\n            '$ref': '#/definitions/AgentState',\n            'definitions':\n                {\n                    'BaseMessage':\n                        {\n                            'title': 'BaseMessage',\n                            'description': 'Base abstract Message class. Messages are the inputs and outputs of ChatModels.',\n                            'type': 'object',\n                            'properties':\n                                {\n                                 'content':\n                                    {\n                                        'title': 'Content',\n                                        'anyOf': [\n                                            {'type': 'string'},\n                                            {'type': 'array','items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}\n                                        ]\n                                    },\n                                'additional_kwargs':\n                                    {\n                                        'title': 'Additional Kwargs',\n                                        'type': 'object'\n                                    },\n                                'response_metadata':\n                                    {\n                                        'title': 'Response Metadata',\n                                        'type': 'object'\n                                    },\n                                'type':\n                                    {\n                                        'title': 'Type',\n                                        'type': 'string'\n                                    },\n                                'name':\n                                    {\n                                        'title': 'Name',\n                                        'type': 'string'\n                                    },\n                                'id':\n                                    {\n                                        'title': 'Id',\n                                        'type': 'string'\n                                    }\n                                },\n                            'required': ['content', 'type']\n                        },\n                    'AgentState':\n                        {\n                            'title': 'AgentState',\n                            'type': 'object',\n                            'properties':\n                                {\n                                    'messages':\n                                        {\n                                            'title': 'Messages',\n                                            'type': 'array',\n                                            'items': {'$ref': '#/definitions/BaseMessage'}\n                                        }\n                                },\n                            'required': ['messages']\n                        }\n                }\n        },\n    'config_schema':\n        {\n            'title': 'Configurable',\n            'type': 'object',\n            'properties':\n                {\n                    'model_name':\n                        {\n                            'title': 'Model Name',\n                            'enum': ['anthropic', 'openai'],\n                            'type': 'string'\n                        }\n                }\n        }\n}","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/deployment/setup_javascript/","title":"How to Set Up a LangGraph.js Application for Deployment | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/deployment/setup_javascript/","uuid":"8f99481b-3782-5ace-8467-ff996ce3bdb7"},"page_content":"How to Set Up a LangGraph.js Application for Deployment\n\nHow to Set Up a LangGraph.js Application for Deployment¶\nA LangGraph.js application must be configured with a LangGraph API configuration file in order to be deployed to LangGraph Cloud (or to be self-hosted). This how-to guide discusses the basic steps to setup a LangGraph.js application for deployment using package.json to specify project dependencies.\nThis walkthrough is based on this repository, which you can play around with to learn more about how to setup your LangGraph application for deployment.\nThe final repo structure will look something like this:\nmy-app/\n├── src # all project code lies within here\n│   ├── utils # optional utilities for your graph\n│   │   ├── tools.ts # tools for your graph\n│   │   ├── nodes.ts # node functions for you graph\n│   │   └── state.ts # state definition of your graph\n│   └── agent.ts # code for constructing your graph\n├── package.json # package dependencies\n├── .env # environment variables\n└── langgraph.json # configuration file for LangGraph\n\nAfter each step, an example file directory is provided to demonstrate how code can be organized.\nSpecify Dependencies¶\nDependencies can be specified in a package.json. If none of these files is created, then dependencies can be specified later in the LangGraph API configuration file.\nExample package.json file:\n{\n  \"name\": \"langgraphjs-studio-starter\",\n  \"packageManager\": \"yarn@1.22.22\",\n  \"dependencies\": {\n    \"@langchain/community\": \"^0.2.31\",\n    \"@langchain/core\": \"^0.2.31\",\n    \"@langchain/langgraph\": \"^0.2.0\",\n    \"@langchain/openai\": \"^0.2.8\"\n  }\n}\n\nExample file directory:\nmy-app/\n└── package.json # package dependencies\n\nSpecify Environment Variables¶\nEnvironment variables can optionally be specified in a file (e.g. .env). See the Environment Variables reference to configure additional variables for a deployment.\nExample .env file:\nMY_ENV_VAR_1=foo\nMY_ENV_VAR_2=bar\nOPENAI_API_KEY=key\nTAVILY_API_KEY=key_2\n\nExample file directory:\nmy-app/\n├── package.json\n└── .env # environment variables\n\nDefine Graphs¶\nImplement your graphs! Graphs can be defined in a single file or multiple files. Make note of the variable names of each compiled graph to be included in the LangGraph application. The variable names will be used later when creating the LangGraph API configuration file.\nHere is an example agent.ts:\nimport type { AIMessage } from \"@langchain/core/messages\";\nimport { TavilySearchResults } from \"@langchain/community/tools/tavily_search\";\nimport { ChatOpenAI } from \"@langchain/openai\";\n\nimport { MessagesAnnotation, StateGraph } from \"@langchain/langgraph\";\nimport { ToolNode } from \"@langchain/langgraph/prebuilt\";\n\nconst tools = [\n  new TavilySearchResults({ maxResults: 3, }),\n];\n\n// Define the function that calls the model\nasync function callModel(\n  state: typeof MessagesAnnotation.State,\n) {\n  /**\n   * Call the LLM powering our agent.\n   * Feel free to customize the prompt, model, and other logic!\n   */\n  const model = new ChatOpenAI({\n    model: \"gpt-4o\",\n  }).bindTools(tools);\n\n  const response = await model.invoke([\n    {\n      role: \"system\",\n      content: `You are a helpful assistant. The current date is ${new Date().getTime()}.`\n    },\n    ...state.messages\n  ]);\n\n  // MessagesAnnotation supports returning a single message or array of messages\n  return { messages: response };\n}\n\n// Define the function that determines whether to continue or not\nfunction routeModelOutput(state: typeof MessagesAnnotation.State) {\n  const messages = state.messages;\n  const lastMessage: AIMessage = messages[messages.length - 1];\n  // If the LLM is invoking tools, route there.\n  if ((lastMessage?.tool_calls?.length ?? 0) > 0) {\n    return \"tools\";\n  }\n  // Otherwise end the graph.\n  return \"__end__\";\n}","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"}],"answer":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","query":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","num_response_attempts":1}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":15,"langgraph_node":"create_research_plan","langgraph_triggers":["start:create_research_plan"],"langgraph_path":["__pregel_pull","create_research_plan"],"langgraph_checkpoint_ns":"create_research_plan:27533e1b-91d2-33b5-d487-e9bbc88d5f0e","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:15"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195929581985Z3a323f66-f558-4195-8318-256c2cabb3ca"}
{"id":"3a323f66-f558-4195-8318-256c2cabb3ca","name":"create_research_plan","end_time":"2024-12-04T19:59:31.162025","error":null,"outputs":{"steps":["Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."],"documents":"delete","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":0}}
{"id":"6f02dfd0-2e62-4e11-b6a1-b11b0005fbf5","name":"RunnableSequence","start_time":"2024-12-04T19:59:29.684864","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:29.684864+00:00"},{"name":"end","time":"2024-12-04T19:59:31.147207+00:00"}],"inputs":{"input":[{"role":"system","content":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful."},{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":15,"langgraph_node":"create_research_plan","langgraph_triggers":["start:create_research_plan"],"langgraph_path":["__pregel_pull","create_research_plan"],"langgraph_checkpoint_ns":"create_research_plan:27533e1b-91d2-33b5-d487-e9bbc88d5f0e","checkpoint_ns":"create_research_plan:27533e1b-91d2-33b5-d487-e9bbc88d5f0e","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195929581985Z3a323f66-f558-4195-8318-256c2cabb3ca.20241204T195929684864Z6f02dfd0-2e62-4e11-b6a1-b11b0005fbf5"}
{"id":"6f02dfd0-2e62-4e11-b6a1-b11b0005fbf5","name":"RunnableSequence","end_time":"2024-12-04T19:59:31.147207","error":null,"outputs":{"steps":["Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."]}}
{"id":"53569791-32cd-4c07-985b-e775c1de8f05","name":"ChatOpenAI","start_time":"2024-12-04T19:59:29.690211","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:29.690211+00:00"},{"name":"new_token","time":"2024-12-04T19:59:30.484797+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.489110+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.493130+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.496826+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.502156+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.506923+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.511681+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.516978+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.602435+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.607574+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.611574+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.615368+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.619811+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.624990+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.631294+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.636148+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.640950+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.646383+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.651583+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.657040+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.662779+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.667708+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.673356+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.680671+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.687912+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.696584+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.703960+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.709256+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.717657+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.723441+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.729263+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.734502+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.740732+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.745796+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.751599+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.756530+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.769682+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.776273+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.782976+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.789464+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.796868+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.802440+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.826550+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.832248+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.838652+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.844443+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.850509+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.855522+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.872957+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.878550+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.886300+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.891214+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.896983+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.901879+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.908180+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.912437+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.923406+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.928527+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.934966+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.940701+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.968150+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.973350+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.989338+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:30.995068+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.007178+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.012293+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.022407+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.028044+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.034849+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.039787+00:00","kwargs":{"token":""}},{"name":"end","time":"2024-12-04T19:59:31.051257+00:00"}],"inputs":{"messages":[[{"lc":1,"type":"constructor","id":["langchain","schema","messages","SystemMessage"],"kwargs":{"content":"You are a LangChain expert and a world-class researcher, here to assist with any and all questions or issues with LangChain, LangGraph, LangSmith, or any related functionality. Users may come to you with questions or issues.\n\nBased on the conversation below, generate a plan for how you will research the answer to their question.\n\nThe plan should generally not be more than 3 steps long, it can be as short as one. The length of the plan depends on the question.\n\nYou have access to the following documentation sources:\n- Conceptual docs\n- Integration docs\n- How-to guides\n\nYou do not need to specify where you want to research for all steps of the plan, but it's sometimes helpful.","type":"system"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","tool_calls":[],"invalid_tool_calls":[]}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","tool_calls":[],"invalid_tool_calls":[]}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd"}}]]},"run_type":"llm","extra":{"invocation_params":{"model":"gpt-4o-mini","model_name":"gpt-4o-mini","stream":false,"n":1,"temperature":0.0,"_type":"openai-chat","stop":null,"tools":[{"type":"function","function":{"name":"Plan","description":"Generate research plan.","parameters":{"type":"object","properties":{"steps":{"type":"array","items":{"type":"string"}}},"required":["steps"]}}}],"parallel_tool_calls":false,"tool_choice":{"type":"function","function":{"name":"Plan"}}},"options":{"stop":null},"batch_size":1,"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":15,"langgraph_node":"create_research_plan","langgraph_triggers":["start:create_research_plan"],"langgraph_path":["__pregel_pull","create_research_plan"],"langgraph_checkpoint_ns":"create_research_plan:27533e1b-91d2-33b5-d487-e9bbc88d5f0e","checkpoint_ns":"create_research_plan:27533e1b-91d2-33b5-d487-e9bbc88d5f0e","ls_provider":"openai","ls_model_name":"gpt-4o-mini","ls_model_type":"chat","ls_temperature":0.0,"LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195929581985Z3a323f66-f558-4195-8318-256c2cabb3ca.20241204T195929684864Z6f02dfd0-2e62-4e11-b6a1-b11b0005fbf5.20241204T195929690211Z53569791-32cd-4c07-985b-e775c1de8f05"}
{"id":"53569791-32cd-4c07-985b-e775c1de8f05","name":"ChatOpenAI","end_time":"2024-12-04T19:59:31.051257","error":null,"outputs":{"generations":[{"text":"","generation_info":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_3de1288069"},"type":"ChatGeneration","message":{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_M9wrxDkTi5Z7vjbfyv45Jlok","function":{"arguments":"{\"steps\":[\"Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.\",\"Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.\",\"Test the workflow with a simplified version of the JSON configuration to isolate the issue.\"]}","name":"Plan"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_3de1288069"},"type":"ai","id":"run-53569791-32cd-4c07-985b-e775c1de8f05","tool_calls":[{"name":"Plan","args":{"steps":["Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."]},"id":"call_M9wrxDkTi5Z7vjbfyv45Jlok","type":"tool_call"}],"invalid_tool_calls":[]}}}],"llm_output":null,"run":null,"type":"LLMResult"}}
{"id":"7cacf9a1-31ea-4983-a350-c3290f227c7b","name":"JsonOutputKeyToolsParser","start_time":"2024-12-04T19:59:31.060057","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:31.060057+00:00"},{"name":"end","time":"2024-12-04T19:59:31.141933+00:00"}],"inputs":{"input":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_M9wrxDkTi5Z7vjbfyv45Jlok","function":{"arguments":"{\"steps\":[\"Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.\",\"Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.\",\"Test the workflow with a simplified version of the JSON configuration to isolate the issue.\"]}","name":"Plan"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_3de1288069"},"type":"ai","id":"run-53569791-32cd-4c07-985b-e775c1de8f05","example":false,"tool_calls":[{"name":"Plan","args":{"steps":["Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."]},"id":"call_M9wrxDkTi5Z7vjbfyv45Jlok","type":"tool_call"}],"invalid_tool_calls":[]}},"run_type":"parser","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":15,"langgraph_node":"create_research_plan","langgraph_triggers":["start:create_research_plan"],"langgraph_path":["__pregel_pull","create_research_plan"],"langgraph_checkpoint_ns":"create_research_plan:27533e1b-91d2-33b5-d487-e9bbc88d5f0e","checkpoint_ns":"create_research_plan:27533e1b-91d2-33b5-d487-e9bbc88d5f0e","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195929581985Z3a323f66-f558-4195-8318-256c2cabb3ca.20241204T195929684864Z6f02dfd0-2e62-4e11-b6a1-b11b0005fbf5.20241204T195931060057Z7cacf9a1-31ea-4983-a350-c3290f227c7b"}
{"id":"7cacf9a1-31ea-4983-a350-c3290f227c7b","name":"JsonOutputKeyToolsParser","end_time":"2024-12-04T19:59:31.141933","error":null,"outputs":{"steps":["Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."]}}
{"id":"ad58ecd3-0206-417c-850c-e9f252139f57","name":"_write","start_time":"2024-12-04T19:59:31.151677","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:31.151677+00:00"},{"name":"end","time":"2024-12-04T19:59:31.155925+00:00"}],"inputs":{"steps":["Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."],"documents":"delete","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":0},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":15,"langgraph_node":"create_research_plan","langgraph_triggers":["start:create_research_plan"],"langgraph_path":["__pregel_pull","create_research_plan"],"langgraph_checkpoint_ns":"create_research_plan:27533e1b-91d2-33b5-d487-e9bbc88d5f0e","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195929581985Z3a323f66-f558-4195-8318-256c2cabb3ca.20241204T195931151677Zad58ecd3-0206-417c-850c-e9f252139f57"}
{"id":"ad58ecd3-0206-417c-850c-e9f252139f57","name":"_write","end_time":"2024-12-04T19:59:31.155925","error":null,"outputs":{"steps":["Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."],"documents":"delete","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":0}}
{"id":"6ff67b1e-a657-4440-a9a4-dc915bf0d334","name":"conduct_research","start_time":"2024-12-04T19:59:31.168340","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:31.168340+00:00"},{"name":"end","time":"2024-12-04T19:59:35.172158+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false}],"router":{"type":"general","logic":""},"steps":["Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."],"documents":[],"answer":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":0}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":16,"langgraph_node":"conduct_research","langgraph_triggers":["create_research_plan"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:16"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334"}
{"id":"6ff67b1e-a657-4440-a9a4-dc915bf0d334","name":"conduct_research","end_time":"2024-12-04T19:59:35.172158","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"}],"steps":["Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."]}}
{"id":"f7ad6074-447d-4073-8543-021e5ac493c5","name":"ResearcherGraph","start_time":"2024-12-04T19:59:31.172724","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:31.172724+00:00"},{"name":"end","time":"2024-12-04T19:59:34.964648+00:00"}],"inputs":{"question":"Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring."},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":16,"langgraph_node":"conduct_research","langgraph_triggers":["create_research_plan"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5"}
{"id":"f7ad6074-447d-4073-8543-021e5ac493c5","name":"ResearcherGraph","end_time":"2024-12-04T19:59:34.964648","error":null,"outputs":{"question":"Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","queries":["function signature of process_claims_query","process_claims_query argument descriptions","docstring of process_claims_query function"],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"}]}}
{"id":"211fa294-be51-4a59-8798-943139aed062","name":"__start__","start_time":"2024-12-04T19:59:31.183569","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:31.183569+00:00"},{"name":"end","time":"2024-12-04T19:59:31.190073+00:00"}],"inputs":{"question":"Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring."},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":0,"langgraph_node":"__start__","langgraph_triggers":["__start__"],"langgraph_path":["__pregel_pull","__start__"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|__start__:8c4abb84-a608-5f58-b09f-88be1584ca8d","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","graph:step:0"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195931183569Z211fa294-be51-4a59-8798-943139aed062"}
{"id":"211fa294-be51-4a59-8798-943139aed062","name":"__start__","end_time":"2024-12-04T19:59:31.190073","error":null,"outputs":{"question":"Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring."}}
{"id":"3a83a26f-ff22-44e9-a21f-491e62cf8386","name":"generate_queries","start_time":"2024-12-04T19:59:31.194730","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:31.194730+00:00"},{"name":"end","time":"2024-12-04T19:59:32.509976+00:00"}],"inputs":{"input":{"question":"Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","queries":[],"documents":[]}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|generate_queries:64a184ed-e009-994a-ef49-5d9f67591cdd","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195931194730Z3a83a26f-ff22-44e9-a21f-491e62cf8386"}
{"id":"3a83a26f-ff22-44e9-a21f-491e62cf8386","name":"generate_queries","end_time":"2024-12-04T19:59:32.509976","error":null,"outputs":{"queries":["function signature of process_claims_query","process_claims_query argument descriptions","docstring of process_claims_query function"]}}
{"id":"a26988f3-ccc8-4adc-b791-660357dde3ce","name":"RunnableSequence","start_time":"2024-12-04T19:59:31.302656","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:31.302656+00:00"},{"name":"end","time":"2024-12-04T19:59:32.311651+00:00"}],"inputs":{"input":[{"role":"system","content":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones."},{"role":"human","content":"Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring."}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|generate_queries:64a184ed-e009-994a-ef49-5d9f67591cdd","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195931194730Z3a83a26f-ff22-44e9-a21f-491e62cf8386.20241204T195931302656Za26988f3-ccc8-4adc-b791-660357dde3ce"}
{"id":"a26988f3-ccc8-4adc-b791-660357dde3ce","name":"RunnableSequence","end_time":"2024-12-04T19:59:32.311651","error":null,"outputs":{"queries":["function signature of process_claims_query","process_claims_query argument descriptions","docstring of process_claims_query function"]}}
{"id":"4cd3d44d-c525-4a2d-8a2c-57b56ac3f5c8","name":"ChatOpenAI","start_time":"2024-12-04T19:59:31.311342","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:31.311342+00:00"},{"name":"new_token","time":"2024-12-04T19:59:31.926198+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.931425+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.937430+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.942109+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.954672+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.959987+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.966154+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.971694+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.989917+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.993848+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:31.999394+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.004011+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.035673+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.041044+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.052309+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.057393+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.061663+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.065457+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.070670+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.076492+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.091066+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.096189+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.128116+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.133021+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.138001+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.142012+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.168102+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.174292+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.180306+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:32.185301+00:00","kwargs":{"token":""}},{"name":"end","time":"2024-12-04T19:59:32.194109+00:00"}],"inputs":{"messages":[[{"lc":1,"type":"constructor","id":["langchain","schema","messages","SystemMessage"],"kwargs":{"content":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","type":"system"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","type":"human"}}]]},"run_type":"llm","extra":{"invocation_params":{"model":"gpt-4o-mini","model_name":"gpt-4o-mini","stream":false,"n":1,"temperature":0.0,"_type":"openai-chat","stop":null,"tools":[{"type":"function","function":{"name":"Response","description":"dict() -> new empty dictionary\ndict(mapping) -> new dictionary initialized from a mapping object's\n    (key, value) pairs\ndict(iterable) -> new dictionary initialized as if via:\n    d = {}\n    for k, v in iterable:\n        d[k] = v\ndict(**kwargs) -> new dictionary initialized with the name=value pairs\n    in the keyword argument list.  For example:  dict(one=1, two=2)","parameters":{"type":"object","properties":{"queries":{"type":"array","items":{"type":"string"}}},"required":["queries"]}}}],"parallel_tool_calls":false,"tool_choice":{"type":"function","function":{"name":"Response"}}},"options":{"stop":null},"batch_size":1,"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|generate_queries:64a184ed-e009-994a-ef49-5d9f67591cdd","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","ls_provider":"openai","ls_model_name":"gpt-4o-mini","ls_model_type":"chat","ls_temperature":0.0,"LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195931194730Z3a83a26f-ff22-44e9-a21f-491e62cf8386.20241204T195931302656Za26988f3-ccc8-4adc-b791-660357dde3ce.20241204T195931311342Z4cd3d44d-c525-4a2d-8a2c-57b56ac3f5c8"}
{"id":"4cd3d44d-c525-4a2d-8a2c-57b56ac3f5c8","name":"ChatOpenAI","end_time":"2024-12-04T19:59:32.194109","error":null,"outputs":{"generations":[{"text":"","generation_info":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ChatGeneration","message":{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_15FCR8QBIapaJC4wST7nJPDE","function":{"arguments":"{\"queries\":[\"function signature of process_claims_query\",\"process_claims_query argument descriptions\",\"docstring of process_claims_query function\"]}","name":"Response"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-4cd3d44d-c525-4a2d-8a2c-57b56ac3f5c8","tool_calls":[{"name":"Response","args":{"queries":["function signature of process_claims_query","process_claims_query argument descriptions","docstring of process_claims_query function"]},"id":"call_15FCR8QBIapaJC4wST7nJPDE","type":"tool_call"}],"invalid_tool_calls":[]}}}],"llm_output":null,"run":null,"type":"LLMResult"}}
{"id":"6b224df6-e0e6-45f4-8228-c8c1bf896363","name":"JsonOutputKeyToolsParser","start_time":"2024-12-04T19:59:32.201086","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:32.201086+00:00"},{"name":"end","time":"2024-12-04T19:59:32.304402+00:00"}],"inputs":{"input":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_15FCR8QBIapaJC4wST7nJPDE","function":{"arguments":"{\"queries\":[\"function signature of process_claims_query\",\"process_claims_query argument descriptions\",\"docstring of process_claims_query function\"]}","name":"Response"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-4cd3d44d-c525-4a2d-8a2c-57b56ac3f5c8","example":false,"tool_calls":[{"name":"Response","args":{"queries":["function signature of process_claims_query","process_claims_query argument descriptions","docstring of process_claims_query function"]},"id":"call_15FCR8QBIapaJC4wST7nJPDE","type":"tool_call"}],"invalid_tool_calls":[]}},"run_type":"parser","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|generate_queries:64a184ed-e009-994a-ef49-5d9f67591cdd","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195931194730Z3a83a26f-ff22-44e9-a21f-491e62cf8386.20241204T195931302656Za26988f3-ccc8-4adc-b791-660357dde3ce.20241204T195932201086Z6b224df6-e0e6-45f4-8228-c8c1bf896363"}
{"id":"6b224df6-e0e6-45f4-8228-c8c1bf896363","name":"JsonOutputKeyToolsParser","end_time":"2024-12-04T19:59:32.304402","error":null,"outputs":{"queries":["function signature of process_claims_query","process_claims_query argument descriptions","docstring of process_claims_query function"]}}
{"id":"4dedd497-b27b-4103-822c-5694516dd9bb","name":"_write","start_time":"2024-12-04T19:59:32.317023","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:32.317023+00:00"},{"name":"end","time":"2024-12-04T19:59:32.321301+00:00"}],"inputs":{"queries":["function signature of process_claims_query","process_claims_query argument descriptions","docstring of process_claims_query function"]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|generate_queries:64a184ed-e009-994a-ef49-5d9f67591cdd","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195931194730Z3a83a26f-ff22-44e9-a21f-491e62cf8386.20241204T195932317023Z4dedd497-b27b-4103-822c-5694516dd9bb"}
{"id":"4dedd497-b27b-4103-822c-5694516dd9bb","name":"_write","end_time":"2024-12-04T19:59:32.321301","error":null,"outputs":{"queries":["function signature of process_claims_query","process_claims_query argument descriptions","docstring of process_claims_query function"]}}
{"id":"a931cb12-51f5-4bdd-8b4e-a5f7469ef08f","name":"retrieve_in_parallel","start_time":"2024-12-04T19:59:32.493515","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:32.493515+00:00"},{"name":"end","time":"2024-12-04T19:59:32.502999+00:00"}],"inputs":{"input":{"question":"Review the function signature of the tool 'process_claims_query' to ensure it matches the argument descriptions in the docstring.","queries":["function signature of process_claims_query","process_claims_query argument descriptions","docstring of process_claims_query function"],"documents":[]}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|generate_queries:64a184ed-e009-994a-ef49-5d9f67591cdd","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:4"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195931194730Z3a83a26f-ff22-44e9-a21f-491e62cf8386.20241204T195932493515Za931cb12-51f5-4bdd-8b4e-a5f7469ef08f"}
{"id":"a931cb12-51f5-4bdd-8b4e-a5f7469ef08f","name":"retrieve_in_parallel","end_time":"2024-12-04T19:59:32.502999","error":null,"outputs":{"output":["Send(node='retrieve_documents', arg=QueryState(query='function signature of process_claims_query'))","Send(node='retrieve_documents', arg=QueryState(query='process_claims_query argument descriptions'))","Send(node='retrieve_documents', arg=QueryState(query='docstring of process_claims_query function'))"]}}
{"id":"e8d09223-0c52-4e3f-ad0e-e7698d57a18b","name":"retrieve_documents","start_time":"2024-12-04T19:59:32.516009","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:32.516009+00:00"},{"name":"end","time":"2024-12-04T19:59:34.585705+00:00"}],"inputs":{"input":{"query":"function signature of process_claims_query"}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",0],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|retrieve_documents:c40f13ad-dadf-2aad-640c-e0fd9e1b4df5","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195932516009Ze8d09223-0c52-4e3f-ad0e-e7698d57a18b"}
{"id":"e8d09223-0c52-4e3f-ad0e-e7698d57a18b","name":"retrieve_documents","end_time":"2024-12-04T19:59:34.585705","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"}]}}
{"id":"83d527a0-6e10-44f2-b583-e87ddebaa65a","name":"VectorStoreRetriever","start_time":"2024-12-04T19:59:32.889441","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:32.889441+00:00"},{"name":"end","time":"2024-12-04T19:59:34.548098+00:00"}],"inputs":{"query":"function signature of process_claims_query"},"run_type":"retriever","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",0],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|retrieve_documents:c40f13ad-dadf-2aad-640c-e0fd9e1b4df5","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","ls_retriever_name":"vectorstore","ls_vector_store_provider":"WeaviateVectorStore","ls_embedding_provider":"OpenAIEmbeddings","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["OpenAIEmbeddings","WeaviateVectorStore","seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195932516009Ze8d09223-0c52-4e3f-ad0e-e7698d57a18b.20241204T195932889441Z83d527a0-6e10-44f2-b583-e87ddebaa65a"}
{"id":"83d527a0-6e10-44f2-b583-e87ddebaa65a","name":"VectorStoreRetriever","end_time":"2024-12-04T19:59:34.548098","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"}]}}
{"id":"b043af92-26b9-4f84-9414-e4a9d57a918c","name":"_write","start_time":"2024-12-04T19:59:34.569791","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:34.569791+00:00"},{"name":"end","time":"2024-12-04T19:59:34.577109+00:00"}],"inputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",0],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|retrieve_documents:c40f13ad-dadf-2aad-640c-e0fd9e1b4df5","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195932516009Ze8d09223-0c52-4e3f-ad0e-e7698d57a18b.20241204T195934569791Zb043af92-26b9-4f84-9414-e4a9d57a918c"}
{"id":"b043af92-26b9-4f84-9414-e4a9d57a918c","name":"_write","end_time":"2024-12-04T19:59:34.577109","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"}]}}
{"id":"ec22dfe4-8d53-4e8b-8720-a1a5ea3c6420","name":"retrieve_documents","start_time":"2024-12-04T19:59:32.517292","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:32.517292+00:00"},{"name":"end","time":"2024-12-04T19:59:34.586591+00:00"}],"inputs":{"input":{"query":"process_claims_query argument descriptions"}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",1],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|retrieve_documents:c404d379-0039-8881-a76c-ad42dac2f2e8","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195932517292Zec22dfe4-8d53-4e8b-8720-a1a5ea3c6420"}
{"id":"ec22dfe4-8d53-4e8b-8720-a1a5ea3c6420","name":"retrieve_documents","end_time":"2024-12-04T19:59:34.586591","error":null,"outputs":{"documents":[{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"}]}}
{"id":"4bd3009b-cc18-4fb6-861a-c68b977c1227","name":"VectorStoreRetriever","start_time":"2024-12-04T19:59:33.208328","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:33.208328+00:00"},{"name":"end","time":"2024-12-04T19:59:34.548658+00:00"}],"inputs":{"query":"process_claims_query argument descriptions"},"run_type":"retriever","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",1],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|retrieve_documents:c404d379-0039-8881-a76c-ad42dac2f2e8","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","ls_retriever_name":"vectorstore","ls_vector_store_provider":"WeaviateVectorStore","ls_embedding_provider":"OpenAIEmbeddings","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["OpenAIEmbeddings","WeaviateVectorStore","seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195932517292Zec22dfe4-8d53-4e8b-8720-a1a5ea3c6420.20241204T195933208328Z4bd3009b-cc18-4fb6-861a-c68b977c1227"}
{"id":"4bd3009b-cc18-4fb6-861a-c68b977c1227","name":"VectorStoreRetriever","end_time":"2024-12-04T19:59:34.548658","error":null,"outputs":{"documents":[{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"}]}}
{"id":"f57676d7-fe2f-46c2-906c-a173ca8abd50","name":"_write","start_time":"2024-12-04T19:59:34.571423","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:34.571423+00:00"},{"name":"end","time":"2024-12-04T19:59:34.578031+00:00"}],"inputs":{"documents":[{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",1],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|retrieve_documents:c404d379-0039-8881-a76c-ad42dac2f2e8","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195932517292Zec22dfe4-8d53-4e8b-8720-a1a5ea3c6420.20241204T195934571423Zf57676d7-fe2f-46c2-906c-a173ca8abd50"}
{"id":"f57676d7-fe2f-46c2-906c-a173ca8abd50","name":"_write","end_time":"2024-12-04T19:59:34.578031","error":null,"outputs":{"documents":[{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"}]}}
{"id":"26a0efeb-4ac4-4e07-8524-035184911c60","name":"retrieve_documents","start_time":"2024-12-04T19:59:32.518415","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:32.518415+00:00"},{"name":"end","time":"2024-12-04T19:59:34.922899+00:00"}],"inputs":{"input":{"query":"docstring of process_claims_query function"}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",2],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|retrieve_documents:d9195333-e349-bc84-69fb-c04ab3fff054","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195932518415Z26a0efeb-4ac4-4e07-8524-035184911c60"}
{"id":"26a0efeb-4ac4-4e07-8524-035184911c60","name":"retrieve_documents","end_time":"2024-12-04T19:59:34.922899","error":null,"outputs":{"documents":[{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"}]}}
{"id":"dce1f045-2718-486b-90e9-9af584266ac0","name":"VectorStoreRetriever","start_time":"2024-12-04T19:59:33.536942","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:33.536942+00:00"},{"name":"end","time":"2024-12-04T19:59:34.890643+00:00"}],"inputs":{"query":"docstring of process_claims_query function"},"run_type":"retriever","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",2],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|retrieve_documents:d9195333-e349-bc84-69fb-c04ab3fff054","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","ls_retriever_name":"vectorstore","ls_vector_store_provider":"WeaviateVectorStore","ls_embedding_provider":"OpenAIEmbeddings","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["OpenAIEmbeddings","WeaviateVectorStore","seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195932518415Z26a0efeb-4ac4-4e07-8524-035184911c60.20241204T195933536942Zdce1f045-2718-486b-90e9-9af584266ac0"}
{"id":"dce1f045-2718-486b-90e9-9af584266ac0","name":"VectorStoreRetriever","end_time":"2024-12-04T19:59:34.890643","error":null,"outputs":{"documents":[{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"}]}}
{"id":"17092867-b5ec-4bad-8a8a-cd95357c2a5c","name":"_write","start_time":"2024-12-04T19:59:34.905395","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:34.905395+00:00"},{"name":"end","time":"2024-12-04T19:59:34.914498+00:00"}],"inputs":{"documents":[{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",2],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a|retrieve_documents:d9195333-e349-bc84-69fb-c04ab3fff054","checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195931172724Zf7ad6074-447d-4073-8543-021e5ac493c5.20241204T195932518415Z26a0efeb-4ac4-4e07-8524-035184911c60.20241204T195934905395Z17092867-b5ec-4bad-8a8a-cd95357c2a5c"}
{"id":"17092867-b5ec-4bad-8a8a-cd95357c2a5c","name":"_write","end_time":"2024-12-04T19:59:34.914498","error":null,"outputs":{"documents":[{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"}]}}
{"id":"ca8d980a-b4e0-4dba-918a-1b8ce8636685","name":"_write","start_time":"2024-12-04T19:59:34.970109","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:34.970109+00:00"},{"name":"end","time":"2024-12-04T19:59:34.975310+00:00"}],"inputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"}],"steps":["Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":16,"langgraph_node":"conduct_research","langgraph_triggers":["create_research_plan"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195934970109Zca8d980a-b4e0-4dba-918a-1b8ce8636685"}
{"id":"ca8d980a-b4e0-4dba-918a-1b8ce8636685","name":"_write","end_time":"2024-12-04T19:59:34.975310","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"}],"steps":["Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."]}}
{"id":"bca2e238-6c51-41fa-9fa1-5dffe982ec36","name":"check_finished","start_time":"2024-12-04T19:59:35.153842","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:35.153842+00:00"},{"name":"end","time":"2024-12-04T19:59:35.165106+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false}],"router":{"type":"general","logic":""},"steps":["Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"}],"answer":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":0}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":16,"langgraph_node":"conduct_research","langgraph_triggers":["create_research_plan"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:273717f8-c4b2-d32a-54a1-14c9ff0cac2a","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:4"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195931168340Z6ff67b1e-a657-4440-a9a4-dc915bf0d334.20241204T195935153842Zbca2e238-6c51-41fa-9fa1-5dffe982ec36"}
{"id":"bca2e238-6c51-41fa-9fa1-5dffe982ec36","name":"check_finished","end_time":"2024-12-04T19:59:35.165106","error":null,"outputs":{"output":"conduct_research"}}
{"id":"b3ba2815-689b-4d05-85d6-5ea2d12cafab","name":"conduct_research","start_time":"2024-12-04T19:59:35.178124","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:35.178124+00:00"},{"name":"end","time":"2024-12-04T19:59:40.261937+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false}],"router":{"type":"general","logic":""},"steps":["Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","Test the workflow with a simplified version of the JSON configuration to isolate the issue."],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"}],"answer":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":0}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":17,"langgraph_node":"conduct_research","langgraph_triggers":["branch:conduct_research:check_finished:conduct_research"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:17"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab"}
{"id":"b3ba2815-689b-4d05-85d6-5ea2d12cafab","name":"conduct_research","end_time":"2024-12-04T19:59:40.261937","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"}],"steps":["Test the workflow with a simplified version of the JSON configuration to isolate the issue."]}}
{"id":"a6fe296b-d903-48d9-b13a-d7081db1495f","name":"ResearcherGraph","start_time":"2024-12-04T19:59:35.182742","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:35.182742+00:00"},{"name":"end","time":"2024-12-04T19:59:40.146701+00:00"}],"inputs":{"question":"Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature."},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":17,"langgraph_node":"conduct_research","langgraph_triggers":["branch:conduct_research:check_finished:conduct_research"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f"}
{"id":"a6fe296b-d903-48d9-b13a-d7081db1495f","name":"ResearcherGraph","end_time":"2024-12-04T19:59:40.146701","error":null,"outputs":{"question":"Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","queries":["how to check tool registration in workflow","confirming tool signature in workflow","troubleshooting tool registration issues in workflows"],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"}]}}
{"id":"bd8af8f5-415c-4cb9-a005-f5807889b31d","name":"__start__","start_time":"2024-12-04T19:59:35.194379","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:35.194379+00:00"},{"name":"end","time":"2024-12-04T19:59:35.199543+00:00"}],"inputs":{"question":"Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature."},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":0,"langgraph_node":"__start__","langgraph_triggers":["__start__"],"langgraph_path":["__pregel_pull","__start__"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|__start__:6d897f22-b479-0612-3675-f7912a98af1d","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","graph:step:0"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195935194379Zbd8af8f5-415c-4cb9-a005-f5807889b31d"}
{"id":"bd8af8f5-415c-4cb9-a005-f5807889b31d","name":"__start__","end_time":"2024-12-04T19:59:35.199543","error":null,"outputs":{"question":"Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature."}}
{"id":"c20cc4f1-afb2-44d0-bff6-86a89b092c3c","name":"generate_queries","start_time":"2024-12-04T19:59:35.203789","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:35.203789+00:00"},{"name":"end","time":"2024-12-04T19:59:37.011962+00:00"}],"inputs":{"input":{"question":"Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","queries":[],"documents":[]}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|generate_queries:6db7899b-3e6d-5f16-70d0-dd31bb91f8a0","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195935203789Zc20cc4f1-afb2-44d0-bff6-86a89b092c3c"}
{"id":"c20cc4f1-afb2-44d0-bff6-86a89b092c3c","name":"generate_queries","end_time":"2024-12-04T19:59:37.011962","error":null,"outputs":{"queries":["how to check tool registration in workflow","confirming tool signature in workflow","troubleshooting tool registration issues in workflows"]}}
{"id":"a719c5b3-355d-4003-a76a-c6e9f80d146d","name":"RunnableSequence","start_time":"2024-12-04T19:59:35.314602","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:35.314602+00:00"},{"name":"end","time":"2024-12-04T19:59:36.232592+00:00"}],"inputs":{"input":[{"role":"system","content":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones."},{"role":"human","content":"Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature."}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|generate_queries:6db7899b-3e6d-5f16-70d0-dd31bb91f8a0","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195935203789Zc20cc4f1-afb2-44d0-bff6-86a89b092c3c.20241204T195935314602Za719c5b3-355d-4003-a76a-c6e9f80d146d"}
{"id":"a719c5b3-355d-4003-a76a-c6e9f80d146d","name":"RunnableSequence","end_time":"2024-12-04T19:59:36.232592","error":null,"outputs":{"queries":["how to check tool registration in workflow","confirming tool signature in workflow","troubleshooting tool registration issues in workflows"]}}
{"id":"ab4eac97-1521-4396-a766-62be4648e7d5","name":"ChatOpenAI","start_time":"2024-12-04T19:59:35.326279","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:35.326279+00:00"},{"name":"new_token","time":"2024-12-04T19:59:35.784957+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.790231+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.796696+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.800760+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.806764+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.811369+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.819762+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.824533+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.839751+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.843674+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.853694+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.858557+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.880551+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.886306+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.891553+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.896186+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.905541+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.910040+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.923046+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.928096+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.936647+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.941081+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.959744+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:35.964988+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:36.012291+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:36.017518+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:36.032538+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:36.037811+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:36.045510+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:36.050244+00:00","kwargs":{"token":""}},{"name":"end","time":"2024-12-04T19:59:36.059143+00:00"}],"inputs":{"messages":[[{"lc":1,"type":"constructor","id":["langchain","schema","messages","SystemMessage"],"kwargs":{"content":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","type":"system"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","type":"human"}}]]},"run_type":"llm","extra":{"invocation_params":{"model":"gpt-4o-mini","model_name":"gpt-4o-mini","stream":false,"n":1,"temperature":0.0,"_type":"openai-chat","stop":null,"tools":[{"type":"function","function":{"name":"Response","description":"dict() -> new empty dictionary\ndict(mapping) -> new dictionary initialized from a mapping object's\n    (key, value) pairs\ndict(iterable) -> new dictionary initialized as if via:\n    d = {}\n    for k, v in iterable:\n        d[k] = v\ndict(**kwargs) -> new dictionary initialized with the name=value pairs\n    in the keyword argument list.  For example:  dict(one=1, two=2)","parameters":{"type":"object","properties":{"queries":{"type":"array","items":{"type":"string"}}},"required":["queries"]}}}],"parallel_tool_calls":false,"tool_choice":{"type":"function","function":{"name":"Response"}}},"options":{"stop":null},"batch_size":1,"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|generate_queries:6db7899b-3e6d-5f16-70d0-dd31bb91f8a0","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","ls_provider":"openai","ls_model_name":"gpt-4o-mini","ls_model_type":"chat","ls_temperature":0.0,"LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195935203789Zc20cc4f1-afb2-44d0-bff6-86a89b092c3c.20241204T195935314602Za719c5b3-355d-4003-a76a-c6e9f80d146d.20241204T195935326279Zab4eac97-1521-4396-a766-62be4648e7d5"}
{"id":"ab4eac97-1521-4396-a766-62be4648e7d5","name":"ChatOpenAI","end_time":"2024-12-04T19:59:36.059143","error":null,"outputs":{"generations":[{"text":"","generation_info":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ChatGeneration","message":{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_NdsKBLRRFrscluW0mJ3jpE3F","function":{"arguments":"{\"queries\":[\"how to check tool registration in workflow\",\"confirming tool signature in workflow\",\"troubleshooting tool registration issues in workflows\"]}","name":"Response"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-ab4eac97-1521-4396-a766-62be4648e7d5","tool_calls":[{"name":"Response","args":{"queries":["how to check tool registration in workflow","confirming tool signature in workflow","troubleshooting tool registration issues in workflows"]},"id":"call_NdsKBLRRFrscluW0mJ3jpE3F","type":"tool_call"}],"invalid_tool_calls":[]}}}],"llm_output":null,"run":null,"type":"LLMResult"}}
{"id":"a7b8e03a-958c-4539-8eb9-bb4914b79f5b","name":"JsonOutputKeyToolsParser","start_time":"2024-12-04T19:59:36.066402","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:36.066402+00:00"},{"name":"end","time":"2024-12-04T19:59:36.226409+00:00"}],"inputs":{"input":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_NdsKBLRRFrscluW0mJ3jpE3F","function":{"arguments":"{\"queries\":[\"how to check tool registration in workflow\",\"confirming tool signature in workflow\",\"troubleshooting tool registration issues in workflows\"]}","name":"Response"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-ab4eac97-1521-4396-a766-62be4648e7d5","example":false,"tool_calls":[{"name":"Response","args":{"queries":["how to check tool registration in workflow","confirming tool signature in workflow","troubleshooting tool registration issues in workflows"]},"id":"call_NdsKBLRRFrscluW0mJ3jpE3F","type":"tool_call"}],"invalid_tool_calls":[]}},"run_type":"parser","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|generate_queries:6db7899b-3e6d-5f16-70d0-dd31bb91f8a0","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195935203789Zc20cc4f1-afb2-44d0-bff6-86a89b092c3c.20241204T195935314602Za719c5b3-355d-4003-a76a-c6e9f80d146d.20241204T195936066402Za7b8e03a-958c-4539-8eb9-bb4914b79f5b"}
{"id":"a7b8e03a-958c-4539-8eb9-bb4914b79f5b","name":"JsonOutputKeyToolsParser","end_time":"2024-12-04T19:59:36.226409","error":null,"outputs":{"queries":["how to check tool registration in workflow","confirming tool signature in workflow","troubleshooting tool registration issues in workflows"]}}
{"id":"9c98970a-df15-4529-9e3e-5e13de4cc261","name":"_write","start_time":"2024-12-04T19:59:36.237511","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:36.237511+00:00"},{"name":"end","time":"2024-12-04T19:59:36.242435+00:00"}],"inputs":{"queries":["how to check tool registration in workflow","confirming tool signature in workflow","troubleshooting tool registration issues in workflows"]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|generate_queries:6db7899b-3e6d-5f16-70d0-dd31bb91f8a0","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195935203789Zc20cc4f1-afb2-44d0-bff6-86a89b092c3c.20241204T195936237511Z9c98970a-df15-4529-9e3e-5e13de4cc261"}
{"id":"9c98970a-df15-4529-9e3e-5e13de4cc261","name":"_write","end_time":"2024-12-04T19:59:36.242435","error":null,"outputs":{"queries":["how to check tool registration in workflow","confirming tool signature in workflow","troubleshooting tool registration issues in workflows"]}}
{"id":"5e1e4f20-07a6-42d1-a268-983c2d94562d","name":"retrieve_in_parallel","start_time":"2024-12-04T19:59:36.989232","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:36.989232+00:00"},{"name":"end","time":"2024-12-04T19:59:37.005527+00:00"}],"inputs":{"input":{"question":"Check the registration of the tool in the workflow to confirm that it is being registered correctly with the expected signature.","queries":["how to check tool registration in workflow","confirming tool signature in workflow","troubleshooting tool registration issues in workflows"],"documents":[]}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|generate_queries:6db7899b-3e6d-5f16-70d0-dd31bb91f8a0","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:4"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195935203789Zc20cc4f1-afb2-44d0-bff6-86a89b092c3c.20241204T195936989232Z5e1e4f20-07a6-42d1-a268-983c2d94562d"}
{"id":"5e1e4f20-07a6-42d1-a268-983c2d94562d","name":"retrieve_in_parallel","end_time":"2024-12-04T19:59:37.005527","error":null,"outputs":{"output":["Send(node='retrieve_documents', arg=QueryState(query='how to check tool registration in workflow'))","Send(node='retrieve_documents', arg=QueryState(query='confirming tool signature in workflow'))","Send(node='retrieve_documents', arg=QueryState(query='troubleshooting tool registration issues in workflows'))"]}}
{"id":"8e4694ba-af2c-4ec7-b5fc-28cf7b0d8a25","name":"retrieve_documents","start_time":"2024-12-04T19:59:37.017555","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:37.017555+00:00"},{"name":"end","time":"2024-12-04T19:59:40.090650+00:00"}],"inputs":{"input":{"query":"how to check tool registration in workflow"}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",0],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|retrieve_documents:4cc77986-c2c2-6f5e-b2ef-5c93d87d9a88","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195937017555Z8e4694ba-af2c-4ec7-b5fc-28cf7b0d8a25"}
{"id":"8e4694ba-af2c-4ec7-b5fc-28cf7b0d8a25","name":"retrieve_documents","end_time":"2024-12-04T19:59:40.090650","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"}]}}
{"id":"b06307b6-a4d9-4ce5-a000-170dbe471354","name":"VectorStoreRetriever","start_time":"2024-12-04T19:59:37.379496","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:37.379496+00:00"},{"name":"end","time":"2024-12-04T19:59:40.057507+00:00"}],"inputs":{"query":"how to check tool registration in workflow"},"run_type":"retriever","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",0],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|retrieve_documents:4cc77986-c2c2-6f5e-b2ef-5c93d87d9a88","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","ls_retriever_name":"vectorstore","ls_vector_store_provider":"WeaviateVectorStore","ls_embedding_provider":"OpenAIEmbeddings","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["OpenAIEmbeddings","WeaviateVectorStore","seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195937017555Z8e4694ba-af2c-4ec7-b5fc-28cf7b0d8a25.20241204T195937379496Zb06307b6-a4d9-4ce5-a000-170dbe471354"}
{"id":"b06307b6-a4d9-4ce5-a000-170dbe471354","name":"VectorStoreRetriever","end_time":"2024-12-04T19:59:40.057507","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"}]}}
{"id":"139dd134-9719-4df1-8325-27794af2ff05","name":"_write","start_time":"2024-12-04T19:59:40.073264","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.073264+00:00"},{"name":"end","time":"2024-12-04T19:59:40.080687+00:00"}],"inputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",0],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|retrieve_documents:4cc77986-c2c2-6f5e-b2ef-5c93d87d9a88","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195937017555Z8e4694ba-af2c-4ec7-b5fc-28cf7b0d8a25.20241204T195940073264Z139dd134-9719-4df1-8325-27794af2ff05"}
{"id":"139dd134-9719-4df1-8325-27794af2ff05","name":"_write","end_time":"2024-12-04T19:59:40.080687","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"}]}}
{"id":"0da4ac36-9060-44f6-bd25-3ab30d905b2a","name":"retrieve_documents","start_time":"2024-12-04T19:59:37.018596","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:37.018596+00:00"},{"name":"end","time":"2024-12-04T19:59:40.083507+00:00"}],"inputs":{"input":{"query":"confirming tool signature in workflow"}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",1],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|retrieve_documents:fa76d0c3-3ceb-f5f2-4077-eae55a63ec96","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195937018596Z0da4ac36-9060-44f6-bd25-3ab30d905b2a"}
{"id":"0da4ac36-9060-44f6-bd25-3ab30d905b2a","name":"retrieve_documents","end_time":"2024-12-04T19:59:40.083507","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"}]}}
{"id":"3a0e87d2-69ae-4888-8622-a8b0ed86edf1","name":"VectorStoreRetriever","start_time":"2024-12-04T19:59:37.652969","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:37.652969+00:00"},{"name":"end","time":"2024-12-04T19:59:40.030449+00:00"}],"inputs":{"query":"confirming tool signature in workflow"},"run_type":"retriever","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",1],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|retrieve_documents:fa76d0c3-3ceb-f5f2-4077-eae55a63ec96","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","ls_retriever_name":"vectorstore","ls_vector_store_provider":"WeaviateVectorStore","ls_embedding_provider":"OpenAIEmbeddings","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["OpenAIEmbeddings","WeaviateVectorStore","seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195937018596Z0da4ac36-9060-44f6-bd25-3ab30d905b2a.20241204T195937652969Z3a0e87d2-69ae-4888-8622-a8b0ed86edf1"}
{"id":"3a0e87d2-69ae-4888-8622-a8b0ed86edf1","name":"VectorStoreRetriever","end_time":"2024-12-04T19:59:40.030449","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"}]}}
{"id":"e7b8ce70-f73f-4850-bf61-2df3ba99f543","name":"_write","start_time":"2024-12-04T19:59:40.053105","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.053105+00:00"},{"name":"end","time":"2024-12-04T19:59:40.062006+00:00"}],"inputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",1],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|retrieve_documents:fa76d0c3-3ceb-f5f2-4077-eae55a63ec96","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195937018596Z0da4ac36-9060-44f6-bd25-3ab30d905b2a.20241204T195940053105Ze7b8ce70-f73f-4850-bf61-2df3ba99f543"}
{"id":"e7b8ce70-f73f-4850-bf61-2df3ba99f543","name":"_write","end_time":"2024-12-04T19:59:40.062006","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"}]}}
{"id":"046db3c6-b7d5-49b3-8897-5bdacaf2d93f","name":"retrieve_documents","start_time":"2024-12-04T19:59:37.019460","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:37.019460+00:00"},{"name":"end","time":"2024-12-04T19:59:40.084396+00:00"}],"inputs":{"input":{"query":"troubleshooting tool registration issues in workflows"}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",2],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|retrieve_documents:b004b36a-cc5b-e36c-7562-27b67d543502","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195937019460Z046db3c6-b7d5-49b3-8897-5bdacaf2d93f"}
{"id":"046db3c6-b7d5-49b3-8897-5bdacaf2d93f","name":"retrieve_documents","end_time":"2024-12-04T19:59:40.084396","error":null,"outputs":{"documents":[{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"}]}}
{"id":"cf8ba656-d427-42b2-96ed-a0c546dabe32","name":"VectorStoreRetriever","start_time":"2024-12-04T19:59:38.029160","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:38.029160+00:00"},{"name":"end","time":"2024-12-04T19:59:40.031064+00:00"}],"inputs":{"query":"troubleshooting tool registration issues in workflows"},"run_type":"retriever","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",2],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|retrieve_documents:b004b36a-cc5b-e36c-7562-27b67d543502","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","ls_retriever_name":"vectorstore","ls_vector_store_provider":"WeaviateVectorStore","ls_embedding_provider":"OpenAIEmbeddings","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["OpenAIEmbeddings","WeaviateVectorStore","seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195937019460Z046db3c6-b7d5-49b3-8897-5bdacaf2d93f.20241204T195938029160Zcf8ba656-d427-42b2-96ed-a0c546dabe32"}
{"id":"cf8ba656-d427-42b2-96ed-a0c546dabe32","name":"VectorStoreRetriever","end_time":"2024-12-04T19:59:40.031064","error":null,"outputs":{"documents":[{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"}]}}
{"id":"cf871057-de67-4489-a349-945074182080","name":"_write","start_time":"2024-12-04T19:59:40.054585","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.054585+00:00"},{"name":"end","time":"2024-12-04T19:59:40.062852+00:00"}],"inputs":{"documents":[{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",2],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07|retrieve_documents:b004b36a-cc5b-e36c-7562-27b67d543502","checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195935182742Za6fe296b-d903-48d9-b13a-d7081db1495f.20241204T195937019460Z046db3c6-b7d5-49b3-8897-5bdacaf2d93f.20241204T195940054585Zcf871057-de67-4489-a349-945074182080"}
{"id":"cf871057-de67-4489-a349-945074182080","name":"_write","end_time":"2024-12-04T19:59:40.062852","error":null,"outputs":{"documents":[{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"}]}}
{"id":"d8fbb37d-7850-47c0-ae63-4eff869e62a2","name":"_write","start_time":"2024-12-04T19:59:40.151457","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.151457+00:00"},{"name":"end","time":"2024-12-04T19:59:40.157465+00:00"}],"inputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"}],"steps":["Test the workflow with a simplified version of the JSON configuration to isolate the issue."]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":17,"langgraph_node":"conduct_research","langgraph_triggers":["branch:conduct_research:check_finished:conduct_research"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195940151457Zd8fbb37d-7850-47c0-ae63-4eff869e62a2"}
{"id":"d8fbb37d-7850-47c0-ae63-4eff869e62a2","name":"_write","end_time":"2024-12-04T19:59:40.157465","error":null,"outputs":{"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"}],"steps":["Test the workflow with a simplified version of the JSON configuration to isolate the issue."]}}
{"id":"3e005da3-7e3b-4976-a437-1d018a90f828","name":"check_finished","start_time":"2024-12-04T19:59:40.246137","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.246137+00:00"},{"name":"end","time":"2024-12-04T19:59:40.255890+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false}],"router":{"type":"general","logic":""},"steps":["Test the workflow with a simplified version of the JSON configuration to isolate the issue."],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"}],"answer":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":0}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":17,"langgraph_node":"conduct_research","langgraph_triggers":["branch:conduct_research:check_finished:conduct_research"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:917fb165-1ef7-c8b9-b6c2-f19b03477d07","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:4"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195935178124Zb3ba2815-689b-4d05-85d6-5ea2d12cafab.20241204T195940246137Z3e005da3-7e3b-4976-a437-1d018a90f828"}
{"id":"3e005da3-7e3b-4976-a437-1d018a90f828","name":"check_finished","end_time":"2024-12-04T19:59:40.255890","error":null,"outputs":{"output":"conduct_research"}}
{"id":"b0fc3edd-a59e-4051-96f6-eaabc07cef9a","name":"conduct_research","start_time":"2024-12-04T19:59:40.269313","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.269313+00:00"},{"name":"end","time":"2024-12-04T19:59:45.572199+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false}],"router":{"type":"general","logic":""},"steps":["Test the workflow with a simplified version of the JSON configuration to isolate the issue."],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"}],"answer":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":0}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":18,"langgraph_node":"conduct_research","langgraph_triggers":["branch:conduct_research:check_finished:conduct_research"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:18"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a"}
{"id":"b0fc3edd-a59e-4051-96f6-eaabc07cef9a","name":"conduct_research","end_time":"2024-12-04T19:59:45.572199","error":null,"outputs":{"documents":[{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}],"steps":[]}}
{"id":"9555082f-c4cb-4cce-bd1f-48c0b8fc923b","name":"ResearcherGraph","start_time":"2024-12-04T19:59:40.274748","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.274748+00:00"},{"name":"end","time":"2024-12-04T19:59:44.996679+00:00"}],"inputs":{"question":"Test the workflow with a simplified version of the JSON configuration to isolate the issue."},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":18,"langgraph_node":"conduct_research","langgraph_triggers":["branch:conduct_research:check_finished:conduct_research"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b"}
{"id":"9555082f-c4cb-4cce-bd1f-48c0b8fc923b","name":"ResearcherGraph","end_time":"2024-12-04T19:59:44.996679","error":null,"outputs":{"question":"Test the workflow with a simplified version of the JSON configuration to isolate the issue.","queries":["how to create a simplified JSON configuration","troubleshooting JSON configuration issues","best practices for testing JSON configurations"],"documents":[{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}]}}
{"id":"996ad03c-7363-4f11-823f-837c58ae4e65","name":"__start__","start_time":"2024-12-04T19:59:40.287276","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.287276+00:00"},{"name":"end","time":"2024-12-04T19:59:40.294025+00:00"}],"inputs":{"question":"Test the workflow with a simplified version of the JSON configuration to isolate the issue."},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":0,"langgraph_node":"__start__","langgraph_triggers":["__start__"],"langgraph_path":["__pregel_pull","__start__"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|__start__:d5ad9c6f-ac15-5b34-bc7b-af80863903e9","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","graph:step:0"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195940287276Z996ad03c-7363-4f11-823f-837c58ae4e65"}
{"id":"996ad03c-7363-4f11-823f-837c58ae4e65","name":"__start__","end_time":"2024-12-04T19:59:40.294025","error":null,"outputs":{"question":"Test the workflow with a simplified version of the JSON configuration to isolate the issue."}}
{"id":"4d150541-f654-4f1b-a887-7fbe74c4e10e","name":"generate_queries","start_time":"2024-12-04T19:59:40.298894","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.298894+00:00"},{"name":"end","time":"2024-12-04T19:59:41.530897+00:00"}],"inputs":{"input":{"question":"Test the workflow with a simplified version of the JSON configuration to isolate the issue.","queries":[],"documents":[]}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|generate_queries:1994acbf-cdbd-6ebb-b927-6b62767593db","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195940298894Z4d150541-f654-4f1b-a887-7fbe74c4e10e"}
{"id":"4d150541-f654-4f1b-a887-7fbe74c4e10e","name":"generate_queries","end_time":"2024-12-04T19:59:41.530897","error":null,"outputs":{"queries":["how to create a simplified JSON configuration","troubleshooting JSON configuration issues","best practices for testing JSON configurations"]}}
{"id":"68462dc6-59e1-4fb7-9d18-496ab7712c97","name":"RunnableSequence","start_time":"2024-12-04T19:59:40.405931","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.405931+00:00"},{"name":"end","time":"2024-12-04T19:59:41.263784+00:00"}],"inputs":{"input":[{"role":"system","content":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones."},{"role":"human","content":"Test the workflow with a simplified version of the JSON configuration to isolate the issue."}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|generate_queries:1994acbf-cdbd-6ebb-b927-6b62767593db","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195940298894Z4d150541-f654-4f1b-a887-7fbe74c4e10e.20241204T195940405931Z68462dc6-59e1-4fb7-9d18-496ab7712c97"}
{"id":"68462dc6-59e1-4fb7-9d18-496ab7712c97","name":"RunnableSequence","end_time":"2024-12-04T19:59:41.263784","error":null,"outputs":{"queries":["how to create a simplified JSON configuration","troubleshooting JSON configuration issues","best practices for testing JSON configurations"]}}
{"id":"1698b2b4-70bc-444f-a8b5-36e8f835486f","name":"ChatOpenAI","start_time":"2024-12-04T19:59:40.419781","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:40.419781+00:00"},{"name":"new_token","time":"2024-12-04T19:59:40.833578+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.838732+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.845784+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.850481+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.870208+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.875042+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.890626+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.895519+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.912606+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.916602+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.922241+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.927293+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.936193+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.940277+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.954603+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.959459+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.973528+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:40.979150+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:41.019400+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:41.024978+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:41.057543+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:41.062270+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:41.066467+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:41.070289+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:41.076205+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:41.081098+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:41.086464+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:41.090607+00:00","kwargs":{"token":""}},{"name":"end","time":"2024-12-04T19:59:41.097970+00:00"}],"inputs":{"messages":[[{"lc":1,"type":"constructor","id":["langchain","schema","messages","SystemMessage"],"kwargs":{"content":"Generate 3 search queries to search for to answer the user's question.\n\nThese search queries should be diverse in nature - do not generate repetitive ones.","type":"system"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"Test the workflow with a simplified version of the JSON configuration to isolate the issue.","type":"human"}}]]},"run_type":"llm","extra":{"invocation_params":{"model":"gpt-4o-mini","model_name":"gpt-4o-mini","stream":false,"n":1,"temperature":0.0,"_type":"openai-chat","stop":null,"tools":[{"type":"function","function":{"name":"Response","description":"dict() -> new empty dictionary\ndict(mapping) -> new dictionary initialized from a mapping object's\n    (key, value) pairs\ndict(iterable) -> new dictionary initialized as if via:\n    d = {}\n    for k, v in iterable:\n        d[k] = v\ndict(**kwargs) -> new dictionary initialized with the name=value pairs\n    in the keyword argument list.  For example:  dict(one=1, two=2)","parameters":{"type":"object","properties":{"queries":{"type":"array","items":{"type":"string"}}},"required":["queries"]}}}],"parallel_tool_calls":false,"tool_choice":{"type":"function","function":{"name":"Response"}}},"options":{"stop":null},"batch_size":1,"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|generate_queries:1994acbf-cdbd-6ebb-b927-6b62767593db","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","ls_provider":"openai","ls_model_name":"gpt-4o-mini","ls_model_type":"chat","ls_temperature":0.0,"LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195940298894Z4d150541-f654-4f1b-a887-7fbe74c4e10e.20241204T195940405931Z68462dc6-59e1-4fb7-9d18-496ab7712c97.20241204T195940419781Z1698b2b4-70bc-444f-a8b5-36e8f835486f"}
{"id":"1698b2b4-70bc-444f-a8b5-36e8f835486f","name":"ChatOpenAI","end_time":"2024-12-04T19:59:41.097970","error":null,"outputs":{"generations":[{"text":"","generation_info":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ChatGeneration","message":{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_XjC3N99Ug4nBgEF8YwhJbvJK","function":{"arguments":"{\"queries\":[\"how to create a simplified JSON configuration\",\"troubleshooting JSON configuration issues\",\"best practices for testing JSON configurations\"]}","name":"Response"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-1698b2b4-70bc-444f-a8b5-36e8f835486f","tool_calls":[{"name":"Response","args":{"queries":["how to create a simplified JSON configuration","troubleshooting JSON configuration issues","best practices for testing JSON configurations"]},"id":"call_XjC3N99Ug4nBgEF8YwhJbvJK","type":"tool_call"}],"invalid_tool_calls":[]}}}],"llm_output":null,"run":null,"type":"LLMResult"}}
{"id":"a0214d1a-f86b-41b9-8bfb-9d5339b31e02","name":"JsonOutputKeyToolsParser","start_time":"2024-12-04T19:59:41.104151","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:41.104151+00:00"},{"name":"end","time":"2024-12-04T19:59:41.256533+00:00"}],"inputs":{"input":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_XjC3N99Ug4nBgEF8YwhJbvJK","function":{"arguments":"{\"queries\":[\"how to create a simplified JSON configuration\",\"troubleshooting JSON configuration issues\",\"best practices for testing JSON configurations\"]}","name":"Response"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-1698b2b4-70bc-444f-a8b5-36e8f835486f","example":false,"tool_calls":[{"name":"Response","args":{"queries":["how to create a simplified JSON configuration","troubleshooting JSON configuration issues","best practices for testing JSON configurations"]},"id":"call_XjC3N99Ug4nBgEF8YwhJbvJK","type":"tool_call"}],"invalid_tool_calls":[]}},"run_type":"parser","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|generate_queries:1994acbf-cdbd-6ebb-b927-6b62767593db","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195940298894Z4d150541-f654-4f1b-a887-7fbe74c4e10e.20241204T195940405931Z68462dc6-59e1-4fb7-9d18-496ab7712c97.20241204T195941104151Za0214d1a-f86b-41b9-8bfb-9d5339b31e02"}
{"id":"a0214d1a-f86b-41b9-8bfb-9d5339b31e02","name":"JsonOutputKeyToolsParser","end_time":"2024-12-04T19:59:41.256533","error":null,"outputs":{"queries":["how to create a simplified JSON configuration","troubleshooting JSON configuration issues","best practices for testing JSON configurations"]}}
{"id":"889fae07-50b4-4bf4-8b24-64f25c06c1c5","name":"_write","start_time":"2024-12-04T19:59:41.269104","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:41.269104+00:00"},{"name":"end","time":"2024-12-04T19:59:41.273465+00:00"}],"inputs":{"queries":["how to create a simplified JSON configuration","troubleshooting JSON configuration issues","best practices for testing JSON configurations"]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|generate_queries:1994acbf-cdbd-6ebb-b927-6b62767593db","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195940298894Z4d150541-f654-4f1b-a887-7fbe74c4e10e.20241204T195941269104Z889fae07-50b4-4bf4-8b24-64f25c06c1c5"}
{"id":"889fae07-50b4-4bf4-8b24-64f25c06c1c5","name":"_write","end_time":"2024-12-04T19:59:41.273465","error":null,"outputs":{"queries":["how to create a simplified JSON configuration","troubleshooting JSON configuration issues","best practices for testing JSON configurations"]}}
{"id":"3572cb84-34a9-4cc8-90ce-2139342166bd","name":"retrieve_in_parallel","start_time":"2024-12-04T19:59:41.303260","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:41.303260+00:00"},{"name":"end","time":"2024-12-04T19:59:41.524729+00:00"}],"inputs":{"input":{"question":"Test the workflow with a simplified version of the JSON configuration to isolate the issue.","queries":["how to create a simplified JSON configuration","troubleshooting JSON configuration issues","best practices for testing JSON configurations"],"documents":[]}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":1,"langgraph_node":"generate_queries","langgraph_triggers":["start:generate_queries"],"langgraph_path":["__pregel_pull","generate_queries"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|generate_queries:1994acbf-cdbd-6ebb-b927-6b62767593db","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:4"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195940298894Z4d150541-f654-4f1b-a887-7fbe74c4e10e.20241204T195941303260Z3572cb84-34a9-4cc8-90ce-2139342166bd"}
{"id":"3572cb84-34a9-4cc8-90ce-2139342166bd","name":"retrieve_in_parallel","end_time":"2024-12-04T19:59:41.524729","error":null,"outputs":{"output":["Send(node='retrieve_documents', arg=QueryState(query='how to create a simplified JSON configuration'))","Send(node='retrieve_documents', arg=QueryState(query='troubleshooting JSON configuration issues'))","Send(node='retrieve_documents', arg=QueryState(query='best practices for testing JSON configurations'))"]}}
{"id":"529eb45a-a429-4389-a82c-6325282e2042","name":"retrieve_documents","start_time":"2024-12-04T19:59:41.536323","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:41.536323+00:00"},{"name":"end","time":"2024-12-04T19:59:44.857130+00:00"}],"inputs":{"input":{"query":"how to create a simplified JSON configuration"}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",0],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|retrieve_documents:0219c4fb-6f55-7f16-4f14-0f1d3653fdec","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195941536323Z529eb45a-a429-4389-a82c-6325282e2042"}
{"id":"529eb45a-a429-4389-a82c-6325282e2042","name":"retrieve_documents","end_time":"2024-12-04T19:59:44.857130","error":null,"outputs":{"documents":[{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"}]}}
{"id":"b33d97a4-0000-4b9d-a6fc-5cc53ca5ff3d","name":"VectorStoreRetriever","start_time":"2024-12-04T19:59:41.824602","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:41.824602+00:00"},{"name":"end","time":"2024-12-04T19:59:44.818495+00:00"}],"inputs":{"query":"how to create a simplified JSON configuration"},"run_type":"retriever","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",0],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|retrieve_documents:0219c4fb-6f55-7f16-4f14-0f1d3653fdec","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","ls_retriever_name":"vectorstore","ls_vector_store_provider":"WeaviateVectorStore","ls_embedding_provider":"OpenAIEmbeddings","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["OpenAIEmbeddings","WeaviateVectorStore","seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195941536323Z529eb45a-a429-4389-a82c-6325282e2042.20241204T195941824602Zb33d97a4-0000-4b9d-a6fc-5cc53ca5ff3d"}
{"id":"b33d97a4-0000-4b9d-a6fc-5cc53ca5ff3d","name":"VectorStoreRetriever","end_time":"2024-12-04T19:59:44.818495","error":null,"outputs":{"documents":[{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"}]}}
{"id":"2b4f4ff6-08a8-4423-999b-d6b9f0051776","name":"_write","start_time":"2024-12-04T19:59:44.835998","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:44.835998+00:00"},{"name":"end","time":"2024-12-04T19:59:44.846240+00:00"}],"inputs":{"documents":[{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",0],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|retrieve_documents:0219c4fb-6f55-7f16-4f14-0f1d3653fdec","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195941536323Z529eb45a-a429-4389-a82c-6325282e2042.20241204T195944835998Z2b4f4ff6-08a8-4423-999b-d6b9f0051776"}
{"id":"2b4f4ff6-08a8-4423-999b-d6b9f0051776","name":"_write","end_time":"2024-12-04T19:59:44.846240","error":null,"outputs":{"documents":[{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"}]}}
{"id":"a7c1e554-3047-48ca-a6c0-e1c976d974bc","name":"retrieve_documents","start_time":"2024-12-04T19:59:41.537350","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:41.537350+00:00"},{"name":"end","time":"2024-12-04T19:59:44.953269+00:00"}],"inputs":{"input":{"query":"troubleshooting JSON configuration issues"}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",1],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|retrieve_documents:11938446-a18e-7ea9-4542-66b1646742e5","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195941537350Za7c1e554-3047-48ca-a6c0-e1c976d974bc"}
{"id":"a7c1e554-3047-48ca-a6c0-e1c976d974bc","name":"retrieve_documents","end_time":"2024-12-04T19:59:44.953269","error":null,"outputs":{"documents":[{"metadata":{"description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"}]}}
{"id":"38bc056e-e964-4873-a49e-dc78175a9951","name":"VectorStoreRetriever","start_time":"2024-12-04T19:59:42.104003","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:42.104003+00:00"},{"name":"end","time":"2024-12-04T19:59:44.923221+00:00"}],"inputs":{"query":"troubleshooting JSON configuration issues"},"run_type":"retriever","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",1],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|retrieve_documents:11938446-a18e-7ea9-4542-66b1646742e5","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","ls_retriever_name":"vectorstore","ls_vector_store_provider":"WeaviateVectorStore","ls_embedding_provider":"OpenAIEmbeddings","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["OpenAIEmbeddings","WeaviateVectorStore","seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195941537350Za7c1e554-3047-48ca-a6c0-e1c976d974bc.20241204T195942104003Z38bc056e-e964-4873-a49e-dc78175a9951"}
{"id":"38bc056e-e964-4873-a49e-dc78175a9951","name":"VectorStoreRetriever","end_time":"2024-12-04T19:59:44.923221","error":null,"outputs":{"documents":[{"metadata":{"description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"}]}}
{"id":"0f095c5c-3f4a-4272-bace-143603be6d91","name":"_write","start_time":"2024-12-04T19:59:44.936775","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:44.936775+00:00"},{"name":"end","time":"2024-12-04T19:59:44.943383+00:00"}],"inputs":{"documents":[{"metadata":{"description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",1],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|retrieve_documents:11938446-a18e-7ea9-4542-66b1646742e5","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195941537350Za7c1e554-3047-48ca-a6c0-e1c976d974bc.20241204T195944936775Z0f095c5c-3f4a-4272-bace-143603be6d91"}
{"id":"0f095c5c-3f4a-4272-bace-143603be6d91","name":"_write","end_time":"2024-12-04T19:59:44.943383","error":null,"outputs":{"documents":[{"metadata":{"description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"}]}}
{"id":"bfbf25f3-3f69-4554-b9a4-00bde78a5e91","name":"retrieve_documents","start_time":"2024-12-04T19:59:41.538263","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:41.538263+00:00"},{"name":"end","time":"2024-12-04T19:59:44.946240+00:00"}],"inputs":{"input":{"query":"best practices for testing JSON configurations"}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",2],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|retrieve_documents:445eb59a-ae82-921f-d404-c1b74bac2fda","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195941538263Zbfbf25f3-3f69-4554-b9a4-00bde78a5e91"}
{"id":"bfbf25f3-3f69-4554-b9a4-00bde78a5e91","name":"retrieve_documents","end_time":"2024-12-04T19:59:44.946240","error":null,"outputs":{"documents":[{"metadata":{"description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}]}}
{"id":"7eb08203-edfb-4b0d-8536-ec243f209105","name":"VectorStoreRetriever","start_time":"2024-12-04T19:59:42.407307","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:42.407307+00:00"},{"name":"end","time":"2024-12-04T19:59:44.910478+00:00"}],"inputs":{"query":"best practices for testing JSON configurations"},"run_type":"retriever","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",2],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|retrieve_documents:445eb59a-ae82-921f-d404-c1b74bac2fda","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","ls_retriever_name":"vectorstore","ls_vector_store_provider":"WeaviateVectorStore","ls_embedding_provider":"OpenAIEmbeddings","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["OpenAIEmbeddings","WeaviateVectorStore","seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195941538263Zbfbf25f3-3f69-4554-b9a4-00bde78a5e91.20241204T195942407307Z7eb08203-edfb-4b0d-8536-ec243f209105"}
{"id":"7eb08203-edfb-4b0d-8536-ec243f209105","name":"VectorStoreRetriever","end_time":"2024-12-04T19:59:44.910478","error":null,"outputs":{"documents":[{"metadata":{"description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}]}}
{"id":"ca3cfe60-6fde-4ca8-917f-c75e3400c448","name":"_write","start_time":"2024-12-04T19:59:44.920127","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:44.920127+00:00"},{"name":"end","time":"2024-12-04T19:59:44.927478+00:00"}],"inputs":{"documents":[{"metadata":{"description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":2,"langgraph_node":"retrieve_documents","langgraph_triggers":["__pregel_push"],"langgraph_path":["__pregel_push",2],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d|retrieve_documents:445eb59a-ae82-921f-d404-c1b74bac2fda","checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195940274748Z9555082f-c4cb-4cce-bd1f-48c0b8fc923b.20241204T195941538263Zbfbf25f3-3f69-4554-b9a4-00bde78a5e91.20241204T195944920127Zca3cfe60-6fde-4ca8-917f-c75e3400c448"}
{"id":"ca3cfe60-6fde-4ca8-917f-c75e3400c448","name":"_write","end_time":"2024-12-04T19:59:44.927478","error":null,"outputs":{"documents":[{"metadata":{"description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}]}}
{"id":"c44f35d4-ecb8-45e1-a44a-aa5b9b10aacb","name":"_write","start_time":"2024-12-04T19:59:45.001491","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:45.001491+00:00"},{"name":"end","time":"2024-12-04T19:59:45.006478+00:00"}],"inputs":{"documents":[{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}],"steps":[]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":18,"langgraph_node":"conduct_research","langgraph_triggers":["branch:conduct_research:check_finished:conduct_research"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195945001491Zc44f35d4-ecb8-45e1-a44a-aa5b9b10aacb"}
{"id":"c44f35d4-ecb8-45e1-a44a-aa5b9b10aacb","name":"_write","end_time":"2024-12-04T19:59:45.006478","error":null,"outputs":{"documents":[{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}],"steps":[]}}
{"id":"6fc592d3-cab8-4bd5-9b34-0c6eefef8277","name":"check_finished","start_time":"2024-12-04T19:59:45.227358","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:45.227358+00:00"},{"name":"end","time":"2024-12-04T19:59:45.561547+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false}],"router":{"type":"general","logic":""},"steps":[],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}],"answer":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":0}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":18,"langgraph_node":"conduct_research","langgraph_triggers":["branch:conduct_research:check_finished:conduct_research"],"langgraph_path":["__pregel_pull","conduct_research"],"langgraph_checkpoint_ns":"conduct_research:4a35db82-9e8a-0ace-84f7-6b3ee61d708d","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:4"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195940269313Zb0fc3edd-a59e-4051-96f6-eaabc07cef9a.20241204T195945227358Z6fc592d3-cab8-4bd5-9b34-0c6eefef8277"}
{"id":"6fc592d3-cab8-4bd5-9b34-0c6eefef8277","name":"check_finished","end_time":"2024-12-04T19:59:45.561547","error":null,"outputs":{"output":"respond"}}
{"id":"3ae3e54f-7361-43f7-b606-58e7f71137e7","name":"respond","start_time":"2024-12-04T19:59:45.581522","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:45.581522+00:00"},{"name":"end","time":"2024-12-04T20:00:01.247838+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false}],"router":{"type":"general","logic":""},"steps":[],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}],"answer":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":0}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":19,"langgraph_node":"respond","langgraph_triggers":["branch:conduct_research:check_finished:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:19"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195945581522Z3ae3e54f-7361-43f7-b606-58e7f71137e7"}
{"id":"3ae3e54f-7361-43f7-b606-58e7f71137e7","name":"respond","end_time":"2024-12-04T20:00:01.247838","error":null,"outputs":{"messages":[{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-7d69b282-55a6-4665-8dd8-50146bca4a14","example":false,"tool_calls":[],"invalid_tool_calls":[]}],"answer":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","num_response_attempts":1}}
{"id":"7d69b282-55a6-4665-8dd8-50146bca4a14","name":"ChatOpenAI","start_time":"2024-12-04T19:59:45.693555","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:45.693555+00:00"},{"name":"new_token","time":"2024-12-04T19:59:47.213396+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T19:59:47.216985+00:00","kwargs":{"token":"The"}},{"name":"new_token","time":"2024-12-04T19:59:47.452366+00:00","kwargs":{"token":" error"}},{"name":"new_token","time":"2024-12-04T19:59:47.456959+00:00","kwargs":{"token":" message"}},{"name":"new_token","time":"2024-12-04T19:59:47.494374+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T19:59:47.499374+00:00","kwargs":{"token":" are"}},{"name":"new_token","time":"2024-12-04T19:59:47.503964+00:00","kwargs":{"token":" encountering"}},{"name":"new_token","time":"2024-12-04T19:59:47.508674+00:00","kwargs":{"token":" indicates"}},{"name":"new_token","time":"2024-12-04T19:59:47.513691+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T19:59:47.517268+00:00","kwargs":{"token":" there"}},{"name":"new_token","time":"2024-12-04T19:59:47.521555+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T19:59:47.526534+00:00","kwargs":{"token":" a"}},{"name":"new_token","time":"2024-12-04T19:59:47.531611+00:00","kwargs":{"token":" mismatch"}},{"name":"new_token","time":"2024-12-04T19:59:47.537171+00:00","kwargs":{"token":" between"}},{"name":"new_token","time":"2024-12-04T19:59:47.542199+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:47.547628+00:00","kwargs":{"token":" argument"}},{"name":"new_token","time":"2024-12-04T19:59:47.553920+00:00","kwargs":{"token":" descriptions"}},{"name":"new_token","time":"2024-12-04T19:59:47.559961+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T19:59:47.566542+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:47.572269+00:00","kwargs":{"token":" doc"}},{"name":"new_token","time":"2024-12-04T19:59:47.576970+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T19:59:47.580876+00:00","kwargs":{"token":" of"}},{"name":"new_token","time":"2024-12-04T19:59:47.595961+00:00","kwargs":{"token":" your"}},{"name":"new_token","time":"2024-12-04T19:59:47.601408+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T19:59:47.615156+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:47.619017+00:00","kwargs":{"token":" and"}},{"name":"new_token","time":"2024-12-04T19:59:47.646213+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:47.650787+00:00","kwargs":{"token":" actual"}},{"name":"new_token","time":"2024-12-04T19:59:47.692058+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:47.697149+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T19:59:47.704703+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:47.709939+00:00","kwargs":{"token":" Specifically"}},{"name":"new_token","time":"2024-12-04T19:59:47.740646+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T19:59:47.745560+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:47.770479+00:00","kwargs":{"token":" error"}},{"name":"new_token","time":"2024-12-04T19:59:47.775521+00:00","kwargs":{"token":" states"}},{"name":"new_token","time":"2024-12-04T19:59:47.834041+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T19:59:47.839146+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:47.845002+00:00","kwargs":{"token":" argument"}},{"name":"new_token","time":"2024-12-04T19:59:47.849757+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T19:59:47.879437+00:00","kwargs":{"token":"query"}},{"name":"new_token","time":"2024-12-04T19:59:47.884100+00:00","kwargs":{"token":"`"}},{"name":"new_token","time":"2024-12-04T19:59:47.896000+00:00","kwargs":{"token":" ("}},{"name":"new_token","time":"2024-12-04T19:59:47.901009+00:00","kwargs":{"token":"of"}},{"name":"new_token","time":"2024-12-04T19:59:47.928993+00:00","kwargs":{"token":" type"}},{"name":"new_token","time":"2024-12-04T19:59:47.934087+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T19:59:47.964328+00:00","kwargs":{"token":"str"}},{"name":"new_token","time":"2024-12-04T19:59:47.969125+00:00","kwargs":{"token":"`)"}},{"name":"new_token","time":"2024-12-04T19:59:47.993678+00:00","kwargs":{"token":" mentioned"}},{"name":"new_token","time":"2024-12-04T19:59:47.998861+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T19:59:48.021844+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:48.026952+00:00","kwargs":{"token":" doc"}},{"name":"new_token","time":"2024-12-04T19:59:48.101423+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T19:59:48.106175+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T19:59:48.154975+00:00","kwargs":{"token":" not"}},{"name":"new_token","time":"2024-12-04T19:59:48.160332+00:00","kwargs":{"token":" found"}},{"name":"new_token","time":"2024-12-04T19:59:48.174433+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T19:59:48.179435+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:48.186861+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:48.191096+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T19:59:48.217792+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:48.222558+00:00","kwargs":{"token":"###"}},{"name":"new_token","time":"2024-12-04T19:59:48.229790+00:00","kwargs":{"token":" Steps"}},{"name":"new_token","time":"2024-12-04T19:59:48.234492+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T19:59:48.247542+00:00","kwargs":{"token":" Resolve"}},{"name":"new_token","time":"2024-12-04T19:59:48.252517+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:48.282573+00:00","kwargs":{"token":" Issue"}},{"name":"new_token","time":"2024-12-04T19:59:48.287629+00:00","kwargs":{"token":"\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:48.330090+00:00","kwargs":{"token":"1"}},{"name":"new_token","time":"2024-12-04T19:59:48.334697+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:48.356440+00:00","kwargs":{"token":" **"}},{"name":"new_token","time":"2024-12-04T19:59:48.361344+00:00","kwargs":{"token":"Check"}},{"name":"new_token","time":"2024-12-04T19:59:48.365399+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:48.383670+00:00","kwargs":{"token":" Tool"}},{"name":"new_token","time":"2024-12-04T19:59:48.388202+00:00","kwargs":{"token":" Function"}},{"name":"new_token","time":"2024-12-04T19:59:48.418387+00:00","kwargs":{"token":" Signature"}},{"name":"new_token","time":"2024-12-04T19:59:48.423202+00:00","kwargs":{"token":"**"}},{"name":"new_token","time":"2024-12-04T19:59:48.445932+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:48.451227+00:00","kwargs":{"token":" Ensure"}},{"name":"new_token","time":"2024-12-04T19:59:48.487945+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T19:59:48.492955+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:48.532469+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:48.537664+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T19:59:48.551269+00:00","kwargs":{"token":" of"}},{"name":"new_token","time":"2024-12-04T19:59:48.556372+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T19:59:48.860239+00:00","kwargs":{"token":"process"}},{"name":"new_token","time":"2024-12-04T19:59:48.864011+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T19:59:48.896400+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T19:59:48.900498+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T19:59:48.928672+00:00","kwargs":{"token":"`"}},{"name":"new_token","time":"2024-12-04T19:59:48.935800+00:00","kwargs":{"token":" matches"}},{"name":"new_token","time":"2024-12-04T19:59:48.941299+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:48.946440+00:00","kwargs":{"token":" argument"}},{"name":"new_token","time":"2024-12-04T19:59:48.951307+00:00","kwargs":{"token":" descriptions"}},{"name":"new_token","time":"2024-12-04T19:59:48.956405+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T19:59:48.962077+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:48.966546+00:00","kwargs":{"token":" doc"}},{"name":"new_token","time":"2024-12-04T19:59:48.970890+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T19:59:48.975665+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:48.980514+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T19:59:48.985789+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:48.990786+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T19:59:48.995866+00:00","kwargs":{"token":" look"}},{"name":"new_token","time":"2024-12-04T19:59:49.000727+00:00","kwargs":{"token":" something"}},{"name":"new_token","time":"2024-12-04T19:59:49.006105+00:00","kwargs":{"token":" like"}},{"name":"new_token","time":"2024-12-04T19:59:49.013149+00:00","kwargs":{"token":" this"}},{"name":"new_token","time":"2024-12-04T19:59:49.018652+00:00","kwargs":{"token":":\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:49.023442+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:49.027715+00:00","kwargs":{"token":" ```"}},{"name":"new_token","time":"2024-12-04T19:59:49.032319+00:00","kwargs":{"token":"python"}},{"name":"new_token","time":"2024-12-04T19:59:49.036388+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T19:59:49.045323+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:49.050389+00:00","kwargs":{"token":" @"}},{"name":"new_token","time":"2024-12-04T19:59:49.098778+00:00","kwargs":{"token":"tool"}},{"name":"new_token","time":"2024-12-04T19:59:49.103652+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T19:59:49.112007+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:49.116897+00:00","kwargs":{"token":" def"}},{"name":"new_token","time":"2024-12-04T19:59:49.977292+00:00","kwargs":{"token":" process"}},{"name":"new_token","time":"2024-12-04T19:59:49.982543+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T19:59:49.997749+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T19:59:50.002833+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T19:59:50.008972+00:00","kwargs":{"token":"(query"}},{"name":"new_token","time":"2024-12-04T19:59:50.013556+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:50.017712+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T19:59:50.022441+00:00","kwargs":{"token":")"}},{"name":"new_token","time":"2024-12-04T19:59:50.027443+00:00","kwargs":{"token":" ->"}},{"name":"new_token","time":"2024-12-04T19:59:50.032531+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T19:59:50.037156+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.042140+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T19:59:50.047963+00:00","kwargs":{"token":" \"\"\"\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.053110+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T19:59:50.057918+00:00","kwargs":{"token":" Process"}},{"name":"new_token","time":"2024-12-04T19:59:50.062476+00:00","kwargs":{"token":" a"}},{"name":"new_token","time":"2024-12-04T19:59:50.066060+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T19:59:50.070438+00:00","kwargs":{"token":"-related"}},{"name":"new_token","time":"2024-12-04T19:59:50.073900+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T19:59:50.078050+00:00","kwargs":{"token":" using"}},{"name":"new_token","time":"2024-12-04T19:59:50.083244+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:50.088922+00:00","kwargs":{"token":" specialized"}},{"name":"new_token","time":"2024-12-04T19:59:50.093319+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T19:59:50.097843+00:00","kwargs":{"token":" workflow"}},{"name":"new_token","time":"2024-12-04T19:59:50.102612+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.106538+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T19:59:50.109956+00:00","kwargs":{"token":" Args"}},{"name":"new_token","time":"2024-12-04T19:59:50.114108+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.118969+00:00","kwargs":{"token":"          "}},{"name":"new_token","time":"2024-12-04T19:59:50.123542+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T19:59:50.128559+00:00","kwargs":{"token":" ("}},{"name":"new_token","time":"2024-12-04T19:59:50.133722+00:00","kwargs":{"token":"str"}},{"name":"new_token","time":"2024-12-04T19:59:50.138839+00:00","kwargs":{"token":"):"}},{"name":"new_token","time":"2024-12-04T19:59:50.143141+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T19:59:50.147038+00:00","kwargs":{"token":" user's"}},{"name":"new_token","time":"2024-12-04T19:59:50.151417+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T19:59:50.156282+00:00","kwargs":{"token":"-related"}},{"name":"new_token","time":"2024-12-04T19:59:50.161959+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T19:59:50.166827+00:00","kwargs":{"token":"\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.170451+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T19:59:50.174032+00:00","kwargs":{"token":" Returns"}},{"name":"new_token","time":"2024-12-04T19:59:50.178572+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.184021+00:00","kwargs":{"token":"          "}},{"name":"new_token","time":"2024-12-04T19:59:50.189205+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T19:59:50.194689+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:50.199319+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T19:59:50.204163+00:00","kwargs":{"token":" response"}},{"name":"new_token","time":"2024-12-04T19:59:50.208743+00:00","kwargs":{"token":" from"}},{"name":"new_token","time":"2024-12-04T19:59:50.213401+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:50.217890+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T19:59:50.222430+00:00","kwargs":{"token":" workflow"}},{"name":"new_token","time":"2024-12-04T19:59:50.226881+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.230405+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T19:59:50.235750+00:00","kwargs":{"token":" \"\"\"\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.240730+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T19:59:50.245915+00:00","kwargs":{"token":" return"}},{"name":"new_token","time":"2024-12-04T19:59:50.250796+00:00","kwargs":{"token":" [{\""}},{"name":"new_token","time":"2024-12-04T19:59:50.256387+00:00","kwargs":{"token":"claim"}},{"name":"new_token","time":"2024-12-04T19:59:50.260957+00:00","kwargs":{"token":"_id"}},{"name":"new_token","time":"2024-12-04T19:59:50.267407+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:50.272947+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:50.278394+00:00","kwargs":{"token":"123"}},{"name":"new_token","time":"2024-12-04T19:59:50.283253+00:00","kwargs":{"token":"4"}},{"name":"new_token","time":"2024-12-04T19:59:50.287212+00:00","kwargs":{"token":"\","}},{"name":"new_token","time":"2024-12-04T19:59:50.290950+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:50.295198+00:00","kwargs":{"token":"status"}},{"name":"new_token","time":"2024-12-04T19:59:50.298964+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:50.303633+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:50.309937+00:00","kwargs":{"token":"pending"}},{"name":"new_token","time":"2024-12-04T19:59:50.315735+00:00","kwargs":{"token":"\"},"}},{"name":"new_token","time":"2024-12-04T19:59:50.321229+00:00","kwargs":{"token":" {\""}},{"name":"new_token","time":"2024-12-04T19:59:50.325876+00:00","kwargs":{"token":"claim"}},{"name":"new_token","time":"2024-12-04T19:59:50.331671+00:00","kwargs":{"token":"_id"}},{"name":"new_token","time":"2024-12-04T19:59:50.336402+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:50.341280+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:50.347245+00:00","kwargs":{"token":"567"}},{"name":"new_token","time":"2024-12-04T19:59:50.351891+00:00","kwargs":{"token":"8"}},{"name":"new_token","time":"2024-12-04T19:59:50.383987+00:00","kwargs":{"token":"\","}},{"name":"new_token","time":"2024-12-04T19:59:50.388620+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:50.422189+00:00","kwargs":{"token":"status"}},{"name":"new_token","time":"2024-12-04T19:59:50.426834+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:50.435407+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:50.440622+00:00","kwargs":{"token":"approved"}},{"name":"new_token","time":"2024-12-04T19:59:50.479554+00:00","kwargs":{"token":"\"}"}},{"name":"new_token","time":"2024-12-04T19:59:50.484533+00:00","kwargs":{"token":"]\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.508628+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:50.513117+00:00","kwargs":{"token":" ``"}},{"name":"new_token","time":"2024-12-04T19:59:50.533717+00:00","kwargs":{"token":"`\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.538684+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:50.567620+00:00","kwargs":{"token":" Make"}},{"name":"new_token","time":"2024-12-04T19:59:50.572240+00:00","kwargs":{"token":" sure"}},{"name":"new_token","time":"2024-12-04T19:59:50.608700+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T19:59:50.613580+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:50.641720+00:00","kwargs":{"token":" argument"}},{"name":"new_token","time":"2024-12-04T19:59:50.646474+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T19:59:50.682210+00:00","kwargs":{"token":"query"}},{"name":"new_token","time":"2024-12-04T19:59:50.687466+00:00","kwargs":{"token":"`"}},{"name":"new_token","time":"2024-12-04T19:59:50.700400+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T19:59:50.704958+00:00","kwargs":{"token":" indeed"}},{"name":"new_token","time":"2024-12-04T19:59:50.753133+00:00","kwargs":{"token":" defined"}},{"name":"new_token","time":"2024-12-04T19:59:50.757689+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T19:59:50.767966+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:50.773112+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:50.798895+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T19:59:50.803503+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:50.849873+00:00","kwargs":{"token":"2"}},{"name":"new_token","time":"2024-12-04T19:59:50.854653+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:50.916722+00:00","kwargs":{"token":" **"}},{"name":"new_token","time":"2024-12-04T19:59:50.921272+00:00","kwargs":{"token":"Ensure"}},{"name":"new_token","time":"2024-12-04T19:59:50.925234+00:00","kwargs":{"token":" Proper"}},{"name":"new_token","time":"2024-12-04T19:59:50.929207+00:00","kwargs":{"token":" Registration"}},{"name":"new_token","time":"2024-12-04T19:59:50.933737+00:00","kwargs":{"token":"**"}},{"name":"new_token","time":"2024-12-04T19:59:50.937415+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:50.959203+00:00","kwargs":{"token":" When"}},{"name":"new_token","time":"2024-12-04T19:59:50.964074+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T19:59:50.999320+00:00","kwargs":{"token":" dynamically"}},{"name":"new_token","time":"2024-12-04T19:59:51.004002+00:00","kwargs":{"token":" register"}},{"name":"new_token","time":"2024-12-04T19:59:51.030724+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:51.035979+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T19:59:51.052293+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:51.058685+00:00","kwargs":{"token":" using"}},{"name":"new_token","time":"2024-12-04T19:59:51.093595+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T19:59:51.098355+00:00","kwargs":{"token":"exec"}},{"name":"new_token","time":"2024-12-04T19:59:51.113323+00:00","kwargs":{"token":"`,"}},{"name":"new_token","time":"2024-12-04T19:59:51.118076+00:00","kwargs":{"token":" ensure"}},{"name":"new_token","time":"2024-12-04T19:59:51.142898+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T19:59:51.147665+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:51.178110+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:51.183009+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T19:59:51.207150+00:00","kwargs":{"token":" correctly"}},{"name":"new_token","time":"2024-12-04T19:59:51.211860+00:00","kwargs":{"token":" defined"}},{"name":"new_token","time":"2024-12-04T19:59:51.241389+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T19:59:51.246550+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:51.281700+00:00","kwargs":{"token":" global"}},{"name":"new_token","time":"2024-12-04T19:59:51.286503+00:00","kwargs":{"token":" scope"}},{"name":"new_token","time":"2024-12-04T19:59:51.356106+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:51.360681+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T19:59:51.386042+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T19:59:51.391476+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:51.419513+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T19:59:51.424148+00:00","kwargs":{"token":" be"}},{"name":"new_token","time":"2024-12-04T19:59:51.449160+00:00","kwargs":{"token":" accessible"}},{"name":"new_token","time":"2024-12-04T19:59:51.453676+00:00","kwargs":{"token":" when"}},{"name":"new_token","time":"2024-12-04T19:59:51.480688+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:51.485334+00:00","kwargs":{"token":" L"}},{"name":"new_token","time":"2024-12-04T19:59:51.538098+00:00","kwargs":{"token":"LM"}},{"name":"new_token","time":"2024-12-04T19:59:51.543160+00:00","kwargs":{"token":" tries"}},{"name":"new_token","time":"2024-12-04T19:59:51.552348+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T19:59:51.557054+00:00","kwargs":{"token":" bind"}},{"name":"new_token","time":"2024-12-04T19:59:51.585164+00:00","kwargs":{"token":" it"}},{"name":"new_token","time":"2024-12-04T19:59:51.590453+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:51.616882+00:00","kwargs":{"token":"3"}},{"name":"new_token","time":"2024-12-04T19:59:51.621526+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:51.646553+00:00","kwargs":{"token":" **"}},{"name":"new_token","time":"2024-12-04T19:59:51.650849+00:00","kwargs":{"token":"Check"}},{"name":"new_token","time":"2024-12-04T19:59:51.686331+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:51.690968+00:00","kwargs":{"token":" JSON"}},{"name":"new_token","time":"2024-12-04T19:59:51.709940+00:00","kwargs":{"token":" Configuration"}},{"name":"new_token","time":"2024-12-04T19:59:51.714493+00:00","kwargs":{"token":"**"}},{"name":"new_token","time":"2024-12-04T19:59:51.751533+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:51.756279+00:00","kwargs":{"token":" Ensure"}},{"name":"new_token","time":"2024-12-04T19:59:51.781559+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T19:59:51.786201+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:51.826451+00:00","kwargs":{"token":" JSON"}},{"name":"new_token","time":"2024-12-04T19:59:51.830961+00:00","kwargs":{"token":" configuration"}},{"name":"new_token","time":"2024-12-04T19:59:51.895951+00:00","kwargs":{"token":" correctly"}},{"name":"new_token","time":"2024-12-04T19:59:51.900404+00:00","kwargs":{"token":" specifies"}},{"name":"new_token","time":"2024-12-04T19:59:51.912059+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:51.916574+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T19:59:51.922882+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:51.926807+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:51.940539+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T19:59:51.945000+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T19:59:51.979641+00:00","kwargs":{"token":"tool"}},{"name":"new_token","time":"2024-12-04T19:59:51.984937+00:00","kwargs":{"token":"`"}},{"name":"new_token","time":"2024-12-04T19:59:52.012145+00:00","kwargs":{"token":" field"}},{"name":"new_token","time":"2024-12-04T19:59:52.016873+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T19:59:52.041414+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:52.045469+00:00","kwargs":{"token":" JSON"}},{"name":"new_token","time":"2024-12-04T19:59:52.065079+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T19:59:52.069633+00:00","kwargs":{"token":" match"}},{"name":"new_token","time":"2024-12-04T19:59:52.096639+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:52.100748+00:00","kwargs":{"token":" name"}},{"name":"new_token","time":"2024-12-04T19:59:52.124071+00:00","kwargs":{"token":" of"}},{"name":"new_token","time":"2024-12-04T19:59:52.128612+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:52.161273+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:52.166267+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T19:59:52.181506+00:00","kwargs":{"token":" are"}},{"name":"new_token","time":"2024-12-04T19:59:52.185609+00:00","kwargs":{"token":" defining"}},{"name":"new_token","time":"2024-12-04T19:59:52.234218+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:52.243596+00:00","kwargs":{"token":" For"}},{"name":"new_token","time":"2024-12-04T19:59:52.256048+00:00","kwargs":{"token":" example"}},{"name":"new_token","time":"2024-12-04T19:59:52.263069+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T19:59:52.270117+00:00","kwargs":{"token":" if"}},{"name":"new_token","time":"2024-12-04T19:59:52.275674+00:00","kwargs":{"token":" your"}},{"name":"new_token","time":"2024-12-04T19:59:52.309463+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:52.314290+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T19:59:52.326333+00:00","kwargs":{"token":" named"}},{"name":"new_token","time":"2024-12-04T19:59:52.331572+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T19:59:52.354999+00:00","kwargs":{"token":"process"}},{"name":"new_token","time":"2024-12-04T19:59:52.359679+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T19:59:52.389974+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T19:59:52.394706+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T19:59:52.427206+00:00","kwargs":{"token":"`,"}},{"name":"new_token","time":"2024-12-04T19:59:52.431868+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:52.442414+00:00","kwargs":{"token":" JSON"}},{"name":"new_token","time":"2024-12-04T19:59:52.446780+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T19:59:52.468066+00:00","kwargs":{"token":" look"}},{"name":"new_token","time":"2024-12-04T19:59:52.473055+00:00","kwargs":{"token":" like"}},{"name":"new_token","time":"2024-12-04T19:59:52.531694+00:00","kwargs":{"token":" this"}},{"name":"new_token","time":"2024-12-04T19:59:52.535965+00:00","kwargs":{"token":":\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:52.541039+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:52.545796+00:00","kwargs":{"token":" ```"}},{"name":"new_token","time":"2024-12-04T19:59:52.584060+00:00","kwargs":{"token":"json"}},{"name":"new_token","time":"2024-12-04T19:59:52.589023+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T19:59:52.598196+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:52.602707+00:00","kwargs":{"token":" {\n"}},{"name":"new_token","time":"2024-12-04T19:59:52.621455+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T19:59:52.626085+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:52.655049+00:00","kwargs":{"token":"uniq"}},{"name":"new_token","time":"2024-12-04T19:59:52.659736+00:00","kwargs":{"token":"_id"}},{"name":"new_token","time":"2024-12-04T19:59:52.688149+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:52.693226+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:52.711506+00:00","kwargs":{"token":"6"}},{"name":"new_token","time":"2024-12-04T19:59:52.717638+00:00","kwargs":{"token":"\",\n"}},{"name":"new_token","time":"2024-12-04T19:59:52.740354+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T19:59:52.746506+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:52.772600+00:00","kwargs":{"token":"type"}},{"name":"new_token","time":"2024-12-04T19:59:52.777610+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:52.799385+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:52.804455+00:00","kwargs":{"token":"STEP"}},{"name":"new_token","time":"2024-12-04T19:59:52.830567+00:00","kwargs":{"token":"\",\n"}},{"name":"new_token","time":"2024-12-04T19:59:52.835493+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T19:59:52.852982+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:52.857450+00:00","kwargs":{"token":"name"}},{"name":"new_token","time":"2024-12-04T19:59:52.883703+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:52.888070+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:52.908877+00:00","kwargs":{"token":"TO"}},{"name":"new_token","time":"2024-12-04T19:59:52.913427+00:00","kwargs":{"token":"OL"}},{"name":"new_token","time":"2024-12-04T19:59:52.946531+00:00","kwargs":{"token":" CALL"}},{"name":"new_token","time":"2024-12-04T19:59:52.952168+00:00","kwargs":{"token":"\",\n"}},{"name":"new_token","time":"2024-12-04T19:59:52.967341+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T19:59:52.972196+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:53.001393+00:00","kwargs":{"token":"description"}},{"name":"new_token","time":"2024-12-04T19:59:53.006000+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:53.032296+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:53.037374+00:00","kwargs":{"token":"Call"}},{"name":"new_token","time":"2024-12-04T19:59:53.056459+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:53.061846+00:00","kwargs":{"token":" appropriate"}},{"name":"new_token","time":"2024-12-04T19:59:53.109162+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T19:59:53.113754+00:00","kwargs":{"token":"\",\n"}},{"name":"new_token","time":"2024-12-04T19:59:53.140934+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T19:59:53.145441+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:53.168689+00:00","kwargs":{"token":"tool"}},{"name":"new_token","time":"2024-12-04T19:59:53.173686+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:53.204506+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:53.208256+00:00","kwargs":{"token":"process"}},{"name":"new_token","time":"2024-12-04T19:59:53.225976+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T19:59:53.230676+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T19:59:53.256075+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T19:59:53.261047+00:00","kwargs":{"token":"\",\n"}},{"name":"new_token","time":"2024-12-04T19:59:53.295936+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T19:59:53.300518+00:00","kwargs":{"token":" ...\n"}},{"name":"new_token","time":"2024-12-04T19:59:53.310002+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:53.315119+00:00","kwargs":{"token":" }\n"}},{"name":"new_token","time":"2024-12-04T19:59:53.352223+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:53.357250+00:00","kwargs":{"token":" ``"}},{"name":"new_token","time":"2024-12-04T19:59:53.366021+00:00","kwargs":{"token":"`\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:53.370627+00:00","kwargs":{"token":"4"}},{"name":"new_token","time":"2024-12-04T19:59:53.429484+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:53.434228+00:00","kwargs":{"token":" **"}},{"name":"new_token","time":"2024-12-04T19:59:53.458141+00:00","kwargs":{"token":"Debug"}},{"name":"new_token","time":"2024-12-04T19:59:53.463013+00:00","kwargs":{"token":"ging"}},{"name":"new_token","time":"2024-12-04T19:59:53.505563+00:00","kwargs":{"token":"**"}},{"name":"new_token","time":"2024-12-04T19:59:53.510494+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:53.536044+00:00","kwargs":{"token":" If"}},{"name":"new_token","time":"2024-12-04T19:59:53.541886+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:53.564354+00:00","kwargs":{"token":" issue"}},{"name":"new_token","time":"2024-12-04T19:59:53.569212+00:00","kwargs":{"token":" persists"}},{"name":"new_token","time":"2024-12-04T19:59:53.595413+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T19:59:53.599941+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T19:59:53.654991+00:00","kwargs":{"token":" can"}},{"name":"new_token","time":"2024-12-04T19:59:53.659762+00:00","kwargs":{"token":" add"}},{"name":"new_token","time":"2024-12-04T19:59:53.686489+00:00","kwargs":{"token":" print"}},{"name":"new_token","time":"2024-12-04T19:59:53.690942+00:00","kwargs":{"token":" statements"}},{"name":"new_token","time":"2024-12-04T19:59:53.716088+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T19:59:53.720616+00:00","kwargs":{"token":" check"}},{"name":"new_token","time":"2024-12-04T19:59:53.745522+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:53.750053+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:53.780536+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T19:59:53.785063+00:00","kwargs":{"token":" and"}},{"name":"new_token","time":"2024-12-04T19:59:53.833219+00:00","kwargs":{"token":" doc"}},{"name":"new_token","time":"2024-12-04T19:59:53.838103+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T19:59:53.844867+00:00","kwargs":{"token":" right"}},{"name":"new_token","time":"2024-12-04T19:59:53.848891+00:00","kwargs":{"token":" after"}},{"name":"new_token","time":"2024-12-04T19:59:53.857754+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T19:59:53.861715+00:00","kwargs":{"token":" define"}},{"name":"new_token","time":"2024-12-04T19:59:53.888435+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:53.893441+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T19:59:53.925739+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:53.936795+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:53.949200+00:00","kwargs":{"token":" This"}},{"name":"new_token","time":"2024-12-04T19:59:53.955623+00:00","kwargs":{"token":" can"}},{"name":"new_token","time":"2024-12-04T19:59:53.974023+00:00","kwargs":{"token":" help"}},{"name":"new_token","time":"2024-12-04T19:59:53.979286+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T19:59:54.003472+00:00","kwargs":{"token":" verify"}},{"name":"new_token","time":"2024-12-04T19:59:54.010623+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T19:59:54.041009+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:54.045876+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:54.083105+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T19:59:54.087875+00:00","kwargs":{"token":" being"}},{"name":"new_token","time":"2024-12-04T19:59:54.100169+00:00","kwargs":{"token":" registered"}},{"name":"new_token","time":"2024-12-04T19:59:54.104999+00:00","kwargs":{"token":" correctly"}},{"name":"new_token","time":"2024-12-04T19:59:54.126480+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:54.130995+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:54.152420+00:00","kwargs":{"token":" ```"}},{"name":"new_token","time":"2024-12-04T19:59:54.157051+00:00","kwargs":{"token":"python"}},{"name":"new_token","time":"2024-12-04T19:59:54.196888+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T19:59:54.201459+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:54.210323+00:00","kwargs":{"token":" print"}},{"name":"new_token","time":"2024-12-04T19:59:54.214869+00:00","kwargs":{"token":"(f"}},{"name":"new_token","time":"2024-12-04T19:59:54.250680+00:00","kwargs":{"token":"\""}},{"name":"new_token","time":"2024-12-04T19:59:54.255800+00:00","kwargs":{"token":"Function"}},{"name":"new_token","time":"2024-12-04T19:59:54.275862+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:54.280429+00:00","kwargs":{"token":" {"}},{"name":"new_token","time":"2024-12-04T19:59:54.300312+00:00","kwargs":{"token":"process"}},{"name":"new_token","time":"2024-12-04T19:59:54.304601+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T19:59:54.326161+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T19:59:54.330706+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T19:59:54.378685+00:00","kwargs":{"token":".__"}},{"name":"new_token","time":"2024-12-04T19:59:54.383344+00:00","kwargs":{"token":"name"}},{"name":"new_token","time":"2024-12-04T19:59:54.404047+00:00","kwargs":{"token":"__"}},{"name":"new_token","time":"2024-12-04T19:59:54.408404+00:00","kwargs":{"token":"},"}},{"name":"new_token","time":"2024-12-04T19:59:54.443045+00:00","kwargs":{"token":" Signature"}},{"name":"new_token","time":"2024-12-04T19:59:54.447935+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:54.461581+00:00","kwargs":{"token":" {"}},{"name":"new_token","time":"2024-12-04T19:59:54.466328+00:00","kwargs":{"token":"inspect"}},{"name":"new_token","time":"2024-12-04T19:59:54.497544+00:00","kwargs":{"token":".signature"}},{"name":"new_token","time":"2024-12-04T19:59:54.502774+00:00","kwargs":{"token":"(process"}},{"name":"new_token","time":"2024-12-04T19:59:54.542617+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T19:59:54.547379+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T19:59:54.554185+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T19:59:54.558967+00:00","kwargs":{"token":")},"}},{"name":"new_token","time":"2024-12-04T19:59:54.582732+00:00","kwargs":{"token":" Doc"}},{"name":"new_token","time":"2024-12-04T19:59:54.587094+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T19:59:54.614645+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:54.619250+00:00","kwargs":{"token":" {"}},{"name":"new_token","time":"2024-12-04T19:59:54.636995+00:00","kwargs":{"token":"process"}},{"name":"new_token","time":"2024-12-04T19:59:54.642178+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T19:59:54.688606+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T19:59:54.693219+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T19:59:54.734768+00:00","kwargs":{"token":".__"}},{"name":"new_token","time":"2024-12-04T19:59:54.739308+00:00","kwargs":{"token":"doc"}},{"name":"new_token","time":"2024-12-04T19:59:54.759040+00:00","kwargs":{"token":"__"}},{"name":"new_token","time":"2024-12-04T19:59:54.763401+00:00","kwargs":{"token":"}\")\n"}},{"name":"new_token","time":"2024-12-04T19:59:54.782924+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T19:59:54.787844+00:00","kwargs":{"token":" ``"}},{"name":"new_token","time":"2024-12-04T19:59:54.809583+00:00","kwargs":{"token":"`\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:54.814417+00:00","kwargs":{"token":"5"}},{"name":"new_token","time":"2024-12-04T19:59:54.841507+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:54.846030+00:00","kwargs":{"token":" **"}},{"name":"new_token","time":"2024-12-04T19:59:54.874744+00:00","kwargs":{"token":"Re"}},{"name":"new_token","time":"2024-12-04T19:59:54.879571+00:00","kwargs":{"token":"-run"}},{"name":"new_token","time":"2024-12-04T19:59:54.900942+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:54.905811+00:00","kwargs":{"token":" Tests"}},{"name":"new_token","time":"2024-12-04T19:59:54.942678+00:00","kwargs":{"token":"**"}},{"name":"new_token","time":"2024-12-04T19:59:54.947306+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:55.018763+00:00","kwargs":{"token":" After"}},{"name":"new_token","time":"2024-12-04T19:59:55.023470+00:00","kwargs":{"token":" making"}},{"name":"new_token","time":"2024-12-04T19:59:55.135357+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:55.139940+00:00","kwargs":{"token":" necessary"}},{"name":"new_token","time":"2024-12-04T19:59:55.173427+00:00","kwargs":{"token":" adjustments"}},{"name":"new_token","time":"2024-12-04T19:59:55.178365+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T19:59:55.204142+00:00","kwargs":{"token":" re"}},{"name":"new_token","time":"2024-12-04T19:59:55.208616+00:00","kwargs":{"token":"-run"}},{"name":"new_token","time":"2024-12-04T19:59:55.263576+00:00","kwargs":{"token":" your"}},{"name":"new_token","time":"2024-12-04T19:59:55.269229+00:00","kwargs":{"token":" tests"}},{"name":"new_token","time":"2024-12-04T19:59:55.275493+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T19:59:55.280050+00:00","kwargs":{"token":" see"}},{"name":"new_token","time":"2024-12-04T19:59:55.294732+00:00","kwargs":{"token":" if"}},{"name":"new_token","time":"2024-12-04T19:59:55.299971+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:55.321017+00:00","kwargs":{"token":" issue"}},{"name":"new_token","time":"2024-12-04T19:59:55.325587+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T19:59:55.350310+00:00","kwargs":{"token":" resolved"}},{"name":"new_token","time":"2024-12-04T19:59:55.355190+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:55.388920+00:00","kwargs":{"token":"###"}},{"name":"new_token","time":"2024-12-04T19:59:55.393561+00:00","kwargs":{"token":" Example"}},{"name":"new_token","time":"2024-12-04T19:59:55.413340+00:00","kwargs":{"token":" of"}},{"name":"new_token","time":"2024-12-04T19:59:55.418370+00:00","kwargs":{"token":" Correct"}},{"name":"new_token","time":"2024-12-04T19:59:55.444433+00:00","kwargs":{"token":" Tool"}},{"name":"new_token","time":"2024-12-04T19:59:55.448159+00:00","kwargs":{"token":" Function"}},{"name":"new_token","time":"2024-12-04T19:59:55.472379+00:00","kwargs":{"token":"\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:55.476976+00:00","kwargs":{"token":"Here"}},{"name":"new_token","time":"2024-12-04T19:59:55.500420+00:00","kwargs":{"token":"’s"}},{"name":"new_token","time":"2024-12-04T19:59:55.506147+00:00","kwargs":{"token":" a"}},{"name":"new_token","time":"2024-12-04T19:59:55.561715+00:00","kwargs":{"token":" complete"}},{"name":"new_token","time":"2024-12-04T19:59:55.567263+00:00","kwargs":{"token":" example"}},{"name":"new_token","time":"2024-12-04T19:59:55.820508+00:00","kwargs":{"token":" of"}},{"name":"new_token","time":"2024-12-04T19:59:55.824490+00:00","kwargs":{"token":" how"}},{"name":"new_token","time":"2024-12-04T19:59:55.839286+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:55.844194+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T19:59:55.848192+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:55.851959+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T19:59:55.855641+00:00","kwargs":{"token":" be"}},{"name":"new_token","time":"2024-12-04T19:59:55.859286+00:00","kwargs":{"token":" defined"}},{"name":"new_token","time":"2024-12-04T19:59:55.863126+00:00","kwargs":{"token":" and"}},{"name":"new_token","time":"2024-12-04T19:59:55.867015+00:00","kwargs":{"token":" registered"}},{"name":"new_token","time":"2024-12-04T19:59:55.870697+00:00","kwargs":{"token":":\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:55.875537+00:00","kwargs":{"token":"```"}},{"name":"new_token","time":"2024-12-04T19:59:55.880513+00:00","kwargs":{"token":"python"}},{"name":"new_token","time":"2024-12-04T19:59:55.895968+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T19:59:55.900792+00:00","kwargs":{"token":"@"}},{"name":"new_token","time":"2024-12-04T19:59:55.918972+00:00","kwargs":{"token":"tool"}},{"name":"new_token","time":"2024-12-04T19:59:55.922585+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T19:59:55.958528+00:00","kwargs":{"token":"def"}},{"name":"new_token","time":"2024-12-04T19:59:55.964226+00:00","kwargs":{"token":" process"}},{"name":"new_token","time":"2024-12-04T19:59:55.978573+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T19:59:55.983659+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T19:59:56.011476+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T19:59:56.016106+00:00","kwargs":{"token":"(query"}},{"name":"new_token","time":"2024-12-04T19:59:56.049681+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:56.053386+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T19:59:56.273593+00:00","kwargs":{"token":")"}},{"name":"new_token","time":"2024-12-04T19:59:56.278786+00:00","kwargs":{"token":" ->"}},{"name":"new_token","time":"2024-12-04T19:59:56.360205+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T19:59:56.365156+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T19:59:56.381312+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T19:59:56.384925+00:00","kwargs":{"token":" \"\"\"\n"}},{"name":"new_token","time":"2024-12-04T19:59:56.390483+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T19:59:56.395376+00:00","kwargs":{"token":" Process"}},{"name":"new_token","time":"2024-12-04T19:59:56.399167+00:00","kwargs":{"token":" a"}},{"name":"new_token","time":"2024-12-04T19:59:56.402862+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T19:59:56.406399+00:00","kwargs":{"token":"-related"}},{"name":"new_token","time":"2024-12-04T19:59:56.410048+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T19:59:56.414560+00:00","kwargs":{"token":" using"}},{"name":"new_token","time":"2024-12-04T19:59:56.418146+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:56.422309+00:00","kwargs":{"token":" specialized"}},{"name":"new_token","time":"2024-12-04T19:59:56.427183+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T19:59:56.432846+00:00","kwargs":{"token":" workflow"}},{"name":"new_token","time":"2024-12-04T19:59:56.437627+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:56.442587+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T19:59:56.446749+00:00","kwargs":{"token":" Args"}},{"name":"new_token","time":"2024-12-04T19:59:56.459429+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T19:59:56.464173+00:00","kwargs":{"token":"       "}},{"name":"new_token","time":"2024-12-04T19:59:56.501002+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T19:59:56.506379+00:00","kwargs":{"token":" ("}},{"name":"new_token","time":"2024-12-04T19:59:56.515868+00:00","kwargs":{"token":"str"}},{"name":"new_token","time":"2024-12-04T19:59:56.520606+00:00","kwargs":{"token":"):"}},{"name":"new_token","time":"2024-12-04T19:59:56.547874+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T19:59:56.552382+00:00","kwargs":{"token":" user's"}},{"name":"new_token","time":"2024-12-04T19:59:56.580713+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T19:59:56.586342+00:00","kwargs":{"token":"-related"}},{"name":"new_token","time":"2024-12-04T19:59:56.602393+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T19:59:56.606115+00:00","kwargs":{"token":"\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:56.666750+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T19:59:56.671800+00:00","kwargs":{"token":" Returns"}},{"name":"new_token","time":"2024-12-04T19:59:56.678148+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T19:59:56.682717+00:00","kwargs":{"token":"       "}},{"name":"new_token","time":"2024-12-04T19:59:56.694461+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T19:59:56.699101+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T19:59:56.759261+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T19:59:56.764010+00:00","kwargs":{"token":" response"}},{"name":"new_token","time":"2024-12-04T19:59:56.767987+00:00","kwargs":{"token":" from"}},{"name":"new_token","time":"2024-12-04T19:59:56.771766+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:56.798168+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T19:59:56.802968+00:00","kwargs":{"token":" workflow"}},{"name":"new_token","time":"2024-12-04T19:59:56.819738+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T19:59:56.824256+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T19:59:56.851999+00:00","kwargs":{"token":" \"\"\"\n"}},{"name":"new_token","time":"2024-12-04T19:59:56.855881+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T19:59:56.861477+00:00","kwargs":{"token":" return"}},{"name":"new_token","time":"2024-12-04T19:59:56.866151+00:00","kwargs":{"token":" [{\""}},{"name":"new_token","time":"2024-12-04T19:59:56.895559+00:00","kwargs":{"token":"claim"}},{"name":"new_token","time":"2024-12-04T19:59:56.899262+00:00","kwargs":{"token":"_id"}},{"name":"new_token","time":"2024-12-04T19:59:56.940235+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:56.945028+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:56.968699+00:00","kwargs":{"token":"123"}},{"name":"new_token","time":"2024-12-04T19:59:56.973250+00:00","kwargs":{"token":"4"}},{"name":"new_token","time":"2024-12-04T19:59:57.004384+00:00","kwargs":{"token":"\","}},{"name":"new_token","time":"2024-12-04T19:59:57.009158+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:57.042593+00:00","kwargs":{"token":"status"}},{"name":"new_token","time":"2024-12-04T19:59:57.047486+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:57.064985+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:57.069388+00:00","kwargs":{"token":"pending"}},{"name":"new_token","time":"2024-12-04T19:59:57.090559+00:00","kwargs":{"token":"\"},"}},{"name":"new_token","time":"2024-12-04T19:59:57.095402+00:00","kwargs":{"token":" {\""}},{"name":"new_token","time":"2024-12-04T19:59:57.119062+00:00","kwargs":{"token":"claim"}},{"name":"new_token","time":"2024-12-04T19:59:57.123477+00:00","kwargs":{"token":"_id"}},{"name":"new_token","time":"2024-12-04T19:59:57.186459+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:57.190364+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:57.193893+00:00","kwargs":{"token":"567"}},{"name":"new_token","time":"2024-12-04T19:59:57.197239+00:00","kwargs":{"token":"8"}},{"name":"new_token","time":"2024-12-04T19:59:57.286432+00:00","kwargs":{"token":"\","}},{"name":"new_token","time":"2024-12-04T19:59:57.291618+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:57.297096+00:00","kwargs":{"token":"status"}},{"name":"new_token","time":"2024-12-04T19:59:57.301609+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T19:59:57.306688+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T19:59:57.311095+00:00","kwargs":{"token":"approved"}},{"name":"new_token","time":"2024-12-04T19:59:57.337789+00:00","kwargs":{"token":"\"}"}},{"name":"new_token","time":"2024-12-04T19:59:57.342273+00:00","kwargs":{"token":"]\n"}},{"name":"new_token","time":"2024-12-04T19:59:57.360721+00:00","kwargs":{"token":"``"}},{"name":"new_token","time":"2024-12-04T19:59:57.364695+00:00","kwargs":{"token":"`\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:57.408555+00:00","kwargs":{"token":"###"}},{"name":"new_token","time":"2024-12-04T19:59:57.413616+00:00","kwargs":{"token":" Conclusion"}},{"name":"new_token","time":"2024-12-04T19:59:57.420142+00:00","kwargs":{"token":"\n\n"}},{"name":"new_token","time":"2024-12-04T19:59:57.424688+00:00","kwargs":{"token":"By"}},{"name":"new_token","time":"2024-12-04T19:59:57.441932+00:00","kwargs":{"token":" ensuring"}},{"name":"new_token","time":"2024-12-04T19:59:57.446512+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T19:59:57.483096+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:57.487797+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:57.505618+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T19:59:57.510283+00:00","kwargs":{"token":" matches"}},{"name":"new_token","time":"2024-12-04T19:59:57.524548+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:57.529086+00:00","kwargs":{"token":" argument"}},{"name":"new_token","time":"2024-12-04T19:59:57.661137+00:00","kwargs":{"token":" descriptions"}},{"name":"new_token","time":"2024-12-04T19:59:57.666707+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T19:59:57.674144+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:57.678308+00:00","kwargs":{"token":" doc"}},{"name":"new_token","time":"2024-12-04T19:59:57.682776+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T19:59:57.687783+00:00","kwargs":{"token":" and"}},{"name":"new_token","time":"2024-12-04T19:59:57.691725+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T19:59:57.695534+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:57.701750+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:57.706573+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T19:59:57.791543+00:00","kwargs":{"token":" properly"}},{"name":"new_token","time":"2024-12-04T19:59:57.797011+00:00","kwargs":{"token":" registered"}},{"name":"new_token","time":"2024-12-04T19:59:57.837305+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T19:59:57.842904+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T19:59:57.856869+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T19:59:57.861646+00:00","kwargs":{"token":" be"}},{"name":"new_token","time":"2024-12-04T19:59:57.880464+00:00","kwargs":{"token":" able"}},{"name":"new_token","time":"2024-12-04T19:59:57.884942+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T19:59:57.912669+00:00","kwargs":{"token":" resolve"}},{"name":"new_token","time":"2024-12-04T19:59:57.917264+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:57.940136+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T19:59:57.944833+00:00","kwargs":{"token":"Value"}},{"name":"new_token","time":"2024-12-04T19:59:58.025985+00:00","kwargs":{"token":"Error"}},{"name":"new_token","time":"2024-12-04T19:59:58.030544+00:00","kwargs":{"token":"`"}},{"name":"new_token","time":"2024-12-04T19:59:58.049251+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T19:59:58.053890+00:00","kwargs":{"token":" are"}},{"name":"new_token","time":"2024-12-04T19:59:58.065227+00:00","kwargs":{"token":" encountering"}},{"name":"new_token","time":"2024-12-04T19:59:58.071106+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:58.118548+00:00","kwargs":{"token":" If"}},{"name":"new_token","time":"2024-12-04T19:59:58.122165+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T19:59:58.137465+00:00","kwargs":{"token":" continue"}},{"name":"new_token","time":"2024-12-04T19:59:58.141868+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T19:59:58.168941+00:00","kwargs":{"token":" face"}},{"name":"new_token","time":"2024-12-04T19:59:58.174161+00:00","kwargs":{"token":" issues"}},{"name":"new_token","time":"2024-12-04T19:59:58.256692+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T19:59:58.264897+00:00","kwargs":{"token":" consider"}},{"name":"new_token","time":"2024-12-04T19:59:58.297354+00:00","kwargs":{"token":" checking"}},{"name":"new_token","time":"2024-12-04T19:59:58.302029+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:58.305725+00:00","kwargs":{"token":" context"}},{"name":"new_token","time":"2024-12-04T19:59:58.309164+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T19:59:58.312596+00:00","kwargs":{"token":" which"}},{"name":"new_token","time":"2024-12-04T19:59:58.316237+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T19:59:58.328925+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T19:59:58.333486+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T19:59:58.358669+00:00","kwargs":{"token":" being"}},{"name":"new_token","time":"2024-12-04T19:59:58.363572+00:00","kwargs":{"token":" executed"}},{"name":"new_token","time":"2024-12-04T19:59:58.384154+00:00","kwargs":{"token":" and"}},{"name":"new_token","time":"2024-12-04T19:59:58.389478+00:00","kwargs":{"token":" ensure"}},{"name":"new_token","time":"2024-12-04T19:59:58.416705+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T19:59:58.422363+00:00","kwargs":{"token":" all"}},{"name":"new_token","time":"2024-12-04T19:59:58.449444+00:00","kwargs":{"token":" dependencies"}},{"name":"new_token","time":"2024-12-04T19:59:58.454405+00:00","kwargs":{"token":" are"}},{"name":"new_token","time":"2024-12-04T19:59:58.484114+00:00","kwargs":{"token":" correctly"}},{"name":"new_token","time":"2024-12-04T19:59:58.489023+00:00","kwargs":{"token":" set"}},{"name":"new_token","time":"2024-12-04T19:59:58.503739+00:00","kwargs":{"token":" up"}},{"name":"new_token","time":"2024-12-04T19:59:58.507468+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T19:59:58.511362+00:00","kwargs":{"token":""}},{"name":"end","time":"2024-12-04T19:59:58.523112+00:00"}],"inputs":{"messages":[[{"lc":1,"type":"constructor","id":["langchain","schema","messages","SystemMessage"],"kwargs":{"content":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${number}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity.\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    <documents>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='594f3236-69b3-5723-8a2a-a67328032782'>\n{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}\n</document>\n<document  description='Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' title='Spreedly | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' uuid='be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee'>\n```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n</document>\n<document  language='en' description=\"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.\" changefreq='weekly' source='https://python.langchain.com/docs/how_to/graph_mapping/' title='How to map values to a graph database | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/graph_mapping/' uuid='ca98b026-baac-5e7f-b687-b177bbf581a0'>\nchain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)\n</document>\n<document  language='en' description='Learn about how the self-querying retriever works here.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/retrievers/self_query/' title='Self-querying retrievers | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/retrievers/self_query/' uuid='315c889a-0f5a-531c-93d4-6c64c77d8abf'>\nSelf-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).\n</document>\n<document  language='en' description='Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.' changefreq='weekly' source='https://python.langchain.com/docs/how_to/query_no_queries/' title='How to handle cases where no queries are generated | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/query_no_queries/' uuid='7c753e2b-c599-5f69-a535-539b12f6c2ed'>\n```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)\n</document>\n<document  description='This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' title='ArcGIS | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' uuid='a9dd78eb-3537-55b1-9e6d-99f9d35a489e'>\n\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```\n</document>\n<document  description='Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.' language='en' changefreq=None source='https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax' title='Trace query syntax | 🦜️🛠️ LangSmith' content_type='text/html; charset=utf-8' lastmod=None priority=None loc=None uuid='6103ddb5-52da-5eae-a911-513966d65f00'>\nTrace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\n</document>\n<document  description=\"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.\" language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/sql_query_checking/' title='How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/sql_query_checking/' uuid='5cea0388-8300-5f71-8f8f-8a94daff7a9d'>\n```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='7ed75ace-8a2b-55de-a415-25083eeba332'>\nquery_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n</document>\n<document  description='This guide assumes familiarity with the following concepts:' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/tool_stream_events/' title='How to stream events from a tool | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/tool_stream_events/' uuid='51f0caf5-c4da-5d8d-9eea-5838a8fb4081'>\n## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)\n</document>\n<document  language='en' description=\"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾\" changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/gradio_tools/' title='Gradio | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/gradio_tools/' uuid='7f36aaa8-0f01-59e6-a58b-df56996a9048'>\nJob Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)\n</document>\n<document  description='ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/clickup/' title='ClickUp Toolkit | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/clickup/' uuid='1a2a0382-266f-5818-9794-e1d0b756039b'>\n```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)\n</document>\n<document  language='' description='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='483a01c0-c8d8-568d-80e3-4c7349518f0d'>\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' title='Review Tool Calls | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' uuid='a7380d1f-89be-5df5-9f1e-6b74afb1a49d'>\nOutput:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '\n</document>\n<document  description=\"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.\" language='en' changefreq=None source='https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api' title='Manage your organization using the API | 🦜️🛠️ LangSmith' lastmod=None content_type='text/html; charset=utf-8' priority=None loc=None uuid='cd89709f-0016-5447-9ab3-2e9efb7db0fa'>\nSample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.\n</document>\n<document  description='You are passing too many, too few, or mismatched ToolMessages to a model.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' title='INVALID_TOOL_RESULTS | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' uuid='62856b31-ccd6-527f-a540-677a2f8170eb'>\nSee [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  language='en' description='ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/providers/datadog/' title='Datadog Tracing | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/providers/datadog/' uuid='aac182d0-171a-5d65-a00e-60b5a764e813'>\n## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  description='JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/document_loader_json/' title='How to load JSON | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/document_loader_json/' uuid='67c83a8d-a61d-5338-a82c-cedaa5def0c1'>\nJSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' title='SDK (Python) | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' uuid='d7081e58-73a0-55f5-9a3f-25d019980493'>\n}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' title='How to create agents with configuration | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' uuid='19b61e09-1d71-560a-a077-a45a31445149'>\nHow to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'\n</document>\n</documents>\n<context/>","type":"system"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","tool_calls":[],"invalid_tool_calls":[]}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","tool_calls":[],"invalid_tool_calls":[]}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd"}}]]},"run_type":"llm","extra":{"invocation_params":{"model":"gpt-4o-mini","model_name":"gpt-4o-mini","stream":false,"n":1,"temperature":0.0,"_type":"openai-chat","stop":null},"options":{"stop":null},"batch_size":1,"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":19,"langgraph_node":"respond","langgraph_triggers":["branch:conduct_research:check_finished:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","ls_provider":"openai","ls_model_name":"gpt-4o-mini","ls_model_type":"chat","ls_temperature":0.0,"LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195945581522Z3ae3e54f-7361-43f7-b606-58e7f71137e7.20241204T195945693555Z7d69b282-55a6-4665-8dd8-50146bca4a14"}
{"id":"7d69b282-55a6-4665-8dd8-50146bca4a14","name":"ChatOpenAI","end_time":"2024-12-04T19:59:58.523112","error":null,"outputs":{"generations":[{"text":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","generation_info":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ChatGeneration","message":{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-7d69b282-55a6-4665-8dd8-50146bca4a14","tool_calls":[],"invalid_tool_calls":[]}}}],"llm_output":null,"run":null,"type":"LLMResult"}}
{"id":"9c875e8c-4352-48f6-98f6-387d5f03df44","name":"_write","start_time":"2024-12-04T19:59:58.547006","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:58.547006+00:00"},{"name":"end","time":"2024-12-04T19:59:58.551758+00:00"}],"inputs":{"messages":[{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-7d69b282-55a6-4665-8dd8-50146bca4a14","example":false,"tool_calls":[],"invalid_tool_calls":[]}],"answer":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","num_response_attempts":1},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":19,"langgraph_node":"respond","langgraph_triggers":["branch:conduct_research:check_finished:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195945581522Z3ae3e54f-7361-43f7-b606-58e7f71137e7.20241204T195958547006Z9c875e8c-4352-48f6-98f6-387d5f03df44"}
{"id":"9c875e8c-4352-48f6-98f6-387d5f03df44","name":"_write","end_time":"2024-12-04T19:59:58.551758","error":null,"outputs":{"messages":[{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-7d69b282-55a6-4665-8dd8-50146bca4a14","example":false,"tool_calls":[],"invalid_tool_calls":[]}],"answer":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","num_response_attempts":1}}
{"id":"48f9a406-0872-4d31-b201-85fbf1dfc4a1","name":"check_hallucination","start_time":"2024-12-04T19:59:58.639104","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:58.639104+00:00"},{"name":"end","time":"2024-12-04T20:00:01.237052+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false},{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-7d69b282-55a6-4665-8dd8-50146bca4a14","example":false,"tool_calls":[],"invalid_tool_calls":[]}],"router":{"type":"general","logic":""},"steps":[],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}],"answer":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":1}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":19,"langgraph_node":"respond","langgraph_triggers":["branch:conduct_research:check_finished:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:4"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195945581522Z3ae3e54f-7361-43f7-b606-58e7f71137e7.20241204T195958639104Z48f9a406-0872-4d31-b201-85fbf1dfc4a1"}
{"id":"48f9a406-0872-4d31-b201-85fbf1dfc4a1","name":"check_hallucination","end_time":"2024-12-04T20:00:01.237052","error":null,"outputs":{"output":"respond"}}
{"id":"ea837153-c43b-4713-b138-80e9ca6ebcf8","name":"RunnableSequence","start_time":"2024-12-04T19:59:58.968291","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:58.968291+00:00"},{"name":"end","time":"2024-12-04T20:00:01.221709+00:00"}],"inputs":{"input":[{"role":"system","content":"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \n \n    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts."},{"role":"human","content":"Set of facts: \n\n <documents>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='594f3236-69b3-5723-8a2a-a67328032782'>\n{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}\n</document>\n<document  description='Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' title='Spreedly | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' uuid='be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee'>\n```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n</document>\n<document  language='en' description=\"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.\" changefreq='weekly' source='https://python.langchain.com/docs/how_to/graph_mapping/' title='How to map values to a graph database | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/graph_mapping/' uuid='ca98b026-baac-5e7f-b687-b177bbf581a0'>\nchain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)\n</document>\n<document  language='en' description='Learn about how the self-querying retriever works here.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/retrievers/self_query/' title='Self-querying retrievers | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/retrievers/self_query/' uuid='315c889a-0f5a-531c-93d4-6c64c77d8abf'>\nSelf-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).\n</document>\n<document  language='en' description='Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.' changefreq='weekly' source='https://python.langchain.com/docs/how_to/query_no_queries/' title='How to handle cases where no queries are generated | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/query_no_queries/' uuid='7c753e2b-c599-5f69-a535-539b12f6c2ed'>\n```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)\n</document>\n<document  description='This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' title='ArcGIS | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' uuid='a9dd78eb-3537-55b1-9e6d-99f9d35a489e'>\n\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```\n</document>\n<document  description='Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.' language='en' changefreq=None source='https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax' title='Trace query syntax | 🦜️🛠️ LangSmith' content_type='text/html; charset=utf-8' lastmod=None priority=None loc=None uuid='6103ddb5-52da-5eae-a911-513966d65f00'>\nTrace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\n</document>\n<document  description=\"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.\" language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/sql_query_checking/' title='How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/sql_query_checking/' uuid='5cea0388-8300-5f71-8f8f-8a94daff7a9d'>\n```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='7ed75ace-8a2b-55de-a415-25083eeba332'>\nquery_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n</document>\n<document  description='This guide assumes familiarity with the following concepts:' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/tool_stream_events/' title='How to stream events from a tool | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/tool_stream_events/' uuid='51f0caf5-c4da-5d8d-9eea-5838a8fb4081'>\n## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)\n</document>\n<document  language='en' description=\"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾\" changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/gradio_tools/' title='Gradio | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/gradio_tools/' uuid='7f36aaa8-0f01-59e6-a58b-df56996a9048'>\nJob Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)\n</document>\n<document  description='ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/clickup/' title='ClickUp Toolkit | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/clickup/' uuid='1a2a0382-266f-5818-9794-e1d0b756039b'>\n```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)\n</document>\n<document  language='' description='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='483a01c0-c8d8-568d-80e3-4c7349518f0d'>\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' title='Review Tool Calls | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' uuid='a7380d1f-89be-5df5-9f1e-6b74afb1a49d'>\nOutput:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '\n</document>\n<document  description=\"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.\" language='en' changefreq=None source='https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api' title='Manage your organization using the API | 🦜️🛠️ LangSmith' lastmod=None content_type='text/html; charset=utf-8' priority=None loc=None uuid='cd89709f-0016-5447-9ab3-2e9efb7db0fa'>\nSample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.\n</document>\n<document  description='You are passing too many, too few, or mismatched ToolMessages to a model.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' title='INVALID_TOOL_RESULTS | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' uuid='62856b31-ccd6-527f-a540-677a2f8170eb'>\nSee [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  language='en' description='ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/providers/datadog/' title='Datadog Tracing | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/providers/datadog/' uuid='aac182d0-171a-5d65-a00e-60b5a764e813'>\n## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  description='JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/document_loader_json/' title='How to load JSON | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/document_loader_json/' uuid='67c83a8d-a61d-5338-a82c-cedaa5def0c1'>\nJSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' title='SDK (Python) | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' uuid='d7081e58-73a0-55f5-9a3f-25d019980493'>\n}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' title='How to create agents with configuration | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' uuid='19b61e09-1d71-560a-a077-a45a31445149'>\nHow to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'\n</document>\n</documents> \n\n LLM generation: The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up."}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":19,"langgraph_node":"respond","langgraph_triggers":["branch:conduct_research:check_finished:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":[],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195945581522Z3ae3e54f-7361-43f7-b606-58e7f71137e7.20241204T195958639104Z48f9a406-0872-4d31-b201-85fbf1dfc4a1.20241204T195958968291Zea837153-c43b-4713-b138-80e9ca6ebcf8"}
{"id":"ea837153-c43b-4713-b138-80e9ca6ebcf8","name":"RunnableSequence","end_time":"2024-12-04T20:00:01.221709","error":null,"outputs":{"output":{"binary_score":"no"}}}
{"id":"df853ec8-1d97-48e7-8f9c-78f6fe01a469","name":"ChatOpenAI","start_time":"2024-12-04T19:59:58.989805","serialized":null,"events":[{"name":"start","time":"2024-12-04T19:59:58.989805+00:00"},{"name":"new_token","time":"2024-12-04T20:00:00.938115+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:01.043677+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:01.090411+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:01.098279+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:01.109578+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:01.114402+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:01.118246+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:01.137247+00:00","kwargs":{"token":""}},{"name":"end","time":"2024-12-04T20:00:01.206620+00:00"}],"inputs":{"messages":[[{"lc":1,"type":"constructor","id":["langchain","schema","messages","SystemMessage"],"kwargs":{"content":"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \n \n    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.","type":"system"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"Set of facts: \n\n <documents>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='594f3236-69b3-5723-8a2a-a67328032782'>\n{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}\n</document>\n<document  description='Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' title='Spreedly | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' uuid='be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee'>\n```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n</document>\n<document  language='en' description=\"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.\" changefreq='weekly' source='https://python.langchain.com/docs/how_to/graph_mapping/' title='How to map values to a graph database | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/graph_mapping/' uuid='ca98b026-baac-5e7f-b687-b177bbf581a0'>\nchain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)\n</document>\n<document  language='en' description='Learn about how the self-querying retriever works here.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/retrievers/self_query/' title='Self-querying retrievers | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/retrievers/self_query/' uuid='315c889a-0f5a-531c-93d4-6c64c77d8abf'>\nSelf-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).\n</document>\n<document  language='en' description='Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.' changefreq='weekly' source='https://python.langchain.com/docs/how_to/query_no_queries/' title='How to handle cases where no queries are generated | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/query_no_queries/' uuid='7c753e2b-c599-5f69-a535-539b12f6c2ed'>\n```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)\n</document>\n<document  description='This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' title='ArcGIS | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' uuid='a9dd78eb-3537-55b1-9e6d-99f9d35a489e'>\n\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```\n</document>\n<document  description='Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.' language='en' changefreq=None source='https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax' title='Trace query syntax | 🦜️🛠️ LangSmith' content_type='text/html; charset=utf-8' lastmod=None priority=None loc=None uuid='6103ddb5-52da-5eae-a911-513966d65f00'>\nTrace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\n</document>\n<document  description=\"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.\" language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/sql_query_checking/' title='How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/sql_query_checking/' uuid='5cea0388-8300-5f71-8f8f-8a94daff7a9d'>\n```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='7ed75ace-8a2b-55de-a415-25083eeba332'>\nquery_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n</document>\n<document  description='This guide assumes familiarity with the following concepts:' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/tool_stream_events/' title='How to stream events from a tool | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/tool_stream_events/' uuid='51f0caf5-c4da-5d8d-9eea-5838a8fb4081'>\n## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)\n</document>\n<document  language='en' description=\"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾\" changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/gradio_tools/' title='Gradio | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/gradio_tools/' uuid='7f36aaa8-0f01-59e6-a58b-df56996a9048'>\nJob Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)\n</document>\n<document  description='ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/clickup/' title='ClickUp Toolkit | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/clickup/' uuid='1a2a0382-266f-5818-9794-e1d0b756039b'>\n```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)\n</document>\n<document  language='' description='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='483a01c0-c8d8-568d-80e3-4c7349518f0d'>\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' title='Review Tool Calls | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' uuid='a7380d1f-89be-5df5-9f1e-6b74afb1a49d'>\nOutput:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '\n</document>\n<document  description=\"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.\" language='en' changefreq=None source='https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api' title='Manage your organization using the API | 🦜️🛠️ LangSmith' lastmod=None content_type='text/html; charset=utf-8' priority=None loc=None uuid='cd89709f-0016-5447-9ab3-2e9efb7db0fa'>\nSample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.\n</document>\n<document  description='You are passing too many, too few, or mismatched ToolMessages to a model.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' title='INVALID_TOOL_RESULTS | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' uuid='62856b31-ccd6-527f-a540-677a2f8170eb'>\nSee [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  language='en' description='ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/providers/datadog/' title='Datadog Tracing | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/providers/datadog/' uuid='aac182d0-171a-5d65-a00e-60b5a764e813'>\n## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  description='JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/document_loader_json/' title='How to load JSON | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/document_loader_json/' uuid='67c83a8d-a61d-5338-a82c-cedaa5def0c1'>\nJSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' title='SDK (Python) | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' uuid='d7081e58-73a0-55f5-9a3f-25d019980493'>\n}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' title='How to create agents with configuration | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' uuid='19b61e09-1d71-560a-a077-a45a31445149'>\nHow to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'\n</document>\n</documents> \n\n LLM generation: The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","type":"human"}}]]},"run_type":"llm","extra":{"invocation_params":{"model":"gpt-4o-mini","model_name":"gpt-4o-mini","stream":false,"n":1,"temperature":0.0,"_type":"openai-chat","stop":null,"tools":[{"type":"function","function":{"name":"GradeHallucinations","description":"Binary score for hallucination present in generation answer.","parameters":{"properties":{"binary_score":{"description":"Answer is grounded in the facts, 'yes' or 'no'","type":"string"}},"required":["binary_score"],"type":"object"}}}],"parallel_tool_calls":false,"tool_choice":{"type":"function","function":{"name":"GradeHallucinations"}}},"options":{"stop":null},"batch_size":1,"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":19,"langgraph_node":"respond","langgraph_triggers":["branch:conduct_research:check_finished:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","ls_provider":"openai","ls_model_name":"gpt-4o-mini","ls_model_type":"chat","ls_temperature":0.0,"LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195945581522Z3ae3e54f-7361-43f7-b606-58e7f71137e7.20241204T195958639104Z48f9a406-0872-4d31-b201-85fbf1dfc4a1.20241204T195958968291Zea837153-c43b-4713-b138-80e9ca6ebcf8.20241204T195958989805Zdf853ec8-1d97-48e7-8f9c-78f6fe01a469"}
{"id":"df853ec8-1d97-48e7-8f9c-78f6fe01a469","name":"ChatOpenAI","end_time":"2024-12-04T20:00:01.206620","error":null,"outputs":{"generations":[{"text":"","generation_info":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ChatGeneration","message":{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_hW0AovDHByAv2TZfgTlT5cRH","function":{"arguments":"{\"binary_score\":\"no\"}","name":"GradeHallucinations"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-df853ec8-1d97-48e7-8f9c-78f6fe01a469","tool_calls":[{"name":"GradeHallucinations","args":{"binary_score":"no"},"id":"call_hW0AovDHByAv2TZfgTlT5cRH","type":"tool_call"}],"invalid_tool_calls":[]}}}],"llm_output":null,"run":null,"type":"LLMResult"}}
{"id":"164c1b92-06d7-46bc-bc90-02318802b0a9","name":"PydanticToolsParser","start_time":"2024-12-04T20:00:01.212753","serialized":null,"events":[{"name":"start","time":"2024-12-04T20:00:01.212753+00:00"},{"name":"end","time":"2024-12-04T20:00:01.217265+00:00"}],"inputs":{"input":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_hW0AovDHByAv2TZfgTlT5cRH","function":{"arguments":"{\"binary_score\":\"no\"}","name":"GradeHallucinations"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-df853ec8-1d97-48e7-8f9c-78f6fe01a469","example":false,"tool_calls":[{"name":"GradeHallucinations","args":{"binary_score":"no"},"id":"call_hW0AovDHByAv2TZfgTlT5cRH","type":"tool_call"}],"invalid_tool_calls":[]}},"run_type":"parser","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":19,"langgraph_node":"respond","langgraph_triggers":["branch:conduct_research:check_finished:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","checkpoint_ns":"respond:726d5523-085c-5edf-d20c-17b3a8ee5bb1","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T195945581522Z3ae3e54f-7361-43f7-b606-58e7f71137e7.20241204T195958639104Z48f9a406-0872-4d31-b201-85fbf1dfc4a1.20241204T195958968291Zea837153-c43b-4713-b138-80e9ca6ebcf8.20241204T200001212753Z164c1b92-06d7-46bc-bc90-02318802b0a9"}
{"id":"164c1b92-06d7-46bc-bc90-02318802b0a9","name":"PydanticToolsParser","end_time":"2024-12-04T20:00:01.217265","error":null,"outputs":{"output":{"binary_score":"no"}}}
{"id":"85066f84-90de-4c8b-bf10-edbbe6052031","name":"respond","start_time":"2024-12-04T20:00:01.263059","serialized":null,"events":[{"name":"start","time":"2024-12-04T20:00:01.263059+00:00"},{"name":"end","time":"2024-12-04T20:00:16.452163+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false},{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-7d69b282-55a6-4665-8dd8-50146bca4a14","example":false,"tool_calls":[],"invalid_tool_calls":[]}],"router":{"type":"general","logic":""},"steps":[],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}],"answer":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":1}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":20,"langgraph_node":"respond","langgraph_triggers":["branch:respond:check_hallucination:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["graph:step:20"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T200001263059Z85066f84-90de-4c8b-bf10-edbbe6052031"}
{"id":"85066f84-90de-4c8b-bf10-edbbe6052031","name":"respond","end_time":"2024-12-04T20:00:16.452163","error":null,"outputs":{"messages":[{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-83dcd4ef-2ca1-41f8-9e85-847e0f6bed23","example":false,"tool_calls":[],"invalid_tool_calls":[]}],"answer":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","num_response_attempts":2}}
{"id":"83dcd4ef-2ca1-41f8-9e85-847e0f6bed23","name":"ChatOpenAI","start_time":"2024-12-04T20:00:01.382015","serialized":null,"events":[{"name":"start","time":"2024-12-04T20:00:01.382015+00:00"},{"name":"new_token","time":"2024-12-04T20:00:02.098357+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:02.106153+00:00","kwargs":{"token":"The"}},{"name":"new_token","time":"2024-12-04T20:00:02.111748+00:00","kwargs":{"token":" error"}},{"name":"new_token","time":"2024-12-04T20:00:02.121777+00:00","kwargs":{"token":" message"}},{"name":"new_token","time":"2024-12-04T20:00:02.169204+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T20:00:02.173689+00:00","kwargs":{"token":" are"}},{"name":"new_token","time":"2024-12-04T20:00:02.180189+00:00","kwargs":{"token":" encountering"}},{"name":"new_token","time":"2024-12-04T20:00:02.184562+00:00","kwargs":{"token":" indicates"}},{"name":"new_token","time":"2024-12-04T20:00:02.195001+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T20:00:02.201391+00:00","kwargs":{"token":" there"}},{"name":"new_token","time":"2024-12-04T20:00:02.208317+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T20:00:02.213367+00:00","kwargs":{"token":" a"}},{"name":"new_token","time":"2024-12-04T20:00:02.225834+00:00","kwargs":{"token":" mismatch"}},{"name":"new_token","time":"2024-12-04T20:00:02.232384+00:00","kwargs":{"token":" between"}},{"name":"new_token","time":"2024-12-04T20:00:02.238735+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:02.245347+00:00","kwargs":{"token":" argument"}},{"name":"new_token","time":"2024-12-04T20:00:02.259501+00:00","kwargs":{"token":" descriptions"}},{"name":"new_token","time":"2024-12-04T20:00:02.267330+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T20:00:02.272254+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:02.276778+00:00","kwargs":{"token":" doc"}},{"name":"new_token","time":"2024-12-04T20:00:02.283844+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T20:00:02.288038+00:00","kwargs":{"token":" of"}},{"name":"new_token","time":"2024-12-04T20:00:02.324167+00:00","kwargs":{"token":" your"}},{"name":"new_token","time":"2024-12-04T20:00:02.328942+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T20:00:02.345766+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:02.350537+00:00","kwargs":{"token":" and"}},{"name":"new_token","time":"2024-12-04T20:00:02.370420+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:02.375439+00:00","kwargs":{"token":" actual"}},{"name":"new_token","time":"2024-12-04T20:00:02.381535+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:02.386932+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T20:00:02.410196+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:02.416427+00:00","kwargs":{"token":" Specifically"}},{"name":"new_token","time":"2024-12-04T20:00:02.433206+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T20:00:02.439049+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:02.467710+00:00","kwargs":{"token":" error"}},{"name":"new_token","time":"2024-12-04T20:00:02.476318+00:00","kwargs":{"token":" states"}},{"name":"new_token","time":"2024-12-04T20:00:02.492711+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T20:00:02.507616+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:02.526554+00:00","kwargs":{"token":" argument"}},{"name":"new_token","time":"2024-12-04T20:00:02.531313+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T20:00:02.552185+00:00","kwargs":{"token":"query"}},{"name":"new_token","time":"2024-12-04T20:00:02.558549+00:00","kwargs":{"token":"`"}},{"name":"new_token","time":"2024-12-04T20:00:02.582183+00:00","kwargs":{"token":" ("}},{"name":"new_token","time":"2024-12-04T20:00:02.589645+00:00","kwargs":{"token":"of"}},{"name":"new_token","time":"2024-12-04T20:00:02.607577+00:00","kwargs":{"token":" type"}},{"name":"new_token","time":"2024-12-04T20:00:02.615416+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T20:00:02.641950+00:00","kwargs":{"token":"str"}},{"name":"new_token","time":"2024-12-04T20:00:02.652608+00:00","kwargs":{"token":"`)"}},{"name":"new_token","time":"2024-12-04T20:00:02.673247+00:00","kwargs":{"token":" mentioned"}},{"name":"new_token","time":"2024-12-04T20:00:02.678774+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T20:00:02.719489+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:02.724743+00:00","kwargs":{"token":" doc"}},{"name":"new_token","time":"2024-12-04T20:00:02.731616+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T20:00:02.735994+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T20:00:02.750745+00:00","kwargs":{"token":" not"}},{"name":"new_token","time":"2024-12-04T20:00:02.757010+00:00","kwargs":{"token":" found"}},{"name":"new_token","time":"2024-12-04T20:00:02.804414+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T20:00:02.814088+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:02.827071+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:02.834577+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T20:00:02.862182+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:02.869406+00:00","kwargs":{"token":"###"}},{"name":"new_token","time":"2024-12-04T20:00:02.876442+00:00","kwargs":{"token":" Steps"}},{"name":"new_token","time":"2024-12-04T20:00:02.881002+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T20:00:02.900755+00:00","kwargs":{"token":" Resolve"}},{"name":"new_token","time":"2024-12-04T20:00:02.908109+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:02.969004+00:00","kwargs":{"token":" Issue"}},{"name":"new_token","time":"2024-12-04T20:00:02.976730+00:00","kwargs":{"token":"\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:03.027619+00:00","kwargs":{"token":"1"}},{"name":"new_token","time":"2024-12-04T20:00:03.034847+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:03.039789+00:00","kwargs":{"token":" **"}},{"name":"new_token","time":"2024-12-04T20:00:03.046243+00:00","kwargs":{"token":"Check"}},{"name":"new_token","time":"2024-12-04T20:00:03.050631+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:03.075358+00:00","kwargs":{"token":" Tool"}},{"name":"new_token","time":"2024-12-04T20:00:03.086235+00:00","kwargs":{"token":" Function"}},{"name":"new_token","time":"2024-12-04T20:00:03.095557+00:00","kwargs":{"token":" Signature"}},{"name":"new_token","time":"2024-12-04T20:00:03.099714+00:00","kwargs":{"token":"**"}},{"name":"new_token","time":"2024-12-04T20:00:03.105959+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:03.111671+00:00","kwargs":{"token":" Ensure"}},{"name":"new_token","time":"2024-12-04T20:00:03.153496+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T20:00:03.157531+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:03.169620+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:03.176370+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T20:00:03.214074+00:00","kwargs":{"token":" of"}},{"name":"new_token","time":"2024-12-04T20:00:03.219360+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T20:00:03.231102+00:00","kwargs":{"token":"process"}},{"name":"new_token","time":"2024-12-04T20:00:03.235517+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T20:00:03.254605+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T20:00:03.259003+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T20:00:03.265872+00:00","kwargs":{"token":"`"}},{"name":"new_token","time":"2024-12-04T20:00:03.271025+00:00","kwargs":{"token":" matches"}},{"name":"new_token","time":"2024-12-04T20:00:03.303240+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:03.308099+00:00","kwargs":{"token":" argument"}},{"name":"new_token","time":"2024-12-04T20:00:03.328134+00:00","kwargs":{"token":" descriptions"}},{"name":"new_token","time":"2024-12-04T20:00:03.334659+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T20:00:03.355142+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:03.363255+00:00","kwargs":{"token":" doc"}},{"name":"new_token","time":"2024-12-04T20:00:03.380447+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T20:00:03.387036+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:03.418634+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T20:00:03.425248+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:03.442181+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T20:00:03.447959+00:00","kwargs":{"token":" look"}},{"name":"new_token","time":"2024-12-04T20:00:03.468171+00:00","kwargs":{"token":" something"}},{"name":"new_token","time":"2024-12-04T20:00:03.473262+00:00","kwargs":{"token":" like"}},{"name":"new_token","time":"2024-12-04T20:00:03.508649+00:00","kwargs":{"token":" this"}},{"name":"new_token","time":"2024-12-04T20:00:03.512797+00:00","kwargs":{"token":":\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:03.580588+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:03.590103+00:00","kwargs":{"token":" ```"}},{"name":"new_token","time":"2024-12-04T20:00:03.596657+00:00","kwargs":{"token":"python"}},{"name":"new_token","time":"2024-12-04T20:00:03.603185+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T20:00:03.611078+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:03.616395+00:00","kwargs":{"token":" @"}},{"name":"new_token","time":"2024-12-04T20:00:03.622106+00:00","kwargs":{"token":"tool"}},{"name":"new_token","time":"2024-12-04T20:00:03.626475+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T20:00:03.651525+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:03.655476+00:00","kwargs":{"token":" def"}},{"name":"new_token","time":"2024-12-04T20:00:03.679480+00:00","kwargs":{"token":" process"}},{"name":"new_token","time":"2024-12-04T20:00:03.684693+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T20:00:03.708858+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T20:00:03.714998+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T20:00:03.735165+00:00","kwargs":{"token":"(query"}},{"name":"new_token","time":"2024-12-04T20:00:03.740728+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:03.778739+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T20:00:03.783715+00:00","kwargs":{"token":")"}},{"name":"new_token","time":"2024-12-04T20:00:03.845666+00:00","kwargs":{"token":" ->"}},{"name":"new_token","time":"2024-12-04T20:00:03.852104+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T20:00:03.872249+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T20:00:03.877436+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T20:00:03.925087+00:00","kwargs":{"token":" \"\"\"\n"}},{"name":"new_token","time":"2024-12-04T20:00:03.929929+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T20:00:04.005104+00:00","kwargs":{"token":" Process"}},{"name":"new_token","time":"2024-12-04T20:00:04.013296+00:00","kwargs":{"token":" a"}},{"name":"new_token","time":"2024-12-04T20:00:04.021805+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T20:00:04.029193+00:00","kwargs":{"token":"-related"}},{"name":"new_token","time":"2024-12-04T20:00:04.035675+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T20:00:04.048477+00:00","kwargs":{"token":" using"}},{"name":"new_token","time":"2024-12-04T20:00:04.055609+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:04.075387+00:00","kwargs":{"token":" specialized"}},{"name":"new_token","time":"2024-12-04T20:00:04.083937+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T20:00:04.096534+00:00","kwargs":{"token":" workflow"}},{"name":"new_token","time":"2024-12-04T20:00:04.207522+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:04.557021+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T20:00:04.561163+00:00","kwargs":{"token":" Args"}},{"name":"new_token","time":"2024-12-04T20:00:04.585264+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T20:00:04.589809+00:00","kwargs":{"token":"          "}},{"name":"new_token","time":"2024-12-04T20:00:04.637656+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T20:00:04.641465+00:00","kwargs":{"token":" ("}},{"name":"new_token","time":"2024-12-04T20:00:04.673779+00:00","kwargs":{"token":"str"}},{"name":"new_token","time":"2024-12-04T20:00:04.678387+00:00","kwargs":{"token":"):"}},{"name":"new_token","time":"2024-12-04T20:00:04.711742+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T20:00:04.717687+00:00","kwargs":{"token":" user's"}},{"name":"new_token","time":"2024-12-04T20:00:04.751744+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T20:00:04.757203+00:00","kwargs":{"token":"-related"}},{"name":"new_token","time":"2024-12-04T20:00:04.792787+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T20:00:04.797692+00:00","kwargs":{"token":"\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:04.803520+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T20:00:04.807811+00:00","kwargs":{"token":" Returns"}},{"name":"new_token","time":"2024-12-04T20:00:04.830665+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T20:00:04.836282+00:00","kwargs":{"token":"          "}},{"name":"new_token","time":"2024-12-04T20:00:04.844679+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T20:00:04.851124+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:04.876735+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T20:00:04.883661+00:00","kwargs":{"token":" response"}},{"name":"new_token","time":"2024-12-04T20:00:04.929681+00:00","kwargs":{"token":" from"}},{"name":"new_token","time":"2024-12-04T20:00:04.935569+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:04.948205+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T20:00:04.955928+00:00","kwargs":{"token":" workflow"}},{"name":"new_token","time":"2024-12-04T20:00:04.969372+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T20:00:04.975283+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T20:00:05.007957+00:00","kwargs":{"token":" \"\"\"\n"}},{"name":"new_token","time":"2024-12-04T20:00:05.014788+00:00","kwargs":{"token":"      "}},{"name":"new_token","time":"2024-12-04T20:00:05.042163+00:00","kwargs":{"token":" return"}},{"name":"new_token","time":"2024-12-04T20:00:05.047427+00:00","kwargs":{"token":" [{\""}},{"name":"new_token","time":"2024-12-04T20:00:05.065709+00:00","kwargs":{"token":"claim"}},{"name":"new_token","time":"2024-12-04T20:00:05.073166+00:00","kwargs":{"token":"_id"}},{"name":"new_token","time":"2024-12-04T20:00:05.102504+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:05.111484+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:05.136159+00:00","kwargs":{"token":"123"}},{"name":"new_token","time":"2024-12-04T20:00:05.143794+00:00","kwargs":{"token":"4"}},{"name":"new_token","time":"2024-12-04T20:00:05.158303+00:00","kwargs":{"token":"\","}},{"name":"new_token","time":"2024-12-04T20:00:05.164475+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:05.203976+00:00","kwargs":{"token":"status"}},{"name":"new_token","time":"2024-12-04T20:00:05.209411+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:05.249411+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:05.254243+00:00","kwargs":{"token":"pending"}},{"name":"new_token","time":"2024-12-04T20:00:05.284797+00:00","kwargs":{"token":"\"},"}},{"name":"new_token","time":"2024-12-04T20:00:05.290482+00:00","kwargs":{"token":" {\""}},{"name":"new_token","time":"2024-12-04T20:00:05.310396+00:00","kwargs":{"token":"claim"}},{"name":"new_token","time":"2024-12-04T20:00:05.318616+00:00","kwargs":{"token":"_id"}},{"name":"new_token","time":"2024-12-04T20:00:05.345711+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:05.353045+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:05.366793+00:00","kwargs":{"token":"567"}},{"name":"new_token","time":"2024-12-04T20:00:05.373395+00:00","kwargs":{"token":"8"}},{"name":"new_token","time":"2024-12-04T20:00:05.405212+00:00","kwargs":{"token":"\","}},{"name":"new_token","time":"2024-12-04T20:00:05.415123+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:05.426043+00:00","kwargs":{"token":"status"}},{"name":"new_token","time":"2024-12-04T20:00:05.550401+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:05.566507+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:05.575516+00:00","kwargs":{"token":"approved"}},{"name":"new_token","time":"2024-12-04T20:00:05.581182+00:00","kwargs":{"token":"\"}"}},{"name":"new_token","time":"2024-12-04T20:00:05.588797+00:00","kwargs":{"token":"]\n"}},{"name":"new_token","time":"2024-12-04T20:00:05.596923+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:05.605224+00:00","kwargs":{"token":" ``"}},{"name":"new_token","time":"2024-12-04T20:00:05.611094+00:00","kwargs":{"token":"`\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:05.619960+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:05.626602+00:00","kwargs":{"token":" Make"}},{"name":"new_token","time":"2024-12-04T20:00:05.638452+00:00","kwargs":{"token":" sure"}},{"name":"new_token","time":"2024-12-04T20:00:05.645772+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T20:00:05.651334+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:05.657008+00:00","kwargs":{"token":" argument"}},{"name":"new_token","time":"2024-12-04T20:00:05.662715+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T20:00:05.690004+00:00","kwargs":{"token":"query"}},{"name":"new_token","time":"2024-12-04T20:00:05.697236+00:00","kwargs":{"token":"`"}},{"name":"new_token","time":"2024-12-04T20:00:05.707573+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T20:00:05.714685+00:00","kwargs":{"token":" indeed"}},{"name":"new_token","time":"2024-12-04T20:00:05.741081+00:00","kwargs":{"token":" defined"}},{"name":"new_token","time":"2024-12-04T20:00:05.747297+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T20:00:05.766484+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:05.770400+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:05.796411+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T20:00:05.800516+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:05.829994+00:00","kwargs":{"token":"2"}},{"name":"new_token","time":"2024-12-04T20:00:05.834541+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:05.866137+00:00","kwargs":{"token":" **"}},{"name":"new_token","time":"2024-12-04T20:00:05.871248+00:00","kwargs":{"token":"Ensure"}},{"name":"new_token","time":"2024-12-04T20:00:05.918712+00:00","kwargs":{"token":" Proper"}},{"name":"new_token","time":"2024-12-04T20:00:05.925247+00:00","kwargs":{"token":" Registration"}},{"name":"new_token","time":"2024-12-04T20:00:05.949341+00:00","kwargs":{"token":"**"}},{"name":"new_token","time":"2024-12-04T20:00:05.955436+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:05.997105+00:00","kwargs":{"token":" When"}},{"name":"new_token","time":"2024-12-04T20:00:06.002623+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T20:00:06.013513+00:00","kwargs":{"token":" dynamically"}},{"name":"new_token","time":"2024-12-04T20:00:06.018864+00:00","kwargs":{"token":" register"}},{"name":"new_token","time":"2024-12-04T20:00:06.045728+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:06.050343+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T20:00:06.093400+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:06.097443+00:00","kwargs":{"token":" using"}},{"name":"new_token","time":"2024-12-04T20:00:06.115939+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T20:00:06.121339+00:00","kwargs":{"token":"exec"}},{"name":"new_token","time":"2024-12-04T20:00:06.162436+00:00","kwargs":{"token":"`,"}},{"name":"new_token","time":"2024-12-04T20:00:06.170401+00:00","kwargs":{"token":" ensure"}},{"name":"new_token","time":"2024-12-04T20:00:06.178678+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T20:00:06.187082+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:06.198934+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:06.210759+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T20:00:06.242410+00:00","kwargs":{"token":" correctly"}},{"name":"new_token","time":"2024-12-04T20:00:06.249265+00:00","kwargs":{"token":" defined"}},{"name":"new_token","time":"2024-12-04T20:00:06.255649+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T20:00:06.265273+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:06.288315+00:00","kwargs":{"token":" global"}},{"name":"new_token","time":"2024-12-04T20:00:06.294430+00:00","kwargs":{"token":" scope"}},{"name":"new_token","time":"2024-12-04T20:00:06.313842+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:06.320964+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T20:00:06.338371+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T20:00:06.344871+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:06.392773+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T20:00:06.400846+00:00","kwargs":{"token":" be"}},{"name":"new_token","time":"2024-12-04T20:00:06.414066+00:00","kwargs":{"token":" accessible"}},{"name":"new_token","time":"2024-12-04T20:00:06.422382+00:00","kwargs":{"token":" when"}},{"name":"new_token","time":"2024-12-04T20:00:06.437442+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:07.409224+00:00","kwargs":{"token":" L"}},{"name":"new_token","time":"2024-12-04T20:00:07.425639+00:00","kwargs":{"token":"LM"}},{"name":"new_token","time":"2024-12-04T20:00:07.431752+00:00","kwargs":{"token":" tries"}},{"name":"new_token","time":"2024-12-04T20:00:07.436977+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T20:00:07.443851+00:00","kwargs":{"token":" bind"}},{"name":"new_token","time":"2024-12-04T20:00:07.451054+00:00","kwargs":{"token":" it"}},{"name":"new_token","time":"2024-12-04T20:00:07.456931+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:07.464703+00:00","kwargs":{"token":"3"}},{"name":"new_token","time":"2024-12-04T20:00:07.474167+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:07.481384+00:00","kwargs":{"token":" **"}},{"name":"new_token","time":"2024-12-04T20:00:07.485701+00:00","kwargs":{"token":"Check"}},{"name":"new_token","time":"2024-12-04T20:00:07.489886+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:07.494420+00:00","kwargs":{"token":" JSON"}},{"name":"new_token","time":"2024-12-04T20:00:07.498831+00:00","kwargs":{"token":" Configuration"}},{"name":"new_token","time":"2024-12-04T20:00:07.502794+00:00","kwargs":{"token":"**"}},{"name":"new_token","time":"2024-12-04T20:00:07.507078+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:07.511015+00:00","kwargs":{"token":" Ensure"}},{"name":"new_token","time":"2024-12-04T20:00:07.516238+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T20:00:07.523789+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:07.529083+00:00","kwargs":{"token":" JSON"}},{"name":"new_token","time":"2024-12-04T20:00:07.535194+00:00","kwargs":{"token":" configuration"}},{"name":"new_token","time":"2024-12-04T20:00:07.540174+00:00","kwargs":{"token":" correctly"}},{"name":"new_token","time":"2024-12-04T20:00:07.544106+00:00","kwargs":{"token":" specifies"}},{"name":"new_token","time":"2024-12-04T20:00:07.548809+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:07.555572+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T20:00:07.560705+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:07.564657+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:07.569706+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T20:00:07.573752+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T20:00:07.578634+00:00","kwargs":{"token":"tool"}},{"name":"new_token","time":"2024-12-04T20:00:07.584486+00:00","kwargs":{"token":"`"}},{"name":"new_token","time":"2024-12-04T20:00:07.589250+00:00","kwargs":{"token":" field"}},{"name":"new_token","time":"2024-12-04T20:00:07.594561+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T20:00:07.599737+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:07.605496+00:00","kwargs":{"token":" JSON"}},{"name":"new_token","time":"2024-12-04T20:00:07.610440+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T20:00:07.615842+00:00","kwargs":{"token":" match"}},{"name":"new_token","time":"2024-12-04T20:00:07.621069+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:07.626593+00:00","kwargs":{"token":" name"}},{"name":"new_token","time":"2024-12-04T20:00:07.631455+00:00","kwargs":{"token":" of"}},{"name":"new_token","time":"2024-12-04T20:00:07.635554+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:07.640638+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:07.646803+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T20:00:07.651696+00:00","kwargs":{"token":" are"}},{"name":"new_token","time":"2024-12-04T20:00:07.657001+00:00","kwargs":{"token":" defining"}},{"name":"new_token","time":"2024-12-04T20:00:07.661294+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:07.665018+00:00","kwargs":{"token":" For"}},{"name":"new_token","time":"2024-12-04T20:00:07.670028+00:00","kwargs":{"token":" example"}},{"name":"new_token","time":"2024-12-04T20:00:07.674359+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T20:00:07.679284+00:00","kwargs":{"token":" if"}},{"name":"new_token","time":"2024-12-04T20:00:07.685447+00:00","kwargs":{"token":" your"}},{"name":"new_token","time":"2024-12-04T20:00:07.690977+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:07.701286+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T20:00:07.707290+00:00","kwargs":{"token":" named"}},{"name":"new_token","time":"2024-12-04T20:00:07.713401+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T20:00:07.718325+00:00","kwargs":{"token":"process"}},{"name":"new_token","time":"2024-12-04T20:00:07.723690+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T20:00:07.728265+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T20:00:07.732163+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T20:00:07.740147+00:00","kwargs":{"token":"`,"}},{"name":"new_token","time":"2024-12-04T20:00:07.750069+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:07.759225+00:00","kwargs":{"token":" JSON"}},{"name":"new_token","time":"2024-12-04T20:00:07.766559+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T20:00:07.771421+00:00","kwargs":{"token":" look"}},{"name":"new_token","time":"2024-12-04T20:00:07.775460+00:00","kwargs":{"token":" like"}},{"name":"new_token","time":"2024-12-04T20:00:07.779929+00:00","kwargs":{"token":" this"}},{"name":"new_token","time":"2024-12-04T20:00:07.784007+00:00","kwargs":{"token":":\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:07.788400+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:07.793561+00:00","kwargs":{"token":" ```"}},{"name":"new_token","time":"2024-12-04T20:00:07.798151+00:00","kwargs":{"token":"json"}},{"name":"new_token","time":"2024-12-04T20:00:07.802535+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T20:00:07.806849+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:07.811440+00:00","kwargs":{"token":" {\n"}},{"name":"new_token","time":"2024-12-04T20:00:07.819861+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T20:00:07.824346+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:07.829118+00:00","kwargs":{"token":"uniq"}},{"name":"new_token","time":"2024-12-04T20:00:07.833670+00:00","kwargs":{"token":"_id"}},{"name":"new_token","time":"2024-12-04T20:00:07.841064+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:07.851369+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:07.858436+00:00","kwargs":{"token":"6"}},{"name":"new_token","time":"2024-12-04T20:00:07.867236+00:00","kwargs":{"token":"\",\n"}},{"name":"new_token","time":"2024-12-04T20:00:07.873458+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T20:00:07.877509+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:07.882061+00:00","kwargs":{"token":"type"}},{"name":"new_token","time":"2024-12-04T20:00:07.887925+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:07.892111+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:07.896071+00:00","kwargs":{"token":"STEP"}},{"name":"new_token","time":"2024-12-04T20:00:07.905141+00:00","kwargs":{"token":"\",\n"}},{"name":"new_token","time":"2024-12-04T20:00:07.913364+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T20:00:07.927132+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:07.934409+00:00","kwargs":{"token":"name"}},{"name":"new_token","time":"2024-12-04T20:00:07.948465+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:07.955943+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:07.962042+00:00","kwargs":{"token":"TO"}},{"name":"new_token","time":"2024-12-04T20:00:07.966547+00:00","kwargs":{"token":"OL"}},{"name":"new_token","time":"2024-12-04T20:00:07.972628+00:00","kwargs":{"token":" CALL"}},{"name":"new_token","time":"2024-12-04T20:00:07.979335+00:00","kwargs":{"token":"\",\n"}},{"name":"new_token","time":"2024-12-04T20:00:07.987309+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T20:00:07.993318+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:07.997881+00:00","kwargs":{"token":"description"}},{"name":"new_token","time":"2024-12-04T20:00:08.001847+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:08.012559+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:08.019482+00:00","kwargs":{"token":"Call"}},{"name":"new_token","time":"2024-12-04T20:00:08.044118+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:08.053665+00:00","kwargs":{"token":" appropriate"}},{"name":"new_token","time":"2024-12-04T20:00:08.063072+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T20:00:08.073297+00:00","kwargs":{"token":"\",\n"}},{"name":"new_token","time":"2024-12-04T20:00:08.081322+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T20:00:08.088980+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:08.103671+00:00","kwargs":{"token":"tool"}},{"name":"new_token","time":"2024-12-04T20:00:08.111580+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:08.162247+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:08.169299+00:00","kwargs":{"token":"process"}},{"name":"new_token","time":"2024-12-04T20:00:08.176539+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T20:00:08.183596+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T20:00:08.195571+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T20:00:08.203508+00:00","kwargs":{"token":"\",\n"}},{"name":"new_token","time":"2024-12-04T20:00:08.221806+00:00","kwargs":{"token":"    "}},{"name":"new_token","time":"2024-12-04T20:00:08.227854+00:00","kwargs":{"token":" ...\n"}},{"name":"new_token","time":"2024-12-04T20:00:08.256769+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:08.261836+00:00","kwargs":{"token":" }\n"}},{"name":"new_token","time":"2024-12-04T20:00:08.386347+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:08.397603+00:00","kwargs":{"token":" ``"}},{"name":"new_token","time":"2024-12-04T20:00:08.419562+00:00","kwargs":{"token":"`\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:08.426270+00:00","kwargs":{"token":"4"}},{"name":"new_token","time":"2024-12-04T20:00:08.432965+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:08.440667+00:00","kwargs":{"token":" **"}},{"name":"new_token","time":"2024-12-04T20:00:08.447886+00:00","kwargs":{"token":"Debug"}},{"name":"new_token","time":"2024-12-04T20:00:08.455242+00:00","kwargs":{"token":"ging"}},{"name":"new_token","time":"2024-12-04T20:00:08.460095+00:00","kwargs":{"token":"**"}},{"name":"new_token","time":"2024-12-04T20:00:08.465676+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:08.472261+00:00","kwargs":{"token":" If"}},{"name":"new_token","time":"2024-12-04T20:00:08.477497+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:08.644596+00:00","kwargs":{"token":" issue"}},{"name":"new_token","time":"2024-12-04T20:00:08.648958+00:00","kwargs":{"token":" persists"}},{"name":"new_token","time":"2024-12-04T20:00:08.691160+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T20:00:08.697405+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T20:00:08.701971+00:00","kwargs":{"token":" can"}},{"name":"new_token","time":"2024-12-04T20:00:08.705744+00:00","kwargs":{"token":" add"}},{"name":"new_token","time":"2024-12-04T20:00:08.709610+00:00","kwargs":{"token":" print"}},{"name":"new_token","time":"2024-12-04T20:00:08.713248+00:00","kwargs":{"token":" statements"}},{"name":"new_token","time":"2024-12-04T20:00:08.748281+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T20:00:08.755324+00:00","kwargs":{"token":" check"}},{"name":"new_token","time":"2024-12-04T20:00:08.763565+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:08.767928+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:08.774366+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T20:00:08.780093+00:00","kwargs":{"token":" and"}},{"name":"new_token","time":"2024-12-04T20:00:08.786396+00:00","kwargs":{"token":" doc"}},{"name":"new_token","time":"2024-12-04T20:00:08.791023+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T20:00:08.794827+00:00","kwargs":{"token":" right"}},{"name":"new_token","time":"2024-12-04T20:00:08.798805+00:00","kwargs":{"token":" after"}},{"name":"new_token","time":"2024-12-04T20:00:08.817502+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T20:00:08.824126+00:00","kwargs":{"token":" define"}},{"name":"new_token","time":"2024-12-04T20:00:08.865318+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:08.870380+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T20:00:08.906779+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:08.912886+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:08.952190+00:00","kwargs":{"token":" This"}},{"name":"new_token","time":"2024-12-04T20:00:08.959593+00:00","kwargs":{"token":" can"}},{"name":"new_token","time":"2024-12-04T20:00:08.985664+00:00","kwargs":{"token":" help"}},{"name":"new_token","time":"2024-12-04T20:00:09.003721+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T20:00:09.029598+00:00","kwargs":{"token":" verify"}},{"name":"new_token","time":"2024-12-04T20:00:09.058361+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T20:00:09.067204+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:09.074412+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:09.079124+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T20:00:09.083888+00:00","kwargs":{"token":" being"}},{"name":"new_token","time":"2024-12-04T20:00:09.090992+00:00","kwargs":{"token":" registered"}},{"name":"new_token","time":"2024-12-04T20:00:09.097334+00:00","kwargs":{"token":" correctly"}},{"name":"new_token","time":"2024-12-04T20:00:09.109370+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:09.119468+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:09.133412+00:00","kwargs":{"token":" ```"}},{"name":"new_token","time":"2024-12-04T20:00:09.140123+00:00","kwargs":{"token":"python"}},{"name":"new_token","time":"2024-12-04T20:00:09.164192+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T20:00:09.169015+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:09.193706+00:00","kwargs":{"token":" print"}},{"name":"new_token","time":"2024-12-04T20:00:09.200995+00:00","kwargs":{"token":"(f"}},{"name":"new_token","time":"2024-12-04T20:00:09.226080+00:00","kwargs":{"token":"\""}},{"name":"new_token","time":"2024-12-04T20:00:09.232031+00:00","kwargs":{"token":"Function"}},{"name":"new_token","time":"2024-12-04T20:00:09.246770+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:09.252258+00:00","kwargs":{"token":" {"}},{"name":"new_token","time":"2024-12-04T20:00:09.281938+00:00","kwargs":{"token":"process"}},{"name":"new_token","time":"2024-12-04T20:00:09.288604+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T20:00:10.231915+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T20:00:10.255546+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T20:00:10.266673+00:00","kwargs":{"token":".__"}},{"name":"new_token","time":"2024-12-04T20:00:10.275074+00:00","kwargs":{"token":"name"}},{"name":"new_token","time":"2024-12-04T20:00:10.280475+00:00","kwargs":{"token":"__"}},{"name":"new_token","time":"2024-12-04T20:00:10.284667+00:00","kwargs":{"token":"},"}},{"name":"new_token","time":"2024-12-04T20:00:10.290487+00:00","kwargs":{"token":" Signature"}},{"name":"new_token","time":"2024-12-04T20:00:10.295158+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:10.300109+00:00","kwargs":{"token":" {"}},{"name":"new_token","time":"2024-12-04T20:00:10.308906+00:00","kwargs":{"token":"inspect"}},{"name":"new_token","time":"2024-12-04T20:00:10.314967+00:00","kwargs":{"token":".signature"}},{"name":"new_token","time":"2024-12-04T20:00:10.321056+00:00","kwargs":{"token":"(process"}},{"name":"new_token","time":"2024-12-04T20:00:10.327264+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T20:00:10.333314+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T20:00:10.338548+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T20:00:10.345537+00:00","kwargs":{"token":")},"}},{"name":"new_token","time":"2024-12-04T20:00:10.351416+00:00","kwargs":{"token":" Doc"}},{"name":"new_token","time":"2024-12-04T20:00:10.356810+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T20:00:10.361879+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:10.367462+00:00","kwargs":{"token":" {"}},{"name":"new_token","time":"2024-12-04T20:00:10.375559+00:00","kwargs":{"token":"process"}},{"name":"new_token","time":"2024-12-04T20:00:10.382585+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T20:00:10.387392+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T20:00:10.392798+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T20:00:10.397658+00:00","kwargs":{"token":".__"}},{"name":"new_token","time":"2024-12-04T20:00:10.403291+00:00","kwargs":{"token":"doc"}},{"name":"new_token","time":"2024-12-04T20:00:10.408485+00:00","kwargs":{"token":"__"}},{"name":"new_token","time":"2024-12-04T20:00:10.413551+00:00","kwargs":{"token":"}\")\n"}},{"name":"new_token","time":"2024-12-04T20:00:10.418187+00:00","kwargs":{"token":"  "}},{"name":"new_token","time":"2024-12-04T20:00:10.421926+00:00","kwargs":{"token":" ``"}},{"name":"new_token","time":"2024-12-04T20:00:10.426342+00:00","kwargs":{"token":"`\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:10.431124+00:00","kwargs":{"token":"5"}},{"name":"new_token","time":"2024-12-04T20:00:10.436367+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:10.442889+00:00","kwargs":{"token":" **"}},{"name":"new_token","time":"2024-12-04T20:00:10.451138+00:00","kwargs":{"token":"Re"}},{"name":"new_token","time":"2024-12-04T20:00:10.457533+00:00","kwargs":{"token":"-run"}},{"name":"new_token","time":"2024-12-04T20:00:10.461902+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:10.465652+00:00","kwargs":{"token":" Tests"}},{"name":"new_token","time":"2024-12-04T20:00:10.470101+00:00","kwargs":{"token":"**"}},{"name":"new_token","time":"2024-12-04T20:00:10.475932+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:10.480980+00:00","kwargs":{"token":" After"}},{"name":"new_token","time":"2024-12-04T20:00:10.486392+00:00","kwargs":{"token":" making"}},{"name":"new_token","time":"2024-12-04T20:00:10.491664+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:10.498904+00:00","kwargs":{"token":" necessary"}},{"name":"new_token","time":"2024-12-04T20:00:10.504090+00:00","kwargs":{"token":" adjustments"}},{"name":"new_token","time":"2024-12-04T20:00:10.510247+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T20:00:10.515595+00:00","kwargs":{"token":" re"}},{"name":"new_token","time":"2024-12-04T20:00:10.521138+00:00","kwargs":{"token":"-run"}},{"name":"new_token","time":"2024-12-04T20:00:10.527464+00:00","kwargs":{"token":" your"}},{"name":"new_token","time":"2024-12-04T20:00:10.533871+00:00","kwargs":{"token":" tests"}},{"name":"new_token","time":"2024-12-04T20:00:10.539177+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T20:00:10.546102+00:00","kwargs":{"token":" see"}},{"name":"new_token","time":"2024-12-04T20:00:10.553153+00:00","kwargs":{"token":" if"}},{"name":"new_token","time":"2024-12-04T20:00:10.559575+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:10.564189+00:00","kwargs":{"token":" issue"}},{"name":"new_token","time":"2024-12-04T20:00:10.568077+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T20:00:10.572153+00:00","kwargs":{"token":" resolved"}},{"name":"new_token","time":"2024-12-04T20:00:10.575907+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:10.580338+00:00","kwargs":{"token":"###"}},{"name":"new_token","time":"2024-12-04T20:00:10.584439+00:00","kwargs":{"token":" Example"}},{"name":"new_token","time":"2024-12-04T20:00:10.591419+00:00","kwargs":{"token":" of"}},{"name":"new_token","time":"2024-12-04T20:00:10.600868+00:00","kwargs":{"token":" Correct"}},{"name":"new_token","time":"2024-12-04T20:00:10.607124+00:00","kwargs":{"token":" Tool"}},{"name":"new_token","time":"2024-12-04T20:00:10.611488+00:00","kwargs":{"token":" Function"}},{"name":"new_token","time":"2024-12-04T20:00:10.616229+00:00","kwargs":{"token":"\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:10.621074+00:00","kwargs":{"token":"Here"}},{"name":"new_token","time":"2024-12-04T20:00:10.628728+00:00","kwargs":{"token":"’s"}},{"name":"new_token","time":"2024-12-04T20:00:10.634015+00:00","kwargs":{"token":" a"}},{"name":"new_token","time":"2024-12-04T20:00:10.638206+00:00","kwargs":{"token":" complete"}},{"name":"new_token","time":"2024-12-04T20:00:10.641995+00:00","kwargs":{"token":" example"}},{"name":"new_token","time":"2024-12-04T20:00:10.646077+00:00","kwargs":{"token":" of"}},{"name":"new_token","time":"2024-12-04T20:00:10.650498+00:00","kwargs":{"token":" how"}},{"name":"new_token","time":"2024-12-04T20:00:10.654408+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:10.659135+00:00","kwargs":{"token":" tool"}},{"name":"new_token","time":"2024-12-04T20:00:10.663001+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:10.667373+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T20:00:10.672434+00:00","kwargs":{"token":" be"}},{"name":"new_token","time":"2024-12-04T20:00:10.677236+00:00","kwargs":{"token":" defined"}},{"name":"new_token","time":"2024-12-04T20:00:10.681218+00:00","kwargs":{"token":" and"}},{"name":"new_token","time":"2024-12-04T20:00:10.685451+00:00","kwargs":{"token":" registered"}},{"name":"new_token","time":"2024-12-04T20:00:10.689422+00:00","kwargs":{"token":":\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:10.699989+00:00","kwargs":{"token":"```"}},{"name":"new_token","time":"2024-12-04T20:00:10.709654+00:00","kwargs":{"token":"python"}},{"name":"new_token","time":"2024-12-04T20:00:10.716065+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T20:00:10.719967+00:00","kwargs":{"token":"@"}},{"name":"new_token","time":"2024-12-04T20:00:10.724273+00:00","kwargs":{"token":"tool"}},{"name":"new_token","time":"2024-12-04T20:00:10.728387+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T20:00:10.736639+00:00","kwargs":{"token":"def"}},{"name":"new_token","time":"2024-12-04T20:00:10.750131+00:00","kwargs":{"token":" process"}},{"name":"new_token","time":"2024-12-04T20:00:10.757979+00:00","kwargs":{"token":"_claim"}},{"name":"new_token","time":"2024-12-04T20:00:10.763051+00:00","kwargs":{"token":"s"}},{"name":"new_token","time":"2024-12-04T20:00:10.768318+00:00","kwargs":{"token":"_query"}},{"name":"new_token","time":"2024-12-04T20:00:10.772540+00:00","kwargs":{"token":"(query"}},{"name":"new_token","time":"2024-12-04T20:00:10.777303+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:10.783397+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T20:00:10.791202+00:00","kwargs":{"token":")"}},{"name":"new_token","time":"2024-12-04T20:00:10.797431+00:00","kwargs":{"token":" ->"}},{"name":"new_token","time":"2024-12-04T20:00:10.803323+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T20:00:10.811957+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T20:00:10.825331+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T20:00:10.832477+00:00","kwargs":{"token":" \"\"\"\n"}},{"name":"new_token","time":"2024-12-04T20:00:10.839374+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T20:00:10.844415+00:00","kwargs":{"token":" Process"}},{"name":"new_token","time":"2024-12-04T20:00:10.891020+00:00","kwargs":{"token":" a"}},{"name":"new_token","time":"2024-12-04T20:00:10.897303+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T20:00:10.909573+00:00","kwargs":{"token":"-related"}},{"name":"new_token","time":"2024-12-04T20:00:10.915128+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T20:00:10.938808+00:00","kwargs":{"token":" using"}},{"name":"new_token","time":"2024-12-04T20:00:10.944771+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:10.970689+00:00","kwargs":{"token":" specialized"}},{"name":"new_token","time":"2024-12-04T20:00:10.976003+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T20:00:10.989271+00:00","kwargs":{"token":" workflow"}},{"name":"new_token","time":"2024-12-04T20:00:10.995111+00:00","kwargs":{"token":".\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:11.023413+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T20:00:11.028921+00:00","kwargs":{"token":" Args"}},{"name":"new_token","time":"2024-12-04T20:00:11.066615+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T20:00:11.071682+00:00","kwargs":{"token":"       "}},{"name":"new_token","time":"2024-12-04T20:00:11.082089+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T20:00:11.087046+00:00","kwargs":{"token":" ("}},{"name":"new_token","time":"2024-12-04T20:00:11.113956+00:00","kwargs":{"token":"str"}},{"name":"new_token","time":"2024-12-04T20:00:11.119968+00:00","kwargs":{"token":"):"}},{"name":"new_token","time":"2024-12-04T20:00:11.144211+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T20:00:11.149502+00:00","kwargs":{"token":" user's"}},{"name":"new_token","time":"2024-12-04T20:00:11.188476+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T20:00:11.195269+00:00","kwargs":{"token":"-related"}},{"name":"new_token","time":"2024-12-04T20:00:11.209422+00:00","kwargs":{"token":" query"}},{"name":"new_token","time":"2024-12-04T20:00:11.214397+00:00","kwargs":{"token":"\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:11.230766+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T20:00:11.238454+00:00","kwargs":{"token":" Returns"}},{"name":"new_token","time":"2024-12-04T20:00:11.272495+00:00","kwargs":{"token":":\n"}},{"name":"new_token","time":"2024-12-04T20:00:11.277521+00:00","kwargs":{"token":"       "}},{"name":"new_token","time":"2024-12-04T20:00:11.302412+00:00","kwargs":{"token":" str"}},{"name":"new_token","time":"2024-12-04T20:00:11.310222+00:00","kwargs":{"token":":"}},{"name":"new_token","time":"2024-12-04T20:00:11.349510+00:00","kwargs":{"token":" The"}},{"name":"new_token","time":"2024-12-04T20:00:11.354233+00:00","kwargs":{"token":" response"}},{"name":"new_token","time":"2024-12-04T20:00:11.368228+00:00","kwargs":{"token":" from"}},{"name":"new_token","time":"2024-12-04T20:00:11.378438+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:11.390046+00:00","kwargs":{"token":" claims"}},{"name":"new_token","time":"2024-12-04T20:00:11.396680+00:00","kwargs":{"token":" workflow"}},{"name":"new_token","time":"2024-12-04T20:00:11.422011+00:00","kwargs":{"token":"\n"}},{"name":"new_token","time":"2024-12-04T20:00:11.427720+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T20:00:11.451383+00:00","kwargs":{"token":" \"\"\"\n"}},{"name":"new_token","time":"2024-12-04T20:00:11.458567+00:00","kwargs":{"token":"   "}},{"name":"new_token","time":"2024-12-04T20:00:11.489598+00:00","kwargs":{"token":" return"}},{"name":"new_token","time":"2024-12-04T20:00:11.495036+00:00","kwargs":{"token":" [{\""}},{"name":"new_token","time":"2024-12-04T20:00:11.514323+00:00","kwargs":{"token":"claim"}},{"name":"new_token","time":"2024-12-04T20:00:11.521372+00:00","kwargs":{"token":"_id"}},{"name":"new_token","time":"2024-12-04T20:00:14.040428+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:14.080914+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:14.095631+00:00","kwargs":{"token":"123"}},{"name":"new_token","time":"2024-12-04T20:00:14.104200+00:00","kwargs":{"token":"4"}},{"name":"new_token","time":"2024-12-04T20:00:14.109920+00:00","kwargs":{"token":"\","}},{"name":"new_token","time":"2024-12-04T20:00:14.115893+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:14.121890+00:00","kwargs":{"token":"status"}},{"name":"new_token","time":"2024-12-04T20:00:14.127579+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:14.133100+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:14.137155+00:00","kwargs":{"token":"pending"}},{"name":"new_token","time":"2024-12-04T20:00:14.143677+00:00","kwargs":{"token":"\"},"}},{"name":"new_token","time":"2024-12-04T20:00:14.147833+00:00","kwargs":{"token":" {\""}},{"name":"new_token","time":"2024-12-04T20:00:14.151804+00:00","kwargs":{"token":"claim"}},{"name":"new_token","time":"2024-12-04T20:00:14.160775+00:00","kwargs":{"token":"_id"}},{"name":"new_token","time":"2024-12-04T20:00:14.168198+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:14.178456+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:14.183653+00:00","kwargs":{"token":"567"}},{"name":"new_token","time":"2024-12-04T20:00:14.187770+00:00","kwargs":{"token":"8"}},{"name":"new_token","time":"2024-12-04T20:00:14.192272+00:00","kwargs":{"token":"\","}},{"name":"new_token","time":"2024-12-04T20:00:14.196449+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:14.201166+00:00","kwargs":{"token":"status"}},{"name":"new_token","time":"2024-12-04T20:00:14.204930+00:00","kwargs":{"token":"\":"}},{"name":"new_token","time":"2024-12-04T20:00:14.209383+00:00","kwargs":{"token":" \""}},{"name":"new_token","time":"2024-12-04T20:00:14.213316+00:00","kwargs":{"token":"approved"}},{"name":"new_token","time":"2024-12-04T20:00:14.217991+00:00","kwargs":{"token":"\"}"}},{"name":"new_token","time":"2024-12-04T20:00:14.222977+00:00","kwargs":{"token":"]\n"}},{"name":"new_token","time":"2024-12-04T20:00:14.228049+00:00","kwargs":{"token":"``"}},{"name":"new_token","time":"2024-12-04T20:00:14.232928+00:00","kwargs":{"token":"`\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:14.237684+00:00","kwargs":{"token":"###"}},{"name":"new_token","time":"2024-12-04T20:00:14.242934+00:00","kwargs":{"token":" Conclusion"}},{"name":"new_token","time":"2024-12-04T20:00:14.248231+00:00","kwargs":{"token":"\n\n"}},{"name":"new_token","time":"2024-12-04T20:00:14.254368+00:00","kwargs":{"token":"By"}},{"name":"new_token","time":"2024-12-04T20:00:14.259128+00:00","kwargs":{"token":" ensuring"}},{"name":"new_token","time":"2024-12-04T20:00:14.264271+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T20:00:14.269448+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:14.274803+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:14.279864+00:00","kwargs":{"token":" signature"}},{"name":"new_token","time":"2024-12-04T20:00:14.284745+00:00","kwargs":{"token":" matches"}},{"name":"new_token","time":"2024-12-04T20:00:14.289186+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:14.292966+00:00","kwargs":{"token":" argument"}},{"name":"new_token","time":"2024-12-04T20:00:14.297596+00:00","kwargs":{"token":" descriptions"}},{"name":"new_token","time":"2024-12-04T20:00:14.302952+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T20:00:14.308226+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:14.313531+00:00","kwargs":{"token":" doc"}},{"name":"new_token","time":"2024-12-04T20:00:14.318410+00:00","kwargs":{"token":"string"}},{"name":"new_token","time":"2024-12-04T20:00:14.323117+00:00","kwargs":{"token":" and"}},{"name":"new_token","time":"2024-12-04T20:00:14.327742+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T20:00:14.333806+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:14.338385+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:14.343171+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T20:00:14.348008+00:00","kwargs":{"token":" properly"}},{"name":"new_token","time":"2024-12-04T20:00:14.354853+00:00","kwargs":{"token":" registered"}},{"name":"new_token","time":"2024-12-04T20:00:14.361841+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T20:00:14.367681+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T20:00:14.372808+00:00","kwargs":{"token":" should"}},{"name":"new_token","time":"2024-12-04T20:00:14.377758+00:00","kwargs":{"token":" be"}},{"name":"new_token","time":"2024-12-04T20:00:14.383510+00:00","kwargs":{"token":" able"}},{"name":"new_token","time":"2024-12-04T20:00:14.388213+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T20:00:14.392725+00:00","kwargs":{"token":" resolve"}},{"name":"new_token","time":"2024-12-04T20:00:14.397401+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:14.402009+00:00","kwargs":{"token":" `"}},{"name":"new_token","time":"2024-12-04T20:00:14.407379+00:00","kwargs":{"token":"Value"}},{"name":"new_token","time":"2024-12-04T20:00:14.413307+00:00","kwargs":{"token":"Error"}},{"name":"new_token","time":"2024-12-04T20:00:14.418214+00:00","kwargs":{"token":"`"}},{"name":"new_token","time":"2024-12-04T20:00:14.422904+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T20:00:14.428345+00:00","kwargs":{"token":" are"}},{"name":"new_token","time":"2024-12-04T20:00:14.433559+00:00","kwargs":{"token":" encountering"}},{"name":"new_token","time":"2024-12-04T20:00:14.446043+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:14.450452+00:00","kwargs":{"token":" If"}},{"name":"new_token","time":"2024-12-04T20:00:14.454401+00:00","kwargs":{"token":" you"}},{"name":"new_token","time":"2024-12-04T20:00:14.459167+00:00","kwargs":{"token":" continue"}},{"name":"new_token","time":"2024-12-04T20:00:14.463839+00:00","kwargs":{"token":" to"}},{"name":"new_token","time":"2024-12-04T20:00:14.468194+00:00","kwargs":{"token":" face"}},{"name":"new_token","time":"2024-12-04T20:00:14.471811+00:00","kwargs":{"token":" issues"}},{"name":"new_token","time":"2024-12-04T20:00:14.476517+00:00","kwargs":{"token":","}},{"name":"new_token","time":"2024-12-04T20:00:14.481586+00:00","kwargs":{"token":" consider"}},{"name":"new_token","time":"2024-12-04T20:00:14.486158+00:00","kwargs":{"token":" checking"}},{"name":"new_token","time":"2024-12-04T20:00:14.491179+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:14.496232+00:00","kwargs":{"token":" context"}},{"name":"new_token","time":"2024-12-04T20:00:14.501272+00:00","kwargs":{"token":" in"}},{"name":"new_token","time":"2024-12-04T20:00:14.505640+00:00","kwargs":{"token":" which"}},{"name":"new_token","time":"2024-12-04T20:00:14.510517+00:00","kwargs":{"token":" the"}},{"name":"new_token","time":"2024-12-04T20:00:14.518543+00:00","kwargs":{"token":" function"}},{"name":"new_token","time":"2024-12-04T20:00:14.523940+00:00","kwargs":{"token":" is"}},{"name":"new_token","time":"2024-12-04T20:00:14.529356+00:00","kwargs":{"token":" being"}},{"name":"new_token","time":"2024-12-04T20:00:14.534933+00:00","kwargs":{"token":" executed"}},{"name":"new_token","time":"2024-12-04T20:00:14.541670+00:00","kwargs":{"token":" and"}},{"name":"new_token","time":"2024-12-04T20:00:14.548518+00:00","kwargs":{"token":" ensure"}},{"name":"new_token","time":"2024-12-04T20:00:14.555279+00:00","kwargs":{"token":" that"}},{"name":"new_token","time":"2024-12-04T20:00:14.562374+00:00","kwargs":{"token":" all"}},{"name":"new_token","time":"2024-12-04T20:00:14.567888+00:00","kwargs":{"token":" dependencies"}},{"name":"new_token","time":"2024-12-04T20:00:14.574265+00:00","kwargs":{"token":" are"}},{"name":"new_token","time":"2024-12-04T20:00:14.578877+00:00","kwargs":{"token":" correctly"}},{"name":"new_token","time":"2024-12-04T20:00:14.582771+00:00","kwargs":{"token":" set"}},{"name":"new_token","time":"2024-12-04T20:00:14.586433+00:00","kwargs":{"token":" up"}},{"name":"new_token","time":"2024-12-04T20:00:14.590148+00:00","kwargs":{"token":"."}},{"name":"new_token","time":"2024-12-04T20:00:14.593755+00:00","kwargs":{"token":""}},{"name":"end","time":"2024-12-04T20:00:14.607095+00:00"}],"inputs":{"messages":[[{"lc":1,"type":"constructor","id":["langchain","schema","messages","SystemMessage"],"kwargs":{"content":"You are an expert programmer and problem-solver, tasked with answering any question about LangChain.\n\nGenerate a comprehensive and informative answer for the given question based solely on the provided search results (URL and content). Do NOT ramble, and adjust your response length based on the question. If they ask a question that can be answered in one sentence, do that. If 5 paragraphs of detail is needed, do that. You must only use information from the provided search results. Use an unbiased and journalistic tone. Combine search results together into a coherent answer. Do not repeat text. Cite search results using [${number}] notation. Only cite the most relevant results that answer the question accurately. Place these citations at the end of the individual sentence or paragraph that reference them. Do not put them all at the end, but rather sprinkle them throughout. If different results refer to different entities within the same name, write separate answers for each entity.\n\nYou should use bullet points in your answer for readability. Put citations where they apply rather than putting them all at the end. DO NOT PUT THEM ALL THAT END, PUT THEM IN THE BULLET POINTS.\n\nIf there is nothing in the context relevant to the question at hand, do NOT make up an answer. Rather, tell them why you're unsure and ask for any additional information that may help you answer better.\n\nSometimes, what a user is asking may NOT be possible. Do NOT tell them that things are possible if you don't see evidence for it in the context below. If you don't see based in the information below that something is possible, do NOT say that it is - instead say that you're not sure.\n\nAnything between the following `context` html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    <documents>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='594f3236-69b3-5723-8a2a-a67328032782'>\n{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}\n</document>\n<document  description='Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' title='Spreedly | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' uuid='be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee'>\n```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n</document>\n<document  language='en' description=\"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.\" changefreq='weekly' source='https://python.langchain.com/docs/how_to/graph_mapping/' title='How to map values to a graph database | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/graph_mapping/' uuid='ca98b026-baac-5e7f-b687-b177bbf581a0'>\nchain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)\n</document>\n<document  language='en' description='Learn about how the self-querying retriever works here.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/retrievers/self_query/' title='Self-querying retrievers | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/retrievers/self_query/' uuid='315c889a-0f5a-531c-93d4-6c64c77d8abf'>\nSelf-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).\n</document>\n<document  language='en' description='Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.' changefreq='weekly' source='https://python.langchain.com/docs/how_to/query_no_queries/' title='How to handle cases where no queries are generated | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/query_no_queries/' uuid='7c753e2b-c599-5f69-a535-539b12f6c2ed'>\n```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)\n</document>\n<document  description='This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' title='ArcGIS | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' uuid='a9dd78eb-3537-55b1-9e6d-99f9d35a489e'>\n\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```\n</document>\n<document  description='Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.' language='en' changefreq=None source='https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax' title='Trace query syntax | 🦜️🛠️ LangSmith' content_type='text/html; charset=utf-8' lastmod=None priority=None loc=None uuid='6103ddb5-52da-5eae-a911-513966d65f00'>\nTrace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\n</document>\n<document  description=\"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.\" language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/sql_query_checking/' title='How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/sql_query_checking/' uuid='5cea0388-8300-5f71-8f8f-8a94daff7a9d'>\n```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='7ed75ace-8a2b-55de-a415-25083eeba332'>\nquery_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n</document>\n<document  description='This guide assumes familiarity with the following concepts:' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/tool_stream_events/' title='How to stream events from a tool | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/tool_stream_events/' uuid='51f0caf5-c4da-5d8d-9eea-5838a8fb4081'>\n## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)\n</document>\n<document  language='en' description=\"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾\" changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/gradio_tools/' title='Gradio | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/gradio_tools/' uuid='7f36aaa8-0f01-59e6-a58b-df56996a9048'>\nJob Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)\n</document>\n<document  description='ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/clickup/' title='ClickUp Toolkit | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/clickup/' uuid='1a2a0382-266f-5818-9794-e1d0b756039b'>\n```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)\n</document>\n<document  language='' description='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='483a01c0-c8d8-568d-80e3-4c7349518f0d'>\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' title='Review Tool Calls | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' uuid='a7380d1f-89be-5df5-9f1e-6b74afb1a49d'>\nOutput:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '\n</document>\n<document  description=\"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.\" language='en' changefreq=None source='https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api' title='Manage your organization using the API | 🦜️🛠️ LangSmith' lastmod=None content_type='text/html; charset=utf-8' priority=None loc=None uuid='cd89709f-0016-5447-9ab3-2e9efb7db0fa'>\nSample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.\n</document>\n<document  description='You are passing too many, too few, or mismatched ToolMessages to a model.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' title='INVALID_TOOL_RESULTS | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' uuid='62856b31-ccd6-527f-a540-677a2f8170eb'>\nSee [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  language='en' description='ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/providers/datadog/' title='Datadog Tracing | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/providers/datadog/' uuid='aac182d0-171a-5d65-a00e-60b5a764e813'>\n## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  description='JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/document_loader_json/' title='How to load JSON | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/document_loader_json/' uuid='67c83a8d-a61d-5338-a82c-cedaa5def0c1'>\nJSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' title='SDK (Python) | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' uuid='d7081e58-73a0-55f5-9a3f-25d019980493'>\n}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' title='How to create agents with configuration | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' uuid='19b61e09-1d71-560a-a077-a45a31445149'>\nHow to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'\n</document>\n</documents>\n<context/>","type":"system"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","tool_calls":[],"invalid_tool_calls":[]}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","tool_calls":[],"invalid_tool_calls":[]}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-7d69b282-55a6-4665-8dd8-50146bca4a14","tool_calls":[],"invalid_tool_calls":[]}}]]},"run_type":"llm","extra":{"invocation_params":{"model":"gpt-4o-mini","model_name":"gpt-4o-mini","stream":false,"n":1,"temperature":0.0,"_type":"openai-chat","stop":null},"options":{"stop":null},"batch_size":1,"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":20,"langgraph_node":"respond","langgraph_triggers":["branch:respond:check_hallucination:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","ls_provider":"openai","ls_model_name":"gpt-4o-mini","ls_model_type":"chat","ls_temperature":0.0,"LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T200001263059Z85066f84-90de-4c8b-bf10-edbbe6052031.20241204T200001382015Z83dcd4ef-2ca1-41f8-9e85-847e0f6bed23"}
{"id":"83dcd4ef-2ca1-41f8-9e85-847e0f6bed23","name":"ChatOpenAI","end_time":"2024-12-04T20:00:14.607095","error":null,"outputs":{"generations":[{"text":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","generation_info":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ChatGeneration","message":{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-83dcd4ef-2ca1-41f8-9e85-847e0f6bed23","tool_calls":[],"invalid_tool_calls":[]}}}],"llm_output":null,"run":null,"type":"LLMResult"}}
{"id":"29428d4c-ef50-4d7c-b44d-5daa849ec1f0","name":"_write","start_time":"2024-12-04T20:00:14.624982","serialized":null,"events":[{"name":"start","time":"2024-12-04T20:00:14.624982+00:00"},{"name":"end","time":"2024-12-04T20:00:14.630650+00:00"}],"inputs":{"messages":[{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-83dcd4ef-2ca1-41f8-9e85-847e0f6bed23","example":false,"tool_calls":[],"invalid_tool_calls":[]}],"answer":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","num_response_attempts":2},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":20,"langgraph_node":"respond","langgraph_triggers":["branch:respond:check_hallucination:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["langsmith:hidden","seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T200001263059Z85066f84-90de-4c8b-bf10-edbbe6052031.20241204T200014624982Z29428d4c-ef50-4d7c-b44d-5daa849ec1f0"}
{"id":"29428d4c-ef50-4d7c-b44d-5daa849ec1f0","name":"_write","end_time":"2024-12-04T20:00:14.630650","error":null,"outputs":{"messages":[{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-83dcd4ef-2ca1-41f8-9e85-847e0f6bed23","example":false,"tool_calls":[],"invalid_tool_calls":[]}],"answer":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","num_response_attempts":2}}
{"id":"a8fdc9d7-05c1-4ea7-a49e-73c543216e9c","name":"check_hallucination","start_time":"2024-12-04T20:00:14.644615","serialized":null,"events":[{"name":"start","time":"2024-12-04T20:00:14.644615+00:00"},{"name":"end","time":"2024-12-04T20:00:16.439659+00:00"}],"inputs":{"input":{"messages":[{"content":"lets refactor this workflow wrapper so that tool execution is uisng langgraphs prebuilt\n\n\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\nimport base64\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    # Encode binary data as Base64\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return base64_data \n    # Create the HTML <img> tag\n    img_tag = f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n    return img_tag\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    print('inputs')\n    generation = llm_chain.invoke(inputs)\n    print('generation ', generation)\n    # Add new message to state\n    #new_message = json.loads(generation)\n    #print('new_message ', new_message)\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\ndef condition_switch(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n\n    # Extract and format messages for the prompt\n    messages = state[\"messages\"]\n    \n    # Generate the prompt\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Parse the LLM output\n    data = json.loads(generation)\n\n    # Update state with the condition result and new system message\n    state[\"messages\"].append((\"system\", generation))\n#    state[\"condition\"] = condition\n\n    return state\n\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        if current_node.tool:\n            tool_info = tool_info_registry[current_node.tool]\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            Available tool: {tool_info}\n            Based on Available tool, arguments in the json format:\n            \"function\": \"<func_name>\", \"args\": [<arg1>, <arg2>, ...]\n\n            next stage directly parse then run <func_name>(<arg1>,<arg2>, ...) make sure syntax is right json and align function siganture\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n        else:\n            prompt_template = f\"\"\"\n            messages: {{messages}}\n            {current_node.description}\n            \"\"\"\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n    # Edges\n    # Find all next nodes from start_node\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name} {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            #lambda state, template=condition_template, llm=llm, name=condition.name: condition_switch(name, state, template, llm)\n                create_step_node_executor(\n                    name=condition.name,\n                    template=condition_template,\n                    llm=llm\n                )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    #llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)","additional_kwargs":{},"response_metadata":{},"type":"human","id":"f93c5a7e-6eb0-418d-b01c-9456622849e5","example":false},{"content":"To refactor the provided workflow wrapper to utilize LangGraph's prebuilt components for tool execution, we will replace the manual tool execution logic with the `ToolNode` from LangGraph. This will streamline the process of invoking tools and managing their outputs. Below is the refactored code:\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Function to handle node execution\ndef execute_step(name: str, state: State, prompt_template: str, llm) -> State:\n    print(f\"{name} is working...\")\n    messages = state[\"messages\"]\n\n    # Generate prompt from messages\n    prompt = PromptTemplate.from_template(prompt_template)\n    llm_chain = prompt | llm | StrOutputParser()\n    inputs = {\"messages\": messages}\n    generation = llm_chain.invoke(inputs)\n\n    # Add new message to state\n    state[\"messages\"].append((\"AI\", generation))\n    return state\n\ndef create_step_node_executor(name: str, template: str, llm):\n    \"\"\"\n    Creates a step node executor function.\n    \"\"\"\n    def executor(state: State):\n        return execute_step(name, state, template, llm)\n    return executor\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Use ToolNode for tool execution\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(\"/Users/c7w6g9/git/cigna/ai-foundation/LangGraph-GUI-backend/src/workspace/\" + filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n- **ToolNode Integration**: The code now uses `ToolNode` from LangGraph for executing tools, which simplifies the tool invocation process.\n- **Removed Manual Tool Execution Logic**: The previous manual handling of tool execution has been replaced with the `ToolNode`, which automatically manages the tool's input and output.\n- **Streamlined Node Addition**: The logic for adding nodes to the workflow has been simplified to check for tools and add them accordingly.\n\nThis refactoring should enhance the maintainability and readability of the workflow while leveraging LangGraph's capabilities for tool execution.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-a62f3a35-cb9c-4300-ad1e-1bfae7b1679b","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"ok the goal is to be able to create graph from a json configuration. for example the below json should create a langgraph that matches the prebuild create react agent. the RunWorkFlow above seems to be creating the right nodes, but the tools are not being called\n\n\n{\n  \"nodes\": [\n    {\n      \"uniq_id\": \"start\",\n      \"pos_x\": 56.967113750823245,\n      \"pos_y\": -245.82536630888245,\n      \"width\": 288,\n      \"height\": 288,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"START\",\n      \"name\": \"Start Node\",\n      \"description\": \"Initialize the agent and receive the user's input\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"llm_decision\",\n      \"pos_x\": 484.879797432337,\n      \"pos_y\": 98.12324978578097,\n      \"width\": 520,\n      \"height\": 337,\n      \"nexts\": [],\n      \"type\": \"CONDITION\",\n      \"name\": \"Agent\",\n      \"description\": \"You are a helpful customer service assistant for CIGNA that can search for providers related information about them.\\n                        You can also look up claims information for the user.\",\n      \"tool\": \"\",\n      \"true_next\": \"6\",\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"6\",\n      \"pos_x\": 113,\n      \"pos_y\": 421.0052032470703,\n      \"width\": 266,\n      \"height\": 266,\n      \"nexts\": [\n        \"Agent\",\n        \"Agent\"\n      ],\n      \"type\": \"STEP\",\n      \"name\": \"TOOL CALL\",\n      \"description\": \"Call the appropriate tool\",\n      \"tool\": \"process_claims_query\",\n      \"true_next\": null,\n      \"false_next\": null\n    },\n    {\n      \"uniq_id\": \"7\",\n      \"pos_x\": -302.30023363002,\n      \"pos_y\": 238.9384749804373,\n      \"width\": 302,\n      \"height\": 331,\n      \"nexts\": [],\n      \"type\": \"TOOL\",\n      \"name\": \"Node 7\",\n      \"description\": \"@tool\\ndef process_claims_query(query: str) -> str:\\n    \\\"\\\"\\\"\\n    Process a claims-related query using the specialized claims workflow.\\n\\n    Args:\\n        query (str): The user's claims-related query\\n\\n    Returns:\\n        str: The response from the claims workflow\\n    \\\"\\\"\\\"\\n    return [{\\\"claim_id\\\": \\\"1234\\\", \\\"status\\\": \\\"pending\\\"}, {\\\"claim_id\\\": \\\"5678\\\", \\\"status\\\": \\\"approved\\\"}]\",\n      \"tool\": \"\",\n      \"true_next\": null,\n      \"false_next\": null\n    }\n  ],\n  \"node_counter\": 8\n}","additional_kwargs":{},"response_metadata":{},"type":"human","id":"de3a03e9-9e6b-41ad-9866-8534a08335c4","example":false},{"content":"To create a LangGraph that matches the prebuilt create react agent from the provided JSON configuration, we need to ensure that the workflow correctly registers and invokes the tools defined in the JSON. The current implementation of `RunWorkFlow` needs to be adjusted to properly handle tool nodes and ensure that the tools are called when the workflow reaches those nodes.\n\nHere’s how you can refactor the `RunWorkFlow` function to ensure that tools are called correctly based on the JSON configuration:\n\n### Refactored Code\n\n```python\nfrom langgraph.prebuilt import ToolNode\nfrom langgraph.graph import StateGraph, END, START\nfrom langchain_core.messages import SystemMessage\nimport json\nimport base64\nimport inspect\nfrom typing import Dict, Callable, List, TypedDict, Annotated\n\n# Tool registry to hold information about tools\ntool_registry: Dict[str, Callable] = {}\ntool_info_registry: Dict[str, str] = {}\n\ndef get_image_tag_from_binary(png_binary: bytes) -> str:\n    \"\"\"\n    Converts PNG binary data into a Base64-encoded image tag.\n    \"\"\"\n    base64_data = base64.b64encode(png_binary).decode(\"utf-8\")\n    return f'<img src=\"data:image/png;base64,{base64_data}\" alt=\"Graph Visualization\">'\n\n# Decorator to register tools\ndef tool(func: Callable) -> Callable:\n    signature = inspect.signature(func)\n    docstring = func.__doc__ or \"\"\n    tool_info = f\"{func.__name__}{signature} - {docstring}\"\n    tool_registry[func.__name__] = func\n    tool_info_registry[func.__name__] = tool_info\n    return func\n\ndef load_nodes_from_json(filename: str) -> Dict[str, NodeData]:\n    with open(filename, 'r') as file:\n        data = json.load(file)\n        node_map = {}\n        for node_data in data[\"nodes\"]:\n            node = NodeData.from_dict(node_data)\n            node_map[node.name] = node\n        return node_map\n\ndef find_nodes_by_type(node_map: Dict[str, NodeData], node_type: str) -> List[NodeData]:\n    return [node for node in node_map.values() if node.type == node_type]\n\n# Define State with messages\nclass State(TypedDict):\n    messages: Annotated[list, lambda x, y: x + y]  # Append new messages to the list\n    condition: Annotated[bool, lambda x, y: y]\n\n# Workflow runner\ndef RunWorkFlow(node_map: Dict[str, NodeData], llm, filename):\n    # Define the state machine\n    workflow = StateGraph(State)\n\n    # Start node, only one start point\n    start_node = find_nodes_by_type(node_map, \"START\")[0]\n    print('start_node ', start_node)\n    print(f\"Start root ID: {start_node.name}\")\n\n    # Step nodes\n    step_nodes = find_nodes_by_type(node_map, \"STEP\")\n    for current_node in step_nodes:\n        prompt_template = f\"\"\"\n        messages: {{messages}}\n        {current_node.description}\n        \"\"\"\n        if current_node.tool:\n            # Register the tool function dynamically\n            exec(current_node.description, globals())\n            tool_node = ToolNode(current_node.tool)\n            workflow.add_node(current_node.name, tool_node)\n        else:\n            workflow.add_node(\n                current_node.name,\n                create_step_node_executor(\n                    name=current_node.name,\n                    template=prompt_template,\n                    llm=llm\n                )\n            )\n\n    # Edges\n    next_node_ids = start_node.nexts\n    next_nodes = [node_map[next_id] for next_id in next_node_ids]\n    \n    for next_node in next_nodes:\n        print(f\"Next node ID: {next_node.name}, Type: {next_node.type}\")\n        workflow.add_edge(START, next_node.name)   \n\n    # Find all next nodes from step_nodes\n    for node in step_nodes:\n        next_nodes = [node_map[next_id] for next_id in node.nexts]\n        \n        for next_node in next_nodes:\n            print(f\"{node.name} {node.name}'s next node: {next_node.name}, Type: {next_node.type}\")\n            workflow.add_edge(node.name, next_node.name)\n\n    # Find all condition nodes\n    condition_nodes = find_nodes_by_type(node_map, \"CONDITION\")\n    for condition in condition_nodes:\n        condition_template = f\"\"\"{condition.description}\n        {{messages}}\n        \"\"\"\n        workflow.add_node(\n            condition.name, \n            create_step_node_executor(\n                name=condition.name,\n                template=condition_template,\n                llm=llm\n            )\n        )\n\n        print(f\"{condition.name} {condition.name}'s condition\")\n        print(f\"true will go {condition.true_next}\")\n        print(f\"false will go {condition.false_next}\")\n        workflow.add_conditional_edges(\n            condition.name,\n            tools_condition\n        )\n        \n    initial_state = State(messages=[(\"user\", \"looking for my last claim\")])\n    app = workflow.compile()\n    png_binary = app.get_graph().draw_mermaid_png()\n    try:\n        with open(filename, \"wb\") as f:\n            f.write(png_binary)\n    except Exception as e:\n        print(f\"Error writing file: {e}\")\n    for state in app.stream(initial_state):\n        print(state)\n\ndef run_workflow_as_server(filename):\n    node_map = load_nodes_from_json(filename)\n    # Register tool functions dynamically\n    for tool in find_nodes_by_type(node_map, \"TOOL\"):\n        tool_code = f\"{tool.description}\"\n        exec(tool_code, globals())\n    llm = get_llm_model()\n    print('llm ', llm)\n    RunWorkFlow(node_map, llm, filename)\n```\n\n### Key Changes Made:\n1. **Dynamic Tool Registration**: The tool function is registered dynamically using `exec(current_node.description, globals())` when the node type is \"STEP\" and a tool is specified. This allows the tool to be available for invocation when the workflow reaches that node.\n\n2. **ToolNode Usage**: The `ToolNode` is created for nodes that specify a tool, ensuring that the tool is called when the workflow reaches that node.\n\n3. **Condition Handling**: The condition nodes are still handled as before, but now they can also lead to tool calls based on the workflow's logic.\n\n### JSON Configuration:\nThe provided JSON configuration should now correctly create a LangGraph that matches the prebuilt create react agent, allowing the tools to be called as intended. Make sure that the tool functions are defined correctly in the JSON and that they are accessible in the global scope when invoked. \n\n### Testing:\nTo test the implementation, ensure that the JSON structure is correctly formatted and that the tool functions are defined as expected. Run the `run_workflow_as_server` function with the path to your JSON file to see the workflow in action.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-267b1e3a-acc7-4e96-abb6-962706f893cf","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","additional_kwargs":{},"response_metadata":{},"type":"human","id":"1b0a4935-aac0-4884-b929-ffb5abebeffd","example":false},{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-7d69b282-55a6-4665-8dd8-50146bca4a14","example":false,"tool_calls":[],"invalid_tool_calls":[]},{"content":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","additional_kwargs":{},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-83dcd4ef-2ca1-41f8-9e85-847e0f6bed23","example":false,"tool_calls":[],"invalid_tool_calls":[]}],"router":{"type":"general","logic":""},"steps":[],"documents":[{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"594f3236-69b3-5723-8a2a-a67328032782"},"page_content":"{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}","type":"Document"},{"metadata":{"description":"Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","title":"Spreedly | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/spreedly/","uuid":"be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee"},"page_content":"```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),","type":"Document"},{"metadata":{"language":"en","description":"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/graph_mapping/","title":"How to map values to a graph database | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/graph_mapping/","uuid":"ca98b026-baac-5e7f-b687-b177bbf581a0"},"page_content":"chain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)","type":"Document"},{"metadata":{"language":"en","description":"Learn about how the self-querying retriever works here.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/retrievers/self_query/","title":"Self-querying retrievers | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/retrievers/self_query/","uuid":"315c889a-0f5a-531c-93d4-6c64c77d8abf"},"page_content":"Self-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).","type":"Document"},{"metadata":{"language":"en","description":"Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/query_no_queries/","title":"How to handle cases where no queries are generated | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/query_no_queries/","uuid":"7c753e2b-c599-5f69-a535-539b12f6c2ed"},"page_content":"```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)","type":"Document"},{"metadata":{"description":"This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","title":"ArcGIS | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/arcgis/","uuid":"a9dd78eb-3537-55b1-9e6d-99f9d35a489e"},"page_content":"\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```","type":"Document"},{"metadata":{"description":"Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax","title":"Trace query syntax | 🦜️🛠️ LangSmith","content_type":"text/html; charset=utf-8","lastmod":null,"priority":null,"loc":null,"uuid":"6103ddb5-52da-5eae-a911-513966d65f00"},"page_content":"Trace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/sql_query_checking/","title":"How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/sql_query_checking/","uuid":"5cea0388-8300-5f71-8f8f-8a94daff7a9d"},"page_content":"```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"7ed75ace-8a2b-55de-a415-25083eeba332"},"page_content":"query_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.","type":"Document"},{"metadata":{"description":"This guide assumes familiarity with the following concepts:","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/tool_stream_events/","title":"How to stream events from a tool | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/tool_stream_events/","uuid":"51f0caf5-c4da-5d8d-9eea-5838a8fb4081"},"page_content":"## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)","type":"Document"},{"metadata":{"language":"en","description":"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","title":"Gradio | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/gradio_tools/","uuid":"7f36aaa8-0f01-59e6-a58b-df56996a9048"},"page_content":"Job Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)","type":"Document"},{"metadata":{"description":"ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/clickup/","title":"ClickUp Toolkit | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/clickup/","uuid":"1a2a0382-266f-5818-9794-e1d0b756039b"},"page_content":"```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)","type":"Document"},{"metadata":{"language":"","description":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","title":"An agent for interacting with a SQL database | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/tutorials/sql-agent/","uuid":"483a01c0-c8d8-568d-80e3-4c7349518f0d"},"page_content":"DO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","title":"Review Tool Calls | 🦜🕸️LangGraph","content_type":null,"lastmod":"2024-12-04","priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/","uuid":"a7380d1f-89be-5df5-9f1e-6b74afb1a49d"},"page_content":"Output:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '","type":"Document"},{"metadata":{"description":"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.","language":"en","changefreq":null,"source":"https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api","title":"Manage your organization using the API | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"cd89709f-0016-5447-9ab3-2e9efb7db0fa"},"page_content":"Sample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.","type":"Document"},{"metadata":{"description":"You are passing too many, too few, or mismatched ToolMessages to a model.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","title":"INVALID_TOOL_RESULTS | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/","uuid":"62856b31-ccd6-527f-a540-677a2f8170eb"},"page_content":"See [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"language":"en","description":"ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/providers/datadog/","title":"Datadog Tracing | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/providers/datadog/","uuid":"aac182d0-171a-5d65-a00e-60b5a764e813"},"page_content":"## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)","type":"Document"},{"metadata":{"description":"JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/how_to/document_loader_json/","title":"How to load JSON | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/how_to/document_loader_json/","uuid":"67c83a8d-a61d-5338-a82c-cedaa5def0c1"},"page_content":"JSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","title":"SDK (Python) | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/","uuid":"d7081e58-73a0-55f5-9a3f-25d019980493"},"page_content":"}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }","type":"Document"},{"metadata":{"description":"","language":"","changefreq":null,"source":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","title":"How to create agents with configuration | 🦜🕸️LangGraph","lastmod":"2024-12-04","content_type":null,"priority":null,"loc":"https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/","uuid":"19b61e09-1d71-560a-a077-a45a31445149"},"page_content":"How to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'","type":"Document"},{"metadata":{"language":"en","description":"The LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.","changefreq":null,"source":"https://docs.smith.langchain.com/prompt_engineering/how_to_guides/playground/managing_model_configurations","title":"Managing Model Configurations | 🦜️🛠️ LangSmith","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"19dcb15c-fd37-566d-b2be-692ddd49188a"},"page_content":"Managing Model Configurations | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringConceptual GuideHow-to GuidesPlaygroundRun the playground against a custom LangServe model serverRun the playground against an OpenAI-compliant model provider/proxyUse custom TLS certificatesManaging Model ConfigurationsPromptsTutorialsOptimize a classifierDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsPrompt EngineeringHow-to GuidesPlaygroundManaging Model ConfigurationsOn this pageManaging Model Configurations\nThe LangSmith playground allows you to save and manage your model configurations, making it easy to reuse your preferred settings across sessions.\nSaving a Configuration​\n\nAdjust the model settings as desired in the playground\nClick the Save As button in the bottom bar\nEnter a name and optional description for your configuration\n\nManaging Saved Configurations​\nAccessing Saved Configurations​\n\nClick the Model configuration dropdown to view all your saved configurations\n\nEditing Configurations​\n\nTo rename or update the description: Click the pencil icon next to a saved configuration\nTo update the current configuration's settings: Click the Save button at the bottom\n\nDeleting Configurations​\n\nSelect the configuration you want to remove\nClick the trash can icon to delete it\n\nResetting to Default​\n\nTo restore default model settings: Click the x button in the top row\nWas this page helpful?You can leave detailed feedback on GitHub.PreviousUse custom TLS certificatesNextCreate a promptSaving a ConfigurationManaging Saved ConfigurationsAccessing Saved ConfigurationsEditing ConfigurationsDeleting ConfigurationsResetting to DefaultCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.","type":"Document"},{"metadata":{"description":"An output parser was unable to handle model output as expected.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"4c5dd25c-312a-58f1-95ff-a433ccc0d012"},"page_content":"## Troubleshooting\n\nThe following may help resolve this error:\n\n- Consider using [tool calling or other structured output techniques](/docs/how_to/structured_output/) if possible without an output parser to reliably output parseable values.\n  - If you are using a prebuilt chain or agent, use [LangGraph](https://langchain-ai.github.io/langgraph/) to compose your logic explicitly instead.\n- Add more precise formatting instructions to your prompt. In the above example, adding `\"You must always return valid JSON fenced by a markdown code block. Do not return any additional text.\"` to your input may help steer the model to returning the expected format.\n- If you are using a smaller or less capable model, try using a more capable one.\n- Add [LLM-powered retries](/docs/how_to/output_parser_fixing/).\n```\n\n#### Was this page helpful?","type":"Document"},{"metadata":{"description":"This notebook showcases an agent interacting with large JSON/dict objects.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/tools/json/","title":"JSON Toolkit | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/tools/json/","uuid":"0c140bd9-e9e4-5976-9637-69444a0049b2"},"page_content":"JSON Toolkit | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSON Toolkit\n\nThis notebook showcases an agent interacting with large `JSON/dict` objects.\nThis is useful when you want to answer questions about a JSON blob that's too large to fit in the context window of an LLM. The agent is able to iteratively explore the blob to find what it needs to answer the user's question.\n\nIn the below example, we are using the OpenAPI spec for the OpenAI API, which you can find [here](https://github.com/openai/openai-openapi/blob/master/openapi.yaml).\n\nWe will use the JSON agent to answer some questions about the API spec.\n\n```python\n%pip install -qU langchain-community\n```\n\n## Initialization​\n\n```python\nimport yaml\nfrom langchain_community.agent_toolkits import JsonToolkit, create_json_agent\nfrom langchain_community.tools.json.tool import JsonSpec\nfrom langchain_openai import OpenAI\n```\n\n**API Reference:**[JsonToolkit](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.toolkit.JsonToolkit.html) | [create_json_agent](https://python.langchain.com/api_reference/community/agent_toolkits/langchain_community.agent_toolkits.json.base.create_json_agent.html) | [JsonSpec](https://python.langchain.com/api_reference/community/tools/langchain_community.tools.json.tool.JsonSpec.html) | [OpenAI](https://python.langchain.com/api_reference/openai/llms/langchain_openai.llms.base.OpenAI.html)\n```python\nwith open(\"openai_openapi.yml\") as f:\n    data = yaml.load(f, Loader=yaml.FullLoader)\njson_spec = JsonSpec(dict_={}, max_value_length=4000)\njson_toolkit = JsonToolkit(spec=json_spec)\n\njson_agent_executor = create_json_agent(\n    llm=OpenAI(temperature=0), toolkit=json_toolkit, verbose=True\n)\n```\n\n## Individual tools​\n\nLet's see what individual tools are inside the Jira toolkit.\n\n```python\n[(el.name, el.description) for el in json_toolkit.get_tools()]\n```\n\n```output\n[('json_spec_list_keys',\n  '\\n    Can be used to list all keys at a given path. \\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    '),\n ('json_spec_get_value',\n  '\\n    Can be used to see value in string format at a given path.\\n    Before calling this you should be SURE that the path to this exists.\\n    The input is a text representation of the path to the dict in Python syntax (e.g. data[\"key1\"][0][\"key2\"]).\\n    ')]\n```\n\n## Example: getting the required POST parameters for a request​\n\n```python\njson_agent_executor.run(\n    \"What are the required parameters in the request body to the /completions endpoint?\"\n)\n```\n\n```output","type":"Document"},{"metadata":{"language":"en","description":"An output parser was unable to handle model output as expected.","changefreq":"weekly","source":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","title":"OUTPUT_PARSING_FAILURE | 🦜️🔗 LangChain","lastmod":null,"content_type":null,"priority":"0.5","loc":"https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE/","uuid":"f74ec081-2448-5edb-8c30-8e10104b2a6d"},"page_content":"The above exception was the direct cause of the following exception:\n``````output\nOutputParserException                     Traceback (most recent call last)\n``````output\nCell In[9], line 3\n      1 message = AIMessage(content='```\\n{{\"foo\":\\n```')\n      2 output_parser = JsonOutputParser()\n----> 3 output_parser.invoke(message)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:193, in BaseOutputParser.invoke(self, input, config, **kwargs)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n--> 193         return self._call_with_config(\n    194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/base.py:1927, in Runnable._call_with_config(self, func, input, config, run_type, serialized, **kwargs)\n   1923     context = copy_context()\n   1924     context.run(_set_config_context, child_config)\n   1925     output = cast(\n   1926         Output,\n-> 1927         context.run(\n   1928             call_func_with_variable_args,  # type: ignore[arg-type]\n   1929             func,  # type: ignore[arg-type]\n   1930             input,  # type: ignore[arg-type]\n   1931             config,\n   1932             run_manager,\n   1933             **kwargs,\n   1934         ),\n   1935     )\n   1936 except BaseException as e:\n   1937     run_manager.on_chain_error(e)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/runnables/config.py:396, in call_func_with_variable_args(func, input, config, run_manager, **kwargs)\n    394 if run_manager is not None and accepts_run_manager(func):\n    395     kwargs[\"run_manager\"] = run_manager\n--> 396 return func(input, **kwargs)\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/base.py:194, in BaseOutputParser.invoke.<locals>.<lambda>(inner_input)\n    186 def invoke(\n    187     self,\n    188     input: Union[str, BaseMessage],\n    189     config: Optional[RunnableConfig] = None,\n    190     **kwargs: Any,\n    191 ) -> T:\n    192     if isinstance(input, BaseMessage):\n    193         return self._call_with_config(\n--> 194             lambda inner_input: self.parse_result(\n    195                 [ChatGeneration(message=inner_input)]\n    196             ),\n    197             input,\n    198             config,\n    199             run_type=\"parser\",\n    200         )\n    201     else:\n    202         return self._call_with_config(\n    203             lambda inner_input: self.parse_result([Generation(text=inner_input)]),\n    204             input,\n    205             config,\n    206             run_type=\"parser\",\n    207         )\n``````output\nFile ~/langchain/oss-py/libs/core/langchain_core/output_parsers/json.py:86, in JsonOutputParser.parse_result(self, result, partial)\n     84 except JSONDecodeError as e:\n     85     msg = f\"Invalid json output: {text}\"\n---> 86     raise OutputParserException(msg, llm_output=text) from e\n``````output\nOutputParserException: Invalid json output: ```\n{{\"foo\":\n```\n\n```text\n\nNote that some prebuilt constructs like [legacy LangChain agents](/docs/how_to/agent_executor) and chains may use output parsers internally,\nso you may see this error even if you're not visibly instantiating and using an output parser.\n\n## Troubleshooting\n\nThe following may help resolve this error:","type":"Document"},{"metadata":{"description":null,"language":"en","changefreq":null,"source":"https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.schema.EvaluatorType.html","title":"langchain.evaluation.schema.EvaluatorType — 🦜🔗 LangChain 0.2.17","lastmod":null,"content_type":"text/html; charset=utf-8","priority":null,"loc":null,"uuid":"466b5eb7-b125-57f1-a1b6-9b0c39cb3a10"},"page_content":"JSON_VALIDITY = 'json_validity'¶\nCheck if a prediction is valid JSON.\n\nJSON_EQUALITY = 'json_equality'¶\nCheck if a prediction is equal to a reference JSON.\n\nJSON_EDIT_DISTANCE = 'json_edit_distance'¶\nCompute the edit distance between two JSON strings after canonicalization.\n\nJSON_SCHEMA_VALIDATION = 'json_schema_validation'¶\nCheck if a prediction is valid JSON according to a JSON schema.\n\n                                © 2023, LangChain, Inc.\n                                    .\n                            Last updated\n                                on Dec 03, 2024.","type":"Document"},{"metadata":{"description":"This notebook provides a quick overview for getting started with JSON document loader. For detailed documentation of all JSONLoader features and configurations head to the API reference.","language":"en","changefreq":"weekly","source":"https://python.langchain.com/docs/integrations/document_loaders/json/","title":"JSONLoader | 🦜️🔗 LangChain","content_type":null,"lastmod":null,"priority":"0.5","loc":"https://python.langchain.com/docs/integrations/document_loaders/json/","uuid":"1d2ff152-291f-59dd-a531-db8321b228c5"},"page_content":"JSONLoader | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# JSONLoader\n\nThis notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/docs/concepts/document_loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n\n- TODO: Add any other relevant links, like information about underlying API, etc.\n\n## Overview​\n\n### Integration details​\n\n| Class | Package | Local | Serializable | JS support |\n| ---- | ---- | ---- | ---- | ---- |\n| JSONLoader | langchain_community | ✅ | ❌ | ✅ |\n\n### Loader features​\n\n| Source | Document Lazy Loading | Native Async Support |\n| ---- | ---- | ---- |\n| JSONLoader | ✅ | ❌ |\n\n## Setup​\n\nTo access JSON document loader you'll need to install the `langchain-community` integration package as well as the `jq` python package.\n\n### Credentials​\n\nNo credentials are required to use the `JSONLoader` class.\n\nIf you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:\n\n```python\n# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n# os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n```\n\n### Installation​\n\nInstall **langchain_community** and **jq**:\n\n```python\n%pip install -qU langchain_community jq \n```\n\n## Initialization​\n\nNow we can instantiate our model object and load documents:\n\n- TODO: Update model instantiation with relevant params.\n\n```python\nfrom langchain_community.document_loaders import JSONLoader\n\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat.json\",\n    jq_schema=\".messages[].content\",\n    text_content=False,\n)\n```\n\n**API Reference:**[JSONLoader](https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html)\n## Load​\n\n```python\ndocs = loader.load()\ndocs[0]\n```\n\n```output\nDocument(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')\n```\n\n```python\nprint(docs[0].metadata)\n```\n\n```output\n{'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}\n```\n\n## Lazy Load​\n\n```python\npages = []\nfor doc in loader.lazy_load():\n    pages.append(doc)\n    if len(pages) >= 10:\n        # do some paged operation, e.g.\n        # index.upsert(pages)\n\n        pages = []\n```\n\n## Read from JSON Lines file​\n\nIf you want to load documents from a JSON Lines file, you pass `json_lines=True`\nand specify `jq_schema` to extract `page_content` from a single JSON object.\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".content\",\n    text_content=False,\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='Bye!' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## Read specific content keys​\n\nAnother option is to set `jq_schema='.'` and provide a `content_key` in order to only load specific content:\n\n```python\nloader = JSONLoader(\n    file_path=\"./example_data/facebook_chat_messages.jsonl\",\n    jq_schema=\".\",\n    content_key=\"sender_name\",\n    json_lines=True,\n)\n\ndocs = loader.load()\nprint(docs[0])\n```\n\n```output\npage_content='User 2' metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat_messages.jsonl', 'seq_num': 1}\n```\n\n## JSON file with jq schema content_key​","type":"Document"}],"answer":"The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","query":"_______________________________________________________________________________________________________ ERROR collecting tests/test_agent.py ________________________________________________________________________________________________________\ntests/test_agent.py:307: in <module>\n    run_workflow_as_server('cra.json')\ntests/test_agent.py:302: in run_workflow_as_server\n    llm = get_llm_model().bind_tools(tools)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1103: in bind_tools\n    convert_to_openai_tool(tool, strict=strict) for tool in tools\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:466: in convert_to_openai_tool\n    oai_function = convert_to_openai_function(tool, strict=strict)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:412: in convert_to_openai_function\n    oai_function = cast(dict, convert_python_function_to_openai_function(function))\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:182: in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/utils/function_calling.py:181: in convert_python_function_to_openai_function\n    model = create_schema_from_function(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:282: in create_schema_from_function\n    description, arg_descriptions = _infer_arg_descriptions(\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:155: in _infer_arg_descriptions\n    _validate_docstring_args_against_annotations(arg_descriptions, annotations)\n../../../../Library/Caches/pypoetry/virtualenvs/core-ai-7T-fVq00-py3.12/lib/python3.12/site-packages/langchain_core/tools/base.py:132: in _validate_docstring_args_against_annotations\n    raise ValueError(msg)\nE   ValueError: Arg query (str) in docstring not found in function signature.\n============================================================================================================== short test summary info ==============================================================================================================\nERROR tests/test_agent.py - ValueError: Arg query (str) in docstring not found in function signature.\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: 1 error during collection !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n================================================================================================================= 1 error in 0.35s ==================================================================================================================\n(base) ➜  core-ai git:(gw/workflow) ✗ ","num_response_attempts":2}},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":20,"langgraph_node":"respond","langgraph_triggers":["branch:respond:check_hallucination:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:4"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T200001263059Z85066f84-90de-4c8b-bf10-edbbe6052031.20241204T200014644615Za8fdc9d7-05c1-4ea7-a49e-73c543216e9c"}
{"id":"a8fdc9d7-05c1-4ea7-a49e-73c543216e9c","name":"check_hallucination","end_time":"2024-12-04T20:00:16.439659","error":null,"outputs":{"output":"end"}}
{"id":"cdabb123-fc0a-46e5-8d35-e642382c6520","name":"RunnableSequence","start_time":"2024-12-04T20:00:14.784868","serialized":null,"events":[{"name":"start","time":"2024-12-04T20:00:14.784868+00:00"},{"name":"end","time":"2024-12-04T20:00:16.024888+00:00"}],"inputs":{"input":[{"role":"system","content":"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \n \n    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts."},{"role":"human","content":"Set of facts: \n\n <documents>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='594f3236-69b3-5723-8a2a-a67328032782'>\n{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}\n</document>\n<document  description='Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' title='Spreedly | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' uuid='be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee'>\n```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n</document>\n<document  language='en' description=\"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.\" changefreq='weekly' source='https://python.langchain.com/docs/how_to/graph_mapping/' title='How to map values to a graph database | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/graph_mapping/' uuid='ca98b026-baac-5e7f-b687-b177bbf581a0'>\nchain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)\n</document>\n<document  language='en' description='Learn about how the self-querying retriever works here.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/retrievers/self_query/' title='Self-querying retrievers | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/retrievers/self_query/' uuid='315c889a-0f5a-531c-93d4-6c64c77d8abf'>\nSelf-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).\n</document>\n<document  language='en' description='Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.' changefreq='weekly' source='https://python.langchain.com/docs/how_to/query_no_queries/' title='How to handle cases where no queries are generated | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/query_no_queries/' uuid='7c753e2b-c599-5f69-a535-539b12f6c2ed'>\n```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)\n</document>\n<document  description='This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' title='ArcGIS | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' uuid='a9dd78eb-3537-55b1-9e6d-99f9d35a489e'>\n\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```\n</document>\n<document  description='Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.' language='en' changefreq=None source='https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax' title='Trace query syntax | 🦜️🛠️ LangSmith' content_type='text/html; charset=utf-8' lastmod=None priority=None loc=None uuid='6103ddb5-52da-5eae-a911-513966d65f00'>\nTrace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\n</document>\n<document  description=\"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.\" language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/sql_query_checking/' title='How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/sql_query_checking/' uuid='5cea0388-8300-5f71-8f8f-8a94daff7a9d'>\n```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='7ed75ace-8a2b-55de-a415-25083eeba332'>\nquery_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n</document>\n<document  description='This guide assumes familiarity with the following concepts:' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/tool_stream_events/' title='How to stream events from a tool | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/tool_stream_events/' uuid='51f0caf5-c4da-5d8d-9eea-5838a8fb4081'>\n## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)\n</document>\n<document  language='en' description=\"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾\" changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/gradio_tools/' title='Gradio | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/gradio_tools/' uuid='7f36aaa8-0f01-59e6-a58b-df56996a9048'>\nJob Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)\n</document>\n<document  description='ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/clickup/' title='ClickUp Toolkit | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/clickup/' uuid='1a2a0382-266f-5818-9794-e1d0b756039b'>\n```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)\n</document>\n<document  language='' description='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='483a01c0-c8d8-568d-80e3-4c7349518f0d'>\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' title='Review Tool Calls | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' uuid='a7380d1f-89be-5df5-9f1e-6b74afb1a49d'>\nOutput:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '\n</document>\n<document  description=\"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.\" language='en' changefreq=None source='https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api' title='Manage your organization using the API | 🦜️🛠️ LangSmith' lastmod=None content_type='text/html; charset=utf-8' priority=None loc=None uuid='cd89709f-0016-5447-9ab3-2e9efb7db0fa'>\nSample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.\n</document>\n<document  description='You are passing too many, too few, or mismatched ToolMessages to a model.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' title='INVALID_TOOL_RESULTS | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' uuid='62856b31-ccd6-527f-a540-677a2f8170eb'>\nSee [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  language='en' description='ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/providers/datadog/' title='Datadog Tracing | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/providers/datadog/' uuid='aac182d0-171a-5d65-a00e-60b5a764e813'>\n## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  description='JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/document_loader_json/' title='How to load JSON | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/document_loader_json/' uuid='67c83a8d-a61d-5338-a82c-cedaa5def0c1'>\nJSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' title='SDK (Python) | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' uuid='d7081e58-73a0-55f5-9a3f-25d019980493'>\n}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' title='How to create agents with configuration | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' uuid='19b61e09-1d71-560a-a077-a45a31445149'>\nHow to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'\n</document>\n</documents> \n\n LLM generation: The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up."}]},"run_type":"chain","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":20,"langgraph_node":"respond","langgraph_triggers":["branch:respond:check_hallucination:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":[],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T200001263059Z85066f84-90de-4c8b-bf10-edbbe6052031.20241204T200014644615Za8fdc9d7-05c1-4ea7-a49e-73c543216e9c.20241204T200014784868Zcdabb123-fc0a-46e5-8d35-e642382c6520"}
{"id":"cdabb123-fc0a-46e5-8d35-e642382c6520","name":"RunnableSequence","end_time":"2024-12-04T20:00:16.024888","error":null,"outputs":{"output":{"binary_score":"no"}}}
{"id":"9834a412-246b-46d9-9e59-767e8231fd97","name":"ChatOpenAI","start_time":"2024-12-04T20:00:14.794974","serialized":null,"events":[{"name":"start","time":"2024-12-04T20:00:14.794974+00:00"},{"name":"new_token","time":"2024-12-04T20:00:15.902593+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:15.906465+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:15.910633+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:15.914535+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:15.995555+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:15.999052+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:16.002566+00:00","kwargs":{"token":""}},{"name":"new_token","time":"2024-12-04T20:00:16.006909+00:00","kwargs":{"token":""}},{"name":"end","time":"2024-12-04T20:00:16.013747+00:00"}],"inputs":{"messages":[[{"lc":1,"type":"constructor","id":["langchain","schema","messages","SystemMessage"],"kwargs":{"content":"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts. \n \n    Give a binary score 'yes' or 'no'. 'Yes' means that the answer is grounded in / supported by the set of facts.","type":"system"}},{"lc":1,"type":"constructor","id":["langchain","schema","messages","HumanMessage"],"kwargs":{"content":"Set of facts: \n\n <documents>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='594f3236-69b3-5723-8a2a-a67328032782'>\n{'correct_query': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'function': {'arguments': '{\"query\":\"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\\\nFROM Invoice i\\\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\\\nWHERE strftime(\\'%Y\\', i.InvoiceDate) = \\'2009\\'\\\\nGROUP BY e.EmployeeId\\\\nORDER BY TotalSales DESC\\\\nLIMIT 1;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 337, 'total_tokens': 427}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-71067e75-80f6-4356-8239-518e466b3526-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': \"SELECT e.FirstName, e.LastName, SUM(i.Total) as TotalSales\\nFROM Invoice i\\nJOIN Customer c ON i.CustomerId = c.CustomerId\\nJOIN Employee e ON c.SupportRepId = e.EmployeeId\\nWHERE strftime('%Y', i.InvoiceDate) = '2009'\\nGROUP BY e.EmployeeId\\nORDER BY TotalSales DESC\\nLIMIT 1;\"}, 'id': 'call_FwCE2c7WORU7lKHdSWqMv0ON', 'type': 'tool_call'}], usage_metadata={'input_tokens': 337, 'output_tokens': 90, 'total_tokens': 427})]}}\n{'execute_query': {'messages': [ToolMessage(content=\"[('Steve', 'Johnson', 164.34)]\", name='db_query_tool', tool_call_id='call_FwCE2c7WORU7lKHdSWqMv0ON')]}}\n{'query_gen': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'function': {'arguments': '{\"final_answer\":\"The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.\"}', 'name': 'SubmitFinalAnswer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 1553, 'total_tokens': 1594}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_cb7cc8e106', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-2ec7bf3a-2a16-47bd-aa9c-b7d6dc531c1b-0', tool_calls=[{'name': 'SubmitFinalAnswer', 'args': {'final_answer': 'The sales agent who made the most in sales in 2009 is Steve Johnson with total sales of 164.34.'}, 'id': 'call_fHJ4lvdiFM9HY6gupE6vLZV4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1553, 'output_tokens': 41, 'total_tokens': 1594})]}}\n</document>\n<document  description='Spreedly is a service that allows you to securely store credit cards and use them to transact against any number of payment gateways and third party APIs. It does this by simultaneously providing a card tokenization/vault service as well as a gateway and receiver integration service. Payment methods tokenized by Spreedly are stored at Spreedly, allowing you to independently store a card and then pass that card to different end points based on your business requirements.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' title='Spreedly | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/spreedly/' uuid='be8ce1f5-2d6f-5220-b9b5-0e72e27e29ee'>\n```output\n[Document(page_content='installment_grace_period_duration\\nreference_data_code\\ninvoice_number\\ntax_management_indicator\\noriginal_amount\\ninvoice_amount\\nvat_tax_rate\\nmobile_remote_payment_type\\ngratuity_amount\\nmdd_field_1\\nmdd_field_2\\nmdd_field_3\\nmdd_field_4\\nmdd_field_5\\nmdd_field_6\\nmdd_field_7\\nmdd_field_8\\nmdd_field_9\\nmdd_field_10\\nmdd_field_11\\nmdd_field_12\\nmdd_field_13\\nmdd_field_14\\nmdd_field_15\\nmdd_field_16\\nmdd_field_17\\nmdd_field_18\\nmdd_field_19\\nmdd_field_20\\nsupported_countries: US\\nAE\\nBR\\nCA\\nCN\\nDK\\nFI\\nFR\\nDE\\nIN\\nJP\\nMX\\nNO\\nSE\\nGB\\nSG\\nLB\\nPK\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\ndiners_club\\njcb\\ndankort\\nmaestro\\nelo\\nregions: asia_pacific\\neurope\\nlatin_america\\nnorth_america\\nhomepage: http://www.cybersource.com\\ndisplay_api_url: https://ics2wsa.ic3.com/commerce/1.x/transactionProcessor\\ncompany_name: CyberSource', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='BG\\nBH\\nBI\\nBJ\\nBM\\nBN\\nBO\\nBR\\nBS\\nBT\\nBW\\nBY\\nBZ\\nCA\\nCC\\nCF\\nCH\\nCK\\nCL\\nCM\\nCN\\nCO\\nCR\\nCV\\nCX\\nCY\\nCZ\\nDE\\nDJ\\nDK\\nDO\\nDZ\\nEC\\nEE\\nEG\\nEH\\nES\\nET\\nFI\\nFJ\\nFK\\nFM\\nFO\\nFR\\nGA\\nGB\\nGD\\nGE\\nGF\\nGG\\nGH\\nGI\\nGL\\nGM\\nGN\\nGP\\nGQ\\nGR\\nGT\\nGU\\nGW\\nGY\\nHK\\nHM\\nHN\\nHR\\nHT\\nHU\\nID\\nIE\\nIL\\nIM\\nIN\\nIO\\nIS\\nIT\\nJE\\nJM\\nJO\\nJP\\nKE\\nKG\\nKH\\nKI\\nKM\\nKN\\nKR\\nKW\\nKY\\nKZ\\nLA\\nLC\\nLI\\nLK\\nLS\\nLT\\nLU\\nLV\\nMA\\nMC\\nMD\\nME\\nMG\\nMH\\nMK\\nML\\nMN\\nMO\\nMP\\nMQ\\nMR\\nMS\\nMT\\nMU\\nMV\\nMW\\nMX\\nMY\\nMZ\\nNA\\nNC\\nNE\\nNF\\nNG\\nNI\\nNL\\nNO\\nNP\\nNR\\nNU\\nNZ\\nOM\\nPA\\nPE\\nPF\\nPH\\nPK\\nPL\\nPN\\nPR\\nPT\\nPW\\nPY\\nQA\\nRE\\nRO\\nRS\\nRU\\nRW\\nSA\\nSB\\nSC\\nSE\\nSG\\nSI\\nSK\\nSL\\nSM\\nSN\\nST\\nSV\\nSZ\\nTC\\nTD\\nTF\\nTG\\nTH\\nTJ\\nTK\\nTM\\nTO\\nTR\\nTT\\nTV\\nTW\\nTZ\\nUA\\nUG\\nUS\\nUY\\nUZ\\nVA\\nVC\\nVE\\nVI\\nVN\\nVU\\nWF\\nWS\\nYE\\nYT\\nZA\\nZM\\nsupported_cardtypes: visa\\nmaster\\namerican_express\\ndiscover\\njcb\\nmaestro\\nelo\\nnaranja\\ncabal\\nunionpay\\nregions: asia_pacific\\neurope\\nmiddle_east\\nnorth_america\\nhomepage: http://worldpay.com\\ndisplay_api_url: https://secure.worldpay.com/jsp/merchant/xml/paymentService.jsp\\ncompany_name: WorldPay', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n Document(page_content='gateway_specific_fields: receipt_email\\nradar_session_id\\nskip_radar_rules\\napplication_fee\\nstripe_account\\nmetadata\\nidempotency_key\\nreason\\nrefund_application_fee\\nrefund_fee_amount\\nreverse_transfer\\naccount_id\\ncustomer_id\\nvalidate\\nmake_default\\ncancellation_reason\\ncapture_method\\nconfirm\\nconfirmation_method\\ncustomer\\ndescription\\nmoto\\noff_session\\non_behalf_of\\npayment_method_types\\nreturn_email\\nreturn_url\\nsave_payment_method\\nsetup_future_usage\\nstatement_descriptor\\nstatement_descriptor_suffix\\ntransfer_amount\\ntransfer_destination\\ntransfer_group\\napplication_fee_amount\\nrequest_three_d_secure\\nerror_on_requires_action\\nnetwork_transaction_id\\nclaim_without_transaction_id\\nfulfillment_date\\nevent_type\\nmodal_challenge\\nidempotent_request\\nmerchant_reference\\ncustomer_reference\\nshipping_address_zip\\nshipping_from_zip\\nshipping_amount\\nline_items\\nsupported_countries: AE\\nAT\\nAU\\nBE\\nBG\\nBR\\nCA\\nCH\\nCY\\nCZ\\nDE\\nDK\\nEE\\nES\\nFI\\nFR\\nGB\\nGR\\nHK\\nHU\\nIE\\nIN\\nIT\\nJP\\nLT\\nLU\\nLV\\nMT\\nMX\\nMY\\nNL\\nNO\\nNZ\\nPL\\nPT\\nRO\\nSE\\nSG\\nSI\\nSK\\nUS\\nsupported_cardtypes: visa', metadata={'source': 'https://core.spreedly.com/v1/gateways_options.json'}),\n</document>\n<document  language='en' description=\"In this guide we'll go over strategies to improve graph database query generation by mapping values from user inputs to database.\" changefreq='weekly' source='https://python.langchain.com/docs/how_to/graph_mapping/' title='How to map values to a graph database | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/graph_mapping/' uuid='ca98b026-baac-5e7f-b687-b177bbf581a0'>\nchain = (\n    RunnablePassthrough.assign(query=cypher_response)\n    | RunnablePassthrough.assign(\n        response=lambda x: graph.query(cypher_validation(x[\"query\"])),\n    )\n    | response_prompt\n    | llm\n    | StrOutputParser()\n)\n```\n\n```python\nchain.invoke({\"question\": \"Who played in Casino movie?\"})\n```\n\n```output\n'Robert De Niro, James Woods, Joe Pesci, and Sharon Stone played in the movie \"Casino\".'\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)\n\n- [Detecting entities in the user input](#detecting-entities-in-the-user-input)\n\n- [Custom Cypher generating chain](#custom-cypher-generating-chain)\n\n- [Generating answers based on database results](#generating-answers-based-on-database-results)\n</document>\n<document  language='en' description='Learn about how the self-querying retriever works here.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/retrievers/self_query/' title='Self-querying retrievers | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/retrievers/self_query/' uuid='315c889a-0f5a-531c-93d4-6c64c77d8abf'>\nSelf-querying retrievers | 🦜️🔗 LangChain\n\n[Skip to main content](#__docusaurus_skipToContent_fallback)# Self-querying retrievers\n\nLearn about how the self-querying retriever works [here](/docs/how_to/self_query/).\n</document>\n<document  language='en' description='Sometimes, a query analysis technique may allow for any number of queries to be generated - including no queries! In this case, our overall chain will need to inspect the result of the query analysis before deciding whether to call the retriever or not.' changefreq='weekly' source='https://python.langchain.com/docs/how_to/query_no_queries/' title='How to handle cases where no queries are generated | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/query_no_queries/' uuid='7c753e2b-c599-5f69-a535-539b12f6c2ed'>\n```python\nquery_analyzer.invoke(\"where did Harrison Work\")\n```\n\n```output\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'function': {'arguments': '{\"query\":\"Harrison\"}', 'name': 'Search'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 95, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ea94d376-37bf-4f80-abe6-e3b42b767ea0-0', tool_calls=[{'name': 'Search', 'args': {'query': 'Harrison'}, 'id': 'call_korLZrh08PTRL94f4L7rFqdj', 'type': 'tool_call'}], usage_metadata={'input_tokens': 95, 'output_tokens': 14, 'total_tokens': 109})\n```\n\n```python\nquery_analyzer.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-ebdfc44a-455a-4ca6-be85-84559886b1e1-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n## Retrieval with query analysis​\n\nSo how would we include this in a chain? Let's look at an example below.\n\n```python\nfrom langchain_core.output_parsers.openai_tools import PydanticToolsParser\nfrom langchain_core.runnables import chain\n\noutput_parser = PydanticToolsParser(tools=[Search])\n```\n\n**API Reference:**[PydanticToolsParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.openai_tools.PydanticToolsParser.html) | [chain](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.chain.html)\n```python\n@chain\ndef custom_chain(question):\n    response = query_analyzer.invoke(question)\n    if \"tool_calls\" in response.additional_kwargs:\n        query = output_parser.invoke(response)\n        docs = retriever.invoke(query[0].query)\n        # Could add more logic - like another LLM call - here\n        return docs\n    else:\n        return response\n```\n\n```python\ncustom_chain.invoke(\"where did Harrison Work\")\n```\n\n```output\nNumber of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n```\n\n```output\n[Document(page_content='Harrison worked at Kensho')]\n```\n\n```python\ncustom_chain.invoke(\"hi!\")\n```\n\n```output\nAIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 93, 'total_tokens': 103}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_483d39d857', 'finish_reason': 'stop', 'logprobs': None}, id='run-e87f058d-30c0-4075-8a89-a01b982d557e-0', usage_metadata={'input_tokens': 93, 'output_tokens': 10, 'total_tokens': 103})\n```\n\n#### Was this page helpful?\n\n- [Setup](#setup)- [Create Index](#create-index)\n\n- [Query analysis](#query-analysis)\n\n- [Retrieval with query analysis](#retrieval-with-query-analysis)\n</document>\n<document  description='This notebook demonstrates the use of the langchaincommunity.documentloaders.ArcGISLoader class.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' title='ArcGIS | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/document_loaders/arcgis/' uuid='a9dd78eb-3537-55b1-9e6d-99f9d35a489e'>\n\"maxRecordCount\": 1000,\n   \"supportsStatistics\": true,\n   \"supportsAdvancedQueries\": true,\n   \"supportedQueryFormats\": \"JSON, geoJSON\",\n   \"isDataVersioned\": false,\n   \"ownershipBasedAccessControlForFeatures\": {\n     \"allowOthersToQuery\": true\n   },\n   \"useStandardizedQueries\": true,\n   \"advancedQueryCapabilities\": {\n     \"useStandardizedQueries\": true,\n     \"supportsStatistics\": true,\n     \"supportsHavingClause\": true,\n     \"supportsCountDistinct\": true,\n     \"supportsOrderBy\": true,\n     \"supportsDistinct\": true,\n     \"supportsPagination\": true,\n     \"supportsTrueCurve\": true,\n     \"supportsReturningQueryExtent\": true,\n     \"supportsQueryWithDistance\": true,\n     \"supportsSqlExpression\": true\n   },\n   \"supportsDatumTransformation\": true,\n   \"dateFieldsTimeReference\": null,\n   \"supportsCoordinatesQuantization\": true\n }}\n```\n</document>\n<document  description='Using the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.' language='en' changefreq=None source='https://docs.smith.langchain.com/reference/data_formats/trace_query_syntax' title='Trace query syntax | 🦜️🛠️ LangSmith' content_type='text/html; charset=utf-8' lastmod=None priority=None loc=None uuid='6103ddb5-52da-5eae-a911-513966d65f00'>\nTrace query syntax | 🦜️🛠️ LangSmith\n\nSkip to main contentGo to API DocsSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringDeployment (LangGraph Platform)AdministrationSelf-hostingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsExample data formatRun (span) data formatFeedback data formatTrace query syntaxDataset prebuilt JSON schema typesEvaluationDataset transformationsRegions FAQSDK referenceLangChain off-the-shelf evaluatorsReferencedata_formatsTrace query syntaxOn this pageTrace query syntax\nUsing the list_runs method in the SDK or /runs/query endpoint in the API, you can filter runs to analyze and export.\nFilter arguments​\nKeysDescriptionproject_id / project_nameThe project(s) to fetch runs from - can be a single project or a list of projects.trace_idFetch runs that are part of a specific trace.run_typeThe type of run to get, such as llm, chain, tool, retriever, etc.dataset_name / dataset_idFetch runs that are associated with an example row in the specified dataset. This is useful for comparing prompts or models over a given dataset.reference_example_idFetch runs that are associated with a specific example row. This is useful for comparing prompts or models on a given input.parent_run_idFetch runs that are children of a given run. This is useful for fetching runs grouped together using the context manager or for fetching an agent trajectory.errorFetch runs that errored or did not error.run_idsFetch runs with a given list of run ids. Note: This will ignore all other filtering arguments.filterFetch runs that match a given structured filter statement. See the guide below for more information.trace_filterFilter to apply to the ROOT run in the trace tree. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of the root run within a trace.tree_filterFilter to apply to OTHER runs in the trace tree, including sibling and child runs. This is meant to be used in conjunction with the regular filter parameter to let you filter runs by attributes of any run within a trace.is_rootOnly return root runs.selectSelect the fields to return in the response. By default, all fields are returned.query (experimental)Natural language query, which translates your query into a filter statement.\nFilter query language​\nLangSmith supports powerful filtering capabilities with a filter query language to permit complex filtering operations when fetching runs.\nThe filtering grammar is based on common comparators on fields in the run object. Supported comparators include:\n\ngte (greater than or equal to)\ngt (greater than)\nlte (less than or equal to)\nlt (less than)\neq (equal to)\nneq (not equal to)\nhas (check if run contains a tag or metadata json blob)\nsearch (search for a substring in a string field)\n\nAdditionally, you can combine multiple comparisons through and and or operators.\nThese can be applied on fields of the run object, such as its id, name, run_type, start_time / end_time, latency, total_tokens, error, execution_order, tags, and any associated feedback through feedback_key and feedback_score.Was this page helpful?You can leave detailed feedback on GitHub.PreviousFeedback data formatNextDataset prebuilt JSON schema typesFilter argumentsFilter query languageCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright © 2024 LangChain, Inc.\n</document>\n<document  description=\"Perhaps the most error-prone part of any SQL chain or agent is writing valid and safe SQL queries. In this guide we'll go over some strategies for validating our queries and handling invalid queries.\" language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/sql_query_checking/' title='How to do query validation as part of SQL question-answering | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/sql_query_checking/' uuid='5cea0388-8300-5f71-8f8f-8a94daff7a9d'>\n```python\nimport getpass\nimport os\n\nos.environ[\"COHERE_API_KEY\"] = getpass.getpass()\n\nfrom langchain_cohere import ChatCohere\n\nllm = ChatCohere(model=\"command-r-plus\")\n```\n\nNVIDIA\n```bash\npip install -qU langchain-nvidia-ai-endpoints\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"NVIDIA_API_KEY\"] = getpass.getpass()\n\nfrom langchain_nvidia_ai_endpoints import ChatNVIDIA\n\nllm = ChatNVIDIA(model=\"meta/llama3-70b-instruct\")\n```\n\nFireworksAI\n```bash\npip install -qU langchain-fireworks\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass()\n\nfrom langchain_fireworks import ChatFireworks\n\nllm = ChatFireworks(model=\"accounts/fireworks/models/llama-v3p1-70b-instruct\")\n```\n\nGroq\n```bash\npip install -qU langchain-groq\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"GROQ_API_KEY\"] = getpass.getpass()\n\nfrom langchain_groq import ChatGroq\n\nllm = ChatGroq(model=\"llama3-8b-8192\")\n```\n\nMistralAI\n```bash\npip install -qU langchain-mistralai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")\n```\n\nTogetherAI\n```bash\npip install -qU langchain-openai\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"TOGETHER_API_KEY\"] = getpass.getpass()\n\nfrom langchain_openai import ChatOpenAI\n\nllm = ChatOpenAI(\n    base_url=\"https://api.together.xyz/v1\",\n    api_key=os.environ[\"TOGETHER_API_KEY\"],\n    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n)\n```\n\nDatabricks\n```bash\npip install -qU databricks-langchain\n```\n\n```python\nimport getpass\nimport os\n\nos.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass()\n\nfrom databricks_langchain import ChatDatabricks\n\nos.environ[\"DATABRICKS_HOST\"] = \"https://example.staging.cloud.databricks.com/serving-endpoints\"\n\nllm = ChatDatabricks(endpoint=\"databricks-meta-llama-3-1-70b-instruct\")\n```\n\n```python\nfrom langchain.chains import create_sql_query_chain\n\nchain = create_sql_query_chain(llm, db)\n```\n\n**API Reference:**[create_sql_query_chain](https://python.langchain.com/api_reference/langchain/chains/langchain.chains.sql_database.query.create_sql_query_chain.html)\nAnd we want to validate its outputs. We can do so by extending the chain with a second prompt and model call:\n\n```python\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\n\nsystem = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n- Using NOT IN with NULL values\n- Using UNION when UNION ALL should have been used\n- Using BETWEEN for exclusive ranges\n- Data type mismatch in predicates\n- Properly quoting identifiers\n- Using the correct number of arguments for functions\n- Casting to the correct data type\n- Using the proper columns for joins\n\nIf there are any of the above mistakes, rewrite the query.\nIf there are no mistakes, just reproduce the original query with no further commentary.\n\nOutput the final SQL query only.\"\"\"\nprompt = ChatPromptTemplate.from_messages(\n    [(\"system\", system), (\"human\", \"{query}\")]\n).partial(dialect=db.dialect)\nvalidation_chain = prompt | llm | StrOutputParser()\n\nfull_chain = {\"query\": chain} | validation_chain\n```\n\n**API Reference:**[StrOutputParser](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.string.StrOutputParser.html) | [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html)\n```python\nquery = full_chain.invoke(\n    {\n        \"question\": \"What's the average Invoice from an American customer whose Fax is missing since 2003 but before 2010\"\n    }\n)\nprint(query)\n```\n\n```output\nSELECT AVG(i.Total) AS AverageInvoice\nFROM Invoice i\nJOIN Customer c ON i.CustomerId = c.CustomerId\nWHERE c.Country = 'USA'\nAND c.Fax IS NULL\nAND i.InvoiceDate >= '2003-01-01' \nAND i.InvoiceDate < '2010-01-01'\n```\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='7ed75ace-8a2b-55de-a415-25083eeba332'>\nquery_check.invoke({\"messages\": [(\"user\", \"SELECT * FROM Artist LIMIT 10;\")]})\n\nAIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'function': {'arguments': '{\"query\":\"SELECT * FROM Artist LIMIT 10;\"}', 'name': 'db_query_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 221, 'total_tokens': 241}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_a2ff031fb5', 'finish_reason': 'stop', 'logprobs': None}, id='run-dd7873ef-d2f7-4769-a5c0-e6776ec2c515-0', tool_calls=[{'name': 'db_query_tool', 'args': {'query': 'SELECT * FROM Artist LIMIT 10;'}, 'id': 'call_la8JTjHox6P1VjTqc15GSgdk', 'type': 'tool_call'}], usage_metadata={'input_tokens': 221, 'output_tokens': 20, 'total_tokens': 241})\n\nAPI Reference:\nChatPromptTemplate\n\nDefine the workflow¶\nWe will then define the workflow for the agent. The agent will first force-call the list_tables_tool to fetch the available tables from the database, then follow the steps mentioned at the beginning of the tutorial.\n\nUsing Pydantic with LangChain\n\n        This notebook uses Pydantic v2 BaseModel, which requires langchain-core >= 0.3. Using langchain-core < 0.3 will result in errors due to mixing of Pydantic v1 and v2 BaseModels.\n    \n\nfrom typing import Annotated, Literal\n\nfrom langchain_core.messages import AIMessage\nfrom langchain_openai import ChatOpenAI\n\nfrom pydantic import BaseModel, Field\nfrom typing_extensions import TypedDict\n\nfrom langgraph.graph import END, StateGraph, START\nfrom langgraph.graph.message import AnyMessage, add_messages\n\n# Define the state for the agent\nclass State(TypedDict):\n    messages: Annotated[list[AnyMessage], add_messages]\n\n# Define a new graph\nworkflow = StateGraph(State)\n\n# Add a node for the first tool call\ndef first_tool_call(state: State) -> dict[str, list[AIMessage]]:\n    return {\n        \"messages\": [\n            AIMessage(\n                content=\"\",\n                tool_calls=[\n                    {\n                        \"name\": \"sql_db_list_tables\",\n                        \"args\": {},\n                        \"id\": \"tool_abcd123\",\n                    }\n                ],\n            )\n        ]\n    }\n\ndef model_check_query(state: State) -> dict[str, list[AIMessage]]:\n    \"\"\"\n    Use this tool to double-check if your query is correct before executing it.\n    \"\"\"\n    return {\"messages\": [query_check.invoke({\"messages\": [state[\"messages\"][-1]]})]}\n\nworkflow.add_node(\"first_tool_call\", first_tool_call)\n\n# Add nodes for the first two tools\nworkflow.add_node(\n    \"list_tables_tool\", create_tool_node_with_fallback([list_tables_tool])\n)\nworkflow.add_node(\"get_schema_tool\", create_tool_node_with_fallback([get_schema_tool]))\n\n# Add a node for a model to choose the relevant tables based on the question and available tables\nmodel_get_schema = ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [get_schema_tool]\n)\nworkflow.add_node(\n    \"model_get_schema\",\n    lambda state: {\n        \"messages\": [model_get_schema.invoke(state[\"messages\"])],\n    },\n)\n\n# Describe a tool to represent the end state\nclass SubmitFinalAnswer(BaseModel):\n    \"\"\"Submit the final answer to the user based on the query results.\"\"\"\n\n    final_answer: str = Field(..., description=\"The final answer to the user\")\n\n# Add a node for a model to generate a query based on the question and schema\nquery_gen_system = \"\"\"You are a SQL expert with a strong attention to detail.\n\nGiven an input question, output a syntactically correct SQLite query to run, then look at the results of the query and return the answer.\n\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n</document>\n<document  description='This guide assumes familiarity with the following concepts:' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/tool_stream_events/' title='How to stream events from a tool | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/how_to/tool_stream_events/' uuid='51f0caf5-c4da-5d8d-9eea-5838a8fb4081'>\n## Next steps​\n\nYou've now seen how to stream events from within a tool. Next, check out the following guides for more on using tools:\n\n- Pass [runtime values to tools](/docs/how_to/tool_runtime/)\n\n- Pass [tool results back to a model](/docs/how_to/tool_results_pass_to_model/)\n\n- [Dispatch custom callback events](/docs/how_to/callbacks_custom_events/)\n\nYou can also check out some more specific uses of tool calling:\n\n- Building [tool-using chains and agents](/docs/how_to/#tools)\n\n- Getting [structured outputs](/docs/how_to/structured_output/) from models\n\n#### Was this page helpful?\n\n- [Next steps](#next-steps)\n</document>\n<document  language='en' description=\"There are many 1000s of Gradio apps on Hugging Face Spaces. This library puts them at the tips of your LLM's fingers 🦾\" changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/gradio_tools/' title='Gradio | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/gradio_tools/' uuid='7f36aaa8-0f01-59e6-a58b-df56996a9048'>\nJob Status: Status.PROCESSING eta: None\n\nObservation: [36;1m[1;3m/Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: ImageCaptioner\nAction Input: /Users/harrisonchase/workplace/langchain/docs/modules/agents/tools/integrations/2e280ce4-4974-4420-8680-450825c31601/tmpfmiz2g1c.jpg[0m\nJob Status: Status.STARTING eta: None\n\nObservation: [33;1m[1;3ma painting of a dog sitting on a skateboard[0m\nThought:[32;1m[1;3m Do I need to use a tool? Yes\nAction: TextToVideo\nAction Input: a painting of a dog sitting on a skateboard[0m\nJob Status: Status.STARTING eta: None\nDue to heavy traffic on this app, the prediction will take approximately 73 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 73.89824726581574\nDue to heavy traffic on this app, the prediction will take approximately 42 seconds.For faster predictions without waiting in queue, you may duplicate the space using: Client.duplicate(damo-vilab/modelscope-text-to-video-synthesis)\n\nJob Status: Status.IN_QUEUE eta: 42.49370198879602\n\nJob Status: Status.IN_QUEUE eta: 21.314297944849187\n\nObservation: [31;1m[1;3m/var/folders/bm/ylzhm36n075cslb9fvvbgq640000gn/T/tmp5snj_nmzf20_cb3m.mp4[0m\nThought:[32;1m[1;3m Do I need to use a tool? No\nAI: Here is a video of a painting of a dog sitting on a skateboard.[0m\n\n[1m> Finished chain.[0m\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Using a tool](#using-a-tool)\n\n- [Using within an agent](#using-within-an-agent)\n\n- [Related](#related)\n</document>\n<document  description='ClickUp is an all-in-one productivity platform that provides small and large teams across industries with flexible and customizable work management solutions, tools, and functions.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/integrations/tools/clickup/' title='ClickUp Toolkit | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/tools/clickup/' uuid='1a2a0382-266f-5818-9794-e1d0b756039b'>\n```output\n[94m$ COMMAND[0m\nFigure out what user ID Rodrigo is, create a task called 'Rod's task', assign it to Rodrigo\n\n[94m$ AGENT[0m\n\n[1m> Entering new AgentExecutor chain...[0m\n[32;1m[1;3m I need to get the user ID of Rodrigo, create a task, and assign it to Rodrigo\nAction: Get Teams\nAction Input: No input necessary[0m\nObservation: [38;5;200m[1;3m{'teams': [{'id': '9011010153', 'name': 'Task Copilot Sandbox Workspace 1', 'members': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'email': 'rlentini@clickup.com', 'initials': 'RL'}]}]}[0m\nThought:[32;1m[1;3m I now have the user ID of Rodrigo\nAction: Create Task\nAction Input: {\"name\": \"Rod's task\", \"assignees\": [81928627]}[0m\n``````output\n/Users/rodrigolentini/repos/langchain-clickup/libs/langchain/langchain/utilities/clickup.py:145: UserWarning: Error encountered while trying to parse <class 'langchain_community.utilities.clickup.Task'>: 'NoneType' object is not subscriptable\n Falling back to returning input data.\n  warnings.warn(f'Error encountered while trying to parse {dataclass}: {e}\\n Falling back to returning input data.')\n``````output\n\nObservation: [36;1m[1;3m{'id': '8685mw6dz', 'custom_id': None, 'name': \"Rod's task\", 'text_content': '', 'description': '', 'status': {'id': 'p90110061901_VlN8IJtk', 'status': 'to do', 'color': '#87909e', 'orderindex': 0, 'type': 'open'}, 'orderindex': '24.00000000000000000000000000000000', 'date_created': '1695047740939', 'date_updated': '1695047740939', 'date_closed': None, 'date_done': None, 'archived': False, 'creator': {'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'email': 'rlentini@clickup.com', 'profilePicture': None}, 'assignees': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'watchers': [{'id': 81928627, 'username': 'Rodrigo Ceballos Lentini', 'color': '#c51162', 'initials': 'RL', 'email': 'rlentini@clickup.com', 'profilePicture': None}], 'checklists': [], 'tags': [], 'parent': None, 'priority': None, 'due_date': None, 'start_date': None, 'points': None, 'time_estimate': None, 'time_spent': 0, 'custom_fields': [], 'dependencies': [], 'linked_tasks': [], 'team_id': '9011010153', 'url': 'https://app.clickup.com/t/8685mw6dz', 'sharing': {'public': False, 'public_share_expires_on': None, 'public_fields': ['assignees', 'priority', 'due_date', 'content', 'comments', 'attachments', 'customFields', 'subtasks', 'tags', 'checklists', 'coverimage'], 'token': None, 'seo_optimized': False}, 'permission_level': 'create', 'list': {'id': '901100754275', 'name': 'Test List', 'access': True}, 'project': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'folder': {'id': '90110336890', 'name': 'Test Folder', 'hidden': False, 'access': True}, 'space': {'id': '90110061901'}}[0m\nThought:[32;1m[1;3m I now have the task created and assigned to Rodrigo\nFinal Answer: Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.[0m\n\n[1m> Finished chain.[0m\n--------------------------------------------------------------------------------\n```\n\n```output\n\"Rodrigo's user ID is 81928627 and a task called 'Rod's task' has been created and assigned to him.\"\n```\n\n## Related​\n\n- Tool [conceptual guide](/docs/concepts/tools/)\n\n- Tool [how-to guides](/docs/how_to/#tools)\n\n#### Was this page helpful?\n\n- [Initializing](#initializing)- [Get Authenticated](#get-authenticated)\n\n- [Get Access Token](#get-access-token)\n\n- [Create Agent](#create-agent)\n\n- [Use an Agent](#use-an-agent)- [Navigation](#navigation)\n\n- [Task Operations](#task-operations)\n\n- [Creation](#creation)\n\n- [Multi-Step Tasks](#multi-step-tasks)\n\n- [Related](#related)\n</document>\n<document  language='' description='' changefreq=None source='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' title='An agent for interacting with a SQL database | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/tutorials/sql-agent/' uuid='483a01c0-c8d8-568d-80e3-4c7349518f0d'>\nDO NOT call any tool besides SubmitFinalAnswer to submit the final answer.\n\nWhen generating the query:\n\nOutput the SQL query that answers the input question without a tool call.\n\nUnless the user specifies a specific number of examples they wish to obtain, always limit your query to at most 5 results.\nYou can order the results by a relevant column to return the most interesting examples in the database.\nNever query for all the columns from a specific table, only ask for the relevant columns given the question.\n\nIf you get an error while executing a query, rewrite the query and try again.\n\nIf you get an empty result set, you should try to rewrite the query to get a non-empty result set. \nNEVER make stuff up if you don't have enough information to answer the query... just say you don't have enough information.\n\nIf you have enough information to answer the input question, simply invoke the appropriate tool to submit the final answer to the user.\n\nDO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\"\"\"\nquery_gen_prompt = ChatPromptTemplate.from_messages(\n    [(\"system\", query_gen_system), (\"placeholder\", \"{messages}\")]\n)\nquery_gen = query_gen_prompt | ChatOpenAI(model=\"gpt-4o\", temperature=0).bind_tools(\n    [SubmitFinalAnswer]\n)\n\ndef query_gen_node(state: State):\n    message = query_gen.invoke(state)\n\n    # Sometimes, the LLM will hallucinate and call the wrong tool. We need to catch this and return an error message.\n    tool_messages = []\n    if message.tool_calls:\n        for tc in message.tool_calls:\n            if tc[\"name\"] != \"SubmitFinalAnswer\":\n                tool_messages.append(\n                    ToolMessage(\n                        content=f\"Error: The wrong tool was called: {tc['name']}. Please fix your mistakes. Remember to only call SubmitFinalAnswer to submit the final answer. Generated queries should be outputted WITHOUT a tool call.\",\n                        tool_call_id=tc[\"id\"],\n                    )\n                )\n    else:\n        tool_messages = []\n    return {\"messages\": [message] + tool_messages}\n\nworkflow.add_node(\"query_gen\", query_gen_node)\n\n# Add a node for the model to check the query before executing it\nworkflow.add_node(\"correct_query\", model_check_query)\n\n# Add node for executing the query\nworkflow.add_node(\"execute_query\", create_tool_node_with_fallback([db_query_tool]))\n\n# Define a conditional edge to decide whether to continue or end the workflow\ndef should_continue(state: State) -> Literal[END, \"correct_query\", \"query_gen\"]:\n    messages = state[\"messages\"]\n    last_message = messages[-1]\n    # If there is a tool call, then we finish\n    if getattr(last_message, \"tool_calls\", None):\n        return END\n    if last_message.content.startswith(\"Error:\"):\n        return \"query_gen\"\n    else:\n        return \"correct_query\"\n\n# Specify the edges between the nodes\nworkflow.add_edge(START, \"first_tool_call\")\nworkflow.add_edge(\"first_tool_call\", \"list_tables_tool\")\nworkflow.add_edge(\"list_tables_tool\", \"model_get_schema\")\nworkflow.add_edge(\"model_get_schema\", \"get_schema_tool\")\nworkflow.add_edge(\"get_schema_tool\", \"query_gen\")\nworkflow.add_conditional_edges(\n    \"query_gen\",\n    should_continue,\n)\nworkflow.add_edge(\"correct_query\", \"execute_query\")\nworkflow.add_edge(\"execute_query\", \"query_gen\")\n\n# Compile the workflow into a runnable\napp = workflow.compile()\n\nAPI Reference:\nAIMessage | ChatOpenAI | END | StateGraph | START | add_messages\n\nVisualize the graph¶\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import MermaidDrawMethod\n\ndisplay(\n    Image(\n        app.get_graph().draw_mermaid_png(\n            draw_method=MermaidDrawMethod.API,\n        )\n    )\n)\n\nAPI Reference:\nMermaidDrawMethod\n\nRun the agent¶\nmessages = app.invoke(\n    {\"messages\": [(\"user\", \"Which sales agent made the most in sales in 2009?\")]}\n)\njson_str = messages[\"messages\"][-1].tool_calls[0][\"args\"][\"final_answer\"]\njson_str\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' title='Review Tool Calls | 🦜🕸️LangGraph' content_type=None lastmod='2024-12-04' priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/human_in_the_loop_review_tool_calls/' uuid='a7380d1f-89be-5df5-9f1e-6b74afb1a49d'>\nOutput:\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}]}\n{'messages': [{'content': 'hi!', 'additional_kwargs': {}, 'response_metadata': {}, 'type': 'human', 'name': None, 'id': '39c51f14-2d5c-4690-883a-d940854b1845', 'example': False}, {'content': [{'text': \"Hello! Welcome. How can I assist you today? Is there anything specific you'd like to know or any information you're looking for?\", 'type': 'text', 'index': 0}], 'additional_kwargs': {}, 'response_metadata': {'stop_reason': 'end_turn', 'stop_sequence': None}, 'type': 'ai', 'name': None, 'id': 'run-d65e07fb-43ff-4d98-ab6b-6316191b9c8b', 'example': False, 'tool_calls': [], 'invalid_tool_calls': [], 'usage_metadata': {'input_tokens': 355, 'output_tokens': 31, 'total_tokens': 386}}]}\n\nIf we check the state, we can see that it is finished\nPythonJavascriptCURL\n\nstate = await client.threads.get_state(thread[\"thread_id\"])\n\nprint(state['next'])\n\nconst state = await client.threads.getState(thread[\"thread_id\"]);\n\nconsole.log(state.next);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/state | jq -c '.next'\n\nOutput:\n[]\n\nExample of approving tool¶\nLet's now look at what it looks like to approve a tool call. Note that we don't need to pass an interrupt to our streaming calls because the graph (defined here) was already compiled with an interrupt before the human_review_node.\nPythonJavascriptCURL\n\ninput = {\"messages\": [{\"role\": \"user\", \"content\": \"what's the weather in sf?\"}]}\n\nasync for chunk in client.runs.stream(\n    thread[\"thread_id\"],\n    assistant_id,\n    input=input,\n):\n    if chunk.data and chunk.event != \"metadata\": \n        print(chunk.data)\n\nconst input = { \"messages\": [{ \"role\": \"user\", \"content\": \"what's the weather in sf?\" }] };\n\nconst streamResponse = client.runs.stream(\n  thread[\"thread_id\"],\n  assistantId,\n  {\n    input: input,\n  }\n);\n\nfor await (const chunk of streamResponse) {\n  if (chunk.data && chunk.event !== \"metadata\") {\n    console.log(chunk.data);\n  }\n}\n\ncurl --request POST \\\n --url <DEPLOYMENT_URL>/threads/<THREAD_ID>/runs/stream \\\n --header 'Content-Type: application/json' \\\n --data \"{\n   \\\"assistant_id\\\": \\\"agent\\\",\n   \\\"input\\\": {\\\"messages\\\": [{\\\"role\\\": \\\"human\\\", \\\"content\\\": \\\"what's the weather in sf?\\\"}]}\n }\" | \\\n sed 's/\\r$//' | \\\n awk '\n /^event:/ {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n     sub(/^event: /, \"\", $0)\n     event_type = $0\n     data_content = \"\"\n }\n /^data:/ {\n     sub(/^data: /, \"\", $0)\n     data_content = $0\n }\n END {\n     if (data_content != \"\" && event_type != \"metadata\") {\n         print data_content \"\\n\"\n     }\n }\n '\n</document>\n<document  description=\"LangSmith's API supports programmatic access via API key to all of the actions available in the UI, with only a few exceptions that are noted below.\" language='en' changefreq=None source='https://docs.smith.langchain.com/administration/how_to_guides/organization_management/manage_organization_by_api' title='Manage your organization using the API | 🦜️🛠️ LangSmith' lastmod=None content_type='text/html; charset=utf-8' priority=None loc=None uuid='cd89709f-0016-5447-9ab3-2e9efb7db0fa'>\nSample Code​\nThe sample code below goes through a few common workflows related to organization management.\nMake sure to make necessary replacements wherever <replace_me> is in the code.\n</document>\n<document  description='You are passing too many, too few, or mismatched ToolMessages to a model.' language='en' changefreq='weekly' source='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' title='INVALID_TOOL_RESULTS | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/troubleshooting/errors/INVALID_TOOL_RESULTS/' uuid='62856b31-ccd6-527f-a540-677a2f8170eb'>\nSee [this guide](/docs/how_to/tool_results_pass_to_model/) for more details on tool calling.\n\n## Troubleshooting​\n\nThe following may help resolve this error:\n\n- If you are using a custom executor rather than a prebuilt one like LangGraph's [ToolNode](https://langchain-ai.github.io/langgraphjs/reference/classes/langgraph_prebuilt.ToolNode.html)\nor the legacy LangChain [AgentExecutor](/docs/how_to/agent_executor/), verify that you are invoking and returning the result for one tool per tool call.\n\n- If you are using [few-shot tool call examples](/docs/how_to/tools_few_shot/) with messages that you manually create, and you want to simulate a failure,\nyou still need to pass back a `ToolMessage` whose content indicates that failure.\n\n#### Was this page helpful?\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  language='en' description='ddtrace is a Datadog application performance monitoring (APM) library which provides an integration to monitor your LangChain application.' changefreq='weekly' source='https://python.langchain.com/docs/integrations/providers/datadog/' title='Datadog Tracing | 🦜️🔗 LangChain' content_type=None lastmod=None priority='0.5' loc='https://python.langchain.com/docs/integrations/providers/datadog/' uuid='aac182d0-171a-5d65-a00e-60b5a764e813'>\n## Troubleshooting​\n\nNeed help? Create an issue on [ddtrace](https://github.com/DataDog/dd-trace-py) or contact [Datadog support](https://docs.datadoghq.com/help/).\n\n#### Was this page helpful?\n\n- [Installation and Setup](#installation-and-setup)\n\n- [Configuration](#configuration)- [Log Prompt & Completion Sampling](#log-prompt--completion-sampling)\n\n- [Troubleshooting](#troubleshooting)\n</document>\n<document  description='JSON (JavaScript Object Notation) is an open standard file format and data interchange format that uses human-readable text to store and transmit data objects consisting of attribute–value pairs and arrays (or other serializable values).' language='en' changefreq='weekly' source='https://python.langchain.com/docs/how_to/document_loader_json/' title='How to load JSON | 🦜️🔗 LangChain' lastmod=None content_type=None priority='0.5' loc='https://python.langchain.com/docs/how_to/document_loader_json/' uuid='67c83a8d-a61d-5338-a82c-cedaa5def0c1'>\nJSON        -> {\"key\": [{\"text\": ...}, {\"text\": ...}, {\"text\": ...}]}\njq_schema   -> \".key[].text\"\n\nJSON        -> [\"...\", \"...\", \"...\"]\njq_schema   -> \".[]\"\n```\n\n#### Was this page helpful?\n\n- [Using JSONLoader](#using-jsonloader)- [JSON file](#json-file)\n\n- [JSON Lines file](#json-lines-file)\n\n- [JSON file with jq schema content_key](#json-file-with-jq-schema-content_key)\n\n- [Extracting metadata](#extracting-metadata)\n\n- [The metadata_func](#the-metadata_func)\n\n- [Common JSON structures with jq schema](#common-json-structures-with-jq-schema)\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' title='SDK (Python) | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/reference/sdk/python_sdk_ref/' uuid='d7081e58-73a0-55f5-9a3f-25d019980493'>\n}\n                            }\n                    },\n                'config_schema':\n                    {\n                        'title': 'Configurable',\n                        'type': 'object',\n                        'properties':\n                            {\n                                'model_name':\n                                    {\n                                        'title': 'Model Name',\n                                        'enum': ['anthropic', 'openai'],\n                                        'type': 'string'\n                                    }\n                            }\n                    }\n            }\n</document>\n<document  description='' language='' changefreq=None source='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' title='How to create agents with configuration | 🦜🕸️LangGraph' lastmod='2024-12-04' content_type=None priority=None loc='https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/' uuid='19b61e09-1d71-560a-a077-a45a31445149'>\nHow to create agents with configuration\n\nHow to create agents with configuration¶\nOne of the benefits of LangGraph API is that it lets you create agents with different configurations.\nThis is useful when you want to:\n\nDefine a cognitive architecture once as a LangGraph\nLet that LangGraph be configurable across some attributes (for example, system message or LLM to use)\nLet users create agents with arbitrary configurations, save them, and then use them in the future\n\nIn this guide we will show how to do that for the default agent we have built in.\nIf you look at the agent we defined, you can see that inside the call_model node we have created the model based on some configuration. That node looks like:\nPythonJavascript\n\ndef call_model(state, config):\n    messages = state[\"messages\"]\n    model_name = config.get('configurable', {}).get(\"model_name\", \"anthropic\")\n    model = _get_model(model_name)\n    response = model.invoke(messages)\n    # We return a list, because this will get added to the existing list\n    return {\"messages\": [response]}\n\nfunction callModel(state: State, config: RunnableConfig) {\n  const messages = state.messages;\n  const modelName = config.configurable?.model_name ?? \"anthropic\";\n  const model = _getModel(modelName);\n  const response = model.invoke(messages);\n  // We return a list, because this will get added to the existing list\n  return { messages: [response] };\n}\n\nWe are looking inside the config for a model_name parameter (which defaults to anthropic if none is found). That means that by default we are using Anthropic as our model provider. In this example we will see an example of how to create an example agent that is configured to use OpenAI.\nFirst let's set up our client and thread:\nPythonJavascriptCURL\n\nfrom langgraph_sdk import get_client\n\nclient = get_client(url=<DEPLOYMENT_URL>)\n# Select an assistant that is not configured\nassistants = await client.assistants.search()\nassistant = [a for a in assistants if not a[\"config\"]][0]\n\nimport { Client } from \"@langchain/langgraph-sdk\";\n\nconst client = new Client({ apiUrl: <DEPLOYMENT_URL> });\n// Select an assistant that is not configured\nconst assistants = await client.assistants.search();\nconst assistant = assistants.find(a => !a.config);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants/search \\\n    --header 'Content-Type: application/json' \\\n    --data '{\n        \"limit\": 10,\n        \"offset\": 0\n    }' | jq -c 'map(select(.config == null or .config == {})) | .[0]'\n\nWe can now call .get_schemas to get schemas associated with this graph:\nPythonJavascriptCURL\n\nschemas = await client.assistants.get_schemas(\n    assistant_id=assistant[\"assistant_id\"]\n)\n# There are multiple types of schemas\n# We can get the `config_schema` to look at the configurable parameters\nprint(schemas[\"config_schema\"])\n\nconst schemas = await client.assistants.getSchemas(\n  assistant[\"assistant_id\"]\n);\n// There are multiple types of schemas\n// We can get the `config_schema` to look at the configurable parameters\nconsole.log(schemas.config_schema);\n\ncurl --request GET \\\n    --url <DEPLOYMENT_URL>/assistants/<ASSISTANT_ID>/schemas | jq -r '.config_schema'\n\nOutput:\n{\n    'model_name': \n        {\n            'title': 'Model Name',\n            'enum': ['anthropic', 'openai'],\n            'type': 'string'\n        }\n}\n\nNow we can initialize an assistant with config:\nPythonJavascriptCURL\n\nopenai_assistant = await client.assistants.create(\n    # \"agent\" is the name of a graph we deployed\n    \"agent\", config={\"configurable\": {\"model_name\": \"openai\"}}\n)\n\nprint(openai_assistant)\n\nlet openAIAssistant = await client.assistants.create(\n  // \"agent\" is the name of a graph we deployed\n  \"agent\", { \"configurable\": { \"model_name\": \"openai\" } }\n);\n\nconsole.log(openAIAssistant);\n\ncurl --request POST \\\n    --url <DEPLOYMENT_URL>/assistants \\\n    --header 'Content-Type: application/json' \\\n    --data '{\"graph_id\":\"agent\",\"config\":{\"configurable\":{\"model_name\":\"open_ai\"}}}'\n</document>\n</documents> \n\n LLM generation: The error message you are encountering indicates that there is a mismatch between the argument descriptions in the docstring of your tool function and the actual function signature. Specifically, the error states that the argument `query` (of type `str`) mentioned in the docstring is not found in the function signature.\n\n### Steps to Resolve the Issue\n\n1. **Check the Tool Function Signature**: Ensure that the function signature of `process_claims_query` matches the argument descriptions in the docstring. The function should look something like this:\n\n   ```python\n   @tool\n   def process_claims_query(query: str) -> str:\n       \"\"\"\n       Process a claims-related query using the specialized claims workflow.\n\n       Args:\n           query (str): The user's claims-related query\n\n       Returns:\n           str: The response from the claims workflow\n       \"\"\"\n       return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n   ```\n\n   Make sure that the argument `query` is indeed defined in the function signature.\n\n2. **Ensure Proper Registration**: When you dynamically register the tool function using `exec`, ensure that the function is correctly defined in the global scope. The tool function should be accessible when the LLM tries to bind it.\n\n3. **Check the JSON Configuration**: Ensure that the JSON configuration correctly specifies the tool function. The `tool` field in the JSON should match the name of the function you are defining. For example, if your function is named `process_claims_query`, the JSON should look like this:\n\n   ```json\n   {\n     \"uniq_id\": \"6\",\n     \"type\": \"STEP\",\n     \"name\": \"TOOL CALL\",\n     \"description\": \"Call the appropriate tool\",\n     \"tool\": \"process_claims_query\",\n     ...\n   }\n   ```\n\n4. **Debugging**: If the issue persists, you can add print statements to check the function signature and docstring right after you define the tool function. This can help you verify that the function is being registered correctly.\n\n   ```python\n   print(f\"Function: {process_claims_query.__name__}, Signature: {inspect.signature(process_claims_query)}, Docstring: {process_claims_query.__doc__}\")\n   ```\n\n5. **Re-run the Tests**: After making the necessary adjustments, re-run your tests to see if the issue is resolved.\n\n### Example of Correct Tool Function\n\nHere’s a complete example of how the tool function should be defined and registered:\n\n```python\n@tool\ndef process_claims_query(query: str) -> str:\n    \"\"\"\n    Process a claims-related query using the specialized claims workflow.\n\n    Args:\n        query (str): The user's claims-related query\n\n    Returns:\n        str: The response from the claims workflow\n    \"\"\"\n    return [{\"claim_id\": \"1234\", \"status\": \"pending\"}, {\"claim_id\": \"5678\", \"status\": \"approved\"}]\n```\n\n### Conclusion\n\nBy ensuring that the function signature matches the argument descriptions in the docstring and that the function is properly registered, you should be able to resolve the `ValueError` you are encountering. If you continue to face issues, consider checking the context in which the function is being executed and ensure that all dependencies are correctly set up.","type":"human"}}]]},"run_type":"llm","extra":{"invocation_params":{"model":"gpt-4o-mini","model_name":"gpt-4o-mini","stream":false,"n":1,"temperature":0.0,"_type":"openai-chat","stop":null,"tools":[{"type":"function","function":{"name":"GradeHallucinations","description":"Binary score for hallucination present in generation answer.","parameters":{"properties":{"binary_score":{"description":"Answer is grounded in the facts, 'yes' or 'no'","type":"string"}},"required":["binary_score"],"type":"object"}}}],"parallel_tool_calls":false,"tool_choice":{"type":"function","function":{"name":"GradeHallucinations"}}},"options":{"stop":null},"batch_size":1,"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":20,"langgraph_node":"respond","langgraph_triggers":["branch:respond:check_hallucination:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","ls_provider":"openai","ls_model_name":"gpt-4o-mini","ls_model_type":"chat","ls_temperature":0.0,"LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:1"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T200001263059Z85066f84-90de-4c8b-bf10-edbbe6052031.20241204T200014644615Za8fdc9d7-05c1-4ea7-a49e-73c543216e9c.20241204T200014784868Zcdabb123-fc0a-46e5-8d35-e642382c6520.20241204T200014794974Z9834a412-246b-46d9-9e59-767e8231fd97"}
{"id":"9834a412-246b-46d9-9e59-767e8231fd97","name":"ChatOpenAI","end_time":"2024-12-04T20:00:16.013747","error":null,"outputs":{"generations":[{"text":"","generation_info":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ChatGeneration","message":{"lc":1,"type":"constructor","id":["langchain","schema","messages","AIMessage"],"kwargs":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_lOh6lYmVr2j5UNm1Xa68awMA","function":{"arguments":"{\"binary_score\":\"no\"}","name":"GradeHallucinations"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-9834a412-246b-46d9-9e59-767e8231fd97","tool_calls":[{"name":"GradeHallucinations","args":{"binary_score":"no"},"id":"call_lOh6lYmVr2j5UNm1Xa68awMA","type":"tool_call"}],"invalid_tool_calls":[]}}}],"llm_output":null,"run":null,"type":"LLMResult"}}
{"id":"493bd9b1-ad3b-4fea-9a31-c27ce7d95acd","name":"PydanticToolsParser","start_time":"2024-12-04T20:00:16.018554","serialized":null,"events":[{"name":"start","time":"2024-12-04T20:00:16.018554+00:00"},{"name":"end","time":"2024-12-04T20:00:16.022034+00:00"}],"inputs":{"input":{"content":"","additional_kwargs":{"tool_calls":[{"index":0,"id":"call_lOh6lYmVr2j5UNm1Xa68awMA","function":{"arguments":"{\"binary_score\":\"no\"}","name":"GradeHallucinations"},"type":"function"}]},"response_metadata":{"finish_reason":"stop","model_name":"gpt-4o-mini-2024-07-18","system_fingerprint":"fp_0705bf87c0"},"type":"ai","id":"run-9834a412-246b-46d9-9e59-767e8231fd97","example":false,"tool_calls":[{"name":"GradeHallucinations","args":{"binary_score":"no"},"id":"call_lOh6lYmVr2j5UNm1Xa68awMA","type":"tool_call"}],"invalid_tool_calls":[]}},"run_type":"parser","extra":{"metadata":{"user_id":"da74c1b6-e3af-4498-a2c5-08757255be48","graph_id":"chat","created_by":"system","run_attempt":1,"langgraph_version":"0.2.53","langgraph_plan":"enterprise","langgraph_host":"saas","run_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","thread_id":"a42dc55d-90cc-4671-93ec-63f025217bc2","model_name":"openai/gpt-4o-mini","x-vercel-id":"cle1::rk85d-1733342368391-77c21452adc9","assistant_id":"eb6db400-e3c8-5d06-a834-015cb89efe69","x-request-id":"bc55a845-cd8c-4b6b-9d3e-a18d3d76d43f","x-forwarded-for":"2a06:98c0:3600::103, 192.168.4.21, 192.168.14.17","x-forwarded-proto":"https","x-middleware-subrequest":"360e81ade3db37183c0489ac723cb341c3683a49","langgraph_step":20,"langgraph_node":"respond","langgraph_triggers":["branch:respond:check_hallucination:respond"],"langgraph_path":["__pregel_pull","respond"],"langgraph_checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","checkpoint_ns":"respond:6e315239-a651-1603-2458-107a0a8c6f43","LANGSMITH_LANGGRAPH_API_VARIANT":"cloud","LANGSMITH_FF_MULTIPART":"true","LANGSMITH_LANGGRAPH_API_REVISION":"bcea33b","LANGSMITH_HOST_PROJECT_ID":"6d5d0ba3-f1a3-4769-97d8-dc2a4f6dba16","LANGSMITH_AUTH_VERIFY_TENANT_ID":"True","LANGSMITH_TENANT_ID":"ebbaf2eb-769b-4505-aca2-d11de10372a4","LANGCHAIN_CALLBACKS_BACKGROUND":"true","LANGSMITH_AUTH_ENDPOINT":"https://api.smith.langchain.com","revision_id":"94a81c9-dirty"},"runtime":{"sdk":"langsmith-py","sdk_version":"0.1.147","library":"langsmith","platform":"Linux-6.1.100+-x86_64-with-glibc2.36","runtime":"python","py_implementation":"CPython","runtime_version":"3.11.10","langchain_version":"0.3.9","langchain_core_version":"0.3.21"}},"tags":["seq:step:2"],"trace_id":"1efb27a4-5264-6908-9ab5-23fc3c60ae2d","dotted_order":"20241204T195929374537Z1efb27a4-5264-6908-9ab5-23fc3c60ae2d.20241204T200001263059Z85066f84-90de-4c8b-bf10-edbbe6052031.20241204T200014644615Za8fdc9d7-05c1-4ea7-a49e-73c543216e9c.20241204T200014784868Zcdabb123-fc0a-46e5-8d35-e642382c6520.20241204T200016018554Z493bd9b1-ad3b-4fea-9a31-c27ce7d95acd"}
{"id":"493bd9b1-ad3b-4fea-9a31-c27ce7d95acd","name":"PydanticToolsParser","end_time":"2024-12-04T20:00:16.022034","error":null,"outputs":{"output":{"binary_score":"no"}}}
